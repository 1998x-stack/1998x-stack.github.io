<h2>
 Deep Learning
</h2>
<ul>
 <li>
  <a href="../../README.md">
   return to home
  </a>
 </li>
</ul>
<h3>
 Deep learning
</h3>
<ul>
 <li>
  Adaptive Computation Time for Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1603.08983.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  A Deep Learning Approach To Multiple Kernel Fusion.
  <a href="https://arxiv.org/pdf/1612.09007.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Aggregated Residual Transformations for Deep Neural Networks.
  <a href="https://arxiv.org/pdf/1611.05431.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/wenxinxu/ResNeXt-in-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  A guide to convolution arithmetic for deep learning.
  <a href="https://arxiv.org/pdf/1603.07285.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A New Method to Visualize Deep Neural Networks.
  <a href="https://icmlviz.github.io/assets/papers/23.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  A Persona-Based Neural Conversation Model.
  <a href="https://www.aclweb.org/anthology/P/P16/P16-1094.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Architectural Complexity Measures of Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1602.08210.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Associative Long Short-Term Memory.
  <a href="https://arxiv.org/pdf/1602.03032.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Automatic chemical design using a data-driven continuous representation of molecules.
  <a href="https://arxiv.org/pdf/1610.02415.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/cxhernandez/molencoder">
   <code>
    pytorch
   </code>
  </a>
 </li>
 <li>
  A Way out of the Odyssey- Analyzing and Combining Recent Insights for LSTMs.
  <a href="https://arxiv.org/pdf/1611.05104.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Batch Policy Gradient Methods for Improving Neural Conversation Models.
  <a href="https://openreview.net/pdf?id=rJfMusFll">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Benefits of depth in neural networks.
  <a href="http://proceedings.mlr.press/v49/telgarsky16.pdf">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  BinaryNet-Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1.
  <a href="https://arxiv.org/pdf/1602.02830.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Bitwise Neural Networks.
  <a href="http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex.
  <a href="https://arxiv.org/pdf/1604.03640.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Building Machines That Learn and Think Like People.
  <a href="http://www.mit.edu/~tomeru/papers/machines_that_think.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors.
  <a href="https://arxiv.org/pdf/1612.04342.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples.
  <a href="https://arxiv.org/pdf/1604.02426.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/filipradenovic/cnnimageretrieval">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Composing graphical models with neural networks for structured representations and fast inference .
  <a href="https://arxiv.org/pdf/1603.06277.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mattjj/svae">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Conditional Generative Moment-Matching Networks.
  <a href="https://arxiv.org/pdf/1606.04218.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Context Encoders: Feature Learning by Inpainting.
  <a href="https://arxiv.org/pdf/1604.07379.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/BoyuanJiang/context_encoder_pytorch">
   <code>
    pytorch
   </code>
  </a>
 </li>
 <li>
  Conversational Contextual Cues-The Case of Personalization and History for Response Ranking.
  <a href="https://arxiv.org/pdf/1606.00372.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Controlling Output Length in Neural Encoder-Decoders.
  <a href="https://arxiv.org/pdf/1609.09552.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kiyukuta/lencon">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.
  <a href="https://arxiv.org/pdf/1606.09375.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mdeff/cnn_graph">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Data Programming- Creating Large Training Sets, Quickly.
  <a href="https://arxiv.org/pdf/1605.07723.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  DCM Bandits: Learning to Rank with Multiple Clicks.
  <a href="https://pdfs.semanticscholar.org/b4c3/a056426aeca24d43785fac6c4d61af7eb5fe.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Decoupled Neural Interfaces using Synthetic Gradients.
  <a href="https://pdfs.semanticscholar.org/b4c3/a056426aeca24d43785fac6c4d61af7eb5fe.pdfhttps://arxiv.org/pdf/1608.05343.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  DeepChess: End-to-End Deep Neural Network for Automatic Learning in Chess.
  <a href="http://www.cs.tau.ac.il/~wolf/papers/deepchess.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/mr-press/DeepChess">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  <b>
   DeepMind Lab.
  </b>
  <a href="https://arxiv.org/pdf/1612.03801.pdf">
   <code>
    url
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep API Learning.
  <a href="http://home.cse.ust.hk/~xguaa/papers/deepapi.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  <b>
   [DeepCoder]
  </b>
  <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=5&amp;sn=2654d4e512ff3c23e1bd17b2e9e562d5">
   DeepCoder: Learning to Write Programs
  </a>
  :star:
 </li>
 <li>
  <b>
   [DeepFashion]
  </b>
  Powering Robust Clothes Recognition and Retrieval with Rich Annotations.
  <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/liuziwei7/fashion-detection">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Deep Learning without Poor Local Minima.
  <a href="https://arxiv.org/pdf/1605.07110.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep Learning with Differential Privacy.
  <a href="https://arxiv.org/pdf/1607.00133.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/differential_privacy/privacy_accountant">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep Portfolio Theory.
  <a href="https://arxiv.org/pdf/1605.07230.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deeply-Fused Nets.
  <a href="https://arxiv.org/pdf/1605.07716.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  DeepSense: A Unified Deep Learning Framework for Time-Series Mobile Sensing Data Processing.
  <a href="https://arxiv.org/pdf/1611.01942.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/yscacaca/DeepSense">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Densely Connected Convolutional Networks.
  <a href="https://arxiv.org/pdf/1608.06993.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="http://www.weibo.com/1402400261/FfDPdBLum?type=comment">
   <code>
    pytorch
   </code>
  </a>
 </li>
 <li>
  Detect, Replace, Refine: Deep Structured Prediction For Pixel Wise Labeling.
  <a href="https://arxiv.org/pdf/1612.04770.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/gidariss/DRR_struct_pred">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  <b>
   [DenseNet]
  </b>
  <a href="https://medium.com/@illarionkhlestov/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504#.a88ur45ce">
   Densely Connected Convolutional Networks.
  </a>
  <a href="https://arxiv.org/pdf/1608.06993.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/andreasveit/densenet-pytorch">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  Density estimation using Real NVP.
  <a href="https://arxiv.org/pdf/1605.08803.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/real_nvp">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Domain Separation Networks. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwij0dG5oI7RAhVriVQKHV3gAfwQFggsMAE&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F6254-domain-separation-networks.pdf&amp;usg=AFQjCNFRd_0epq_0QAs21drboBmgCRdg1A">
   url
  </a>
  ]
 </li>
 <li>
  <b>
   [DrMAD]
  </b>
  <a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650326224&amp;idx=1&amp;sn=d40d8e0078f71b76c140ebe5185a8f80&amp;chksm=f235a3dac5422acc9c8a0fa9a485cd666b792e52a188b4be3ec25cc800423be8ffecb069ae23&amp;mpshare=1">
   Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks.
  </a>
  )
  <a href="https://arxiv.org/pdf/1601.00917.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/bigaidream-projects/drmad">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes.
  <a href="https://arxiv.org/pdf/1607.00036.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Early Visual Concept Learning with Unsupervised Deep Learning.
  <a href="https://arxiv.org/pdf/1606.05579.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/miyosuda/disentangled_vae">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Efficient softmax approximation for GPUs.
  <a href="https://arxiv.org/pdf/1609.04309.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/rosinality/adaptive-softmax-pytorch">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Efficient Training of Very Deep Neural Networks for Supervised Hashing.
  <a href="https://arxiv.org/pdf/1511.04524.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Episodic Exploration for Deep Deterministic Policies- An Application to StarCraft Micromanagement Tasks.
  <a href="https://arxiv.org/pdf/1609.02993.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Event-driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines.
  <a href="https://arxiv.org/pdf/1612.05596.pdf?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Fathom: Reference Workloads for Modern Deep Learning Methods.
  <a href="https://arxiv.org/pdf/1608.06581.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Feedback arcs and node hierarchy in directed networks.
  <a href="https://arxiv.org/pdf/1612.05347.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  FINN: A framework for fast, scalable binarized neural network inference.
  <a href="https://arxiv.org/pdf/1612.07119.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/Xilinx/BNN-PYNQ">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks.
  <a href="https://arxiv.org/pdf/1612.01925.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/lmb-freiburg/flownet2">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  FractalNet-Ultra-Deep Neural Networks without Residuals.
  <a href="https://arxiv.org/pdf/1605.07648.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [URNN]
  </b>
  Full-Capacity Unitary Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1611.00035.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/stwisdom/urnn">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Fused-Layer CNN Accelerators.
  <a href="http://compas.cs.stonybrook.edu/~mferdman/downloads.php/MICRO16_Fused_Layer_CNN_Accelerators.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Generating long and diverse responses with neural conversation models.
  <a href="https://arxiv.org/pdf/1701.03185.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  GRAPH CONVOLUTIONAL NETWORKS.
  <a href="http://tkipf.github.io/graph-convolutional-networks/">
   <code>
    url
   </code>
  </a>
  <a href="https://github.com//shagunsodhani/pregel">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Hierarchical Multiscale Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1609.01704.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Higher Order Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1605.00064.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Highway and Residual Networks learn Unrolled Iterative Estimation.
  <a href="https://openreview.net/pdf?id=Skn9Shcxe">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.
  <a href="https://arxiv.org/pdf/1603.06560.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kevinzakka/hyperband">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  How to Train Your Deep Neural Network with Dictionary Learning.
  <a href="https://arxiv.org/pdf/1612.07454.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Improving the Robustness of Deep Neural Networks via Stability Training.
  <a href="https://arxiv.org/pdf/1604.04326.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Large-Margin Softmax Loss for Convolutional Neural Networks.
  <a href="https://arxiv.org/pdf/1612.02295.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Latent Predictor Networks for Code Generation.
  <a href="https://arxiv.org/pdf/1603.06744.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [Normalization]
  </b>
  Layer Normalization.
  <a href="https://arxiv.org/pdf/1607.06450.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/ryankiros/layer-norm">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning Discriminative Features via Label Consistent Neural Network.
  <a href="https://arxiv.org/pdf/1602.01168.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning End-to-End Goal-Oriented Dialog.
  <a href="https://arxiv.org/pdf/1605.07683.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning Features by Watching Objects Move.
  <a href="https://arxiv.org/pdf/1612.06370.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/pathak22/unsupervised-video">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Learning Python Code Suggestion with a Sparse Pointer Network.
  <a href="https://arxiv.org/pdf/1611.08307.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/uclmr/pycodesuggest">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning to learn by gradient descent by gradient descent.
  <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Machine Comprehension Using Match-LSTM and Answer Pointer.
  <a href="https://arxiv.org/pdf/1608.07905.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [AlphaGo]
  </b>
  Mastering the game of Go with deep neural networks and tree search.
  <a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf">
   <code>
    pdf
   </code>
  </a>
  ] :star:
 </li>
 <li>
  Meta-Unsupervised-Learning: A supervised approach to unsupervised learning.
  <a href="https://arxiv.org/pdf/1612.09030.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Models, networks and algorithmic complexity.
  <a href="https://arxiv.org/pdf/1612.05627.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model.
  <a href="https://128.84.21.199/abs/1612.06676">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Multiresolution Recurrent Neural Networks- An Application to Dialogue Response Generation.
  <a href="https://arxiv.org/pdf/1606.00776.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Mutual information for fitting deep nonlinear models.
  <a href="https://128.84.21.199/pdf/1612.05708">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Natural-Parameter Networks: A Class of Probabilistic Neural Networks.
  <a href="https://arxiv.org/pdf/1611.00448.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Neural Paraphrase Generation with Stacked Residual LSTM Networks.
  <a href="https://arxiv.org/pdf/1610.03098.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com//iamaaditya/neural-paraphrase-generation">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Outrageously Large Neural Networks- The Sparsely-Gated Mixture-of-Experts Layer.
  <a href="https://openreview.net/pdf?id=B1ckMDqlg">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Overcoming catastrophic forgetting in neural networks.
  <a href="https://arxiv.org/pdf/1612.00796.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences.
  <a href="https://arxiv.org/pdf/1610.09513.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/PhasedLSTMCell">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Pixel Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1601.06759.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Polynomial networks and factorization machines new insights and efficient training algorithms.
  <a href="http://mblondel.org/talks/mblondel-erato-2016-08.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Policy Networks with Two-Stage Training for Dialogue Systems.
  <a href="https://arxiv.org/pdf/1606.03152.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [PSPNet]
  </b>
  <a href="http://www.dongzhuoyao.com/pyramid-scene-parsing-network/">
   Pyramid Scene Parsing Network.
  </a>
  <a href="https://arxiv.org/pdf/1612.01105.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="http://weibo.com/1402400261/EuVYls29J?type=comment">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Projected Semi-Stochastic Gradient Descent Method with Mini-Batch Scheme under Weak Strong Convexity Assumption.
  <a href="https://arxiv.org/pdf/1612.05356.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [QRNN]
  </b>
  Quasi-Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1611.01576.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/santi-pdp/quasi-rnn">
   <code>
    tensorflow
   </code>
  </a>
  <a href="https://github.com/DingKe/qrnn">
   <code>
    keras
   </code>
  </a>
  <a href="https://github.com/salesforce/pytorch-qrnn">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  RAISR: Rapid and Accurate Image Super Resolution.
  <a href="https://arxiv.org/pdf/1606.01299.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Recurrent Batch Normalization.
  <a href="https://arxiv.org/pdf/1603.09025.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Recurrent Dropout without Memory Loss.
  <a href="https://arxiv.org/pdf/1603.05118.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Recurrent Highway Networks.
  <a href="https://arxiv.org/pdf/1607.03474.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Residual Networks of Residual Networks- Multilevel Residual Networks.
  <a href="https://arxiv.org/pdf/1608.02908.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Revisiting Semi-Supervised Learning with Graph Embeddings.
  <a href="https://arxiv.org/pdf/1603.08861.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com//kimiyoung/planetoid">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout.
  <a href="http://bayesiandeeplearning.org/papers/BDL_4.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  RNN-based Encoder-decoder Approach with Word Frequency Estimation.
  <a href="https://arxiv.org/pdf/1701.00138.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  SampleRNN: An Unconditional End-To-End Neural Audio Generation Model.
  <a href="https://openreview.net/pdf?id=HyJsPvcgg">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/soroushmehr/sampleRNN_ICLR2017">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Semantic3D.net: A new Large-scale Point Cloud Classification Benchmark.
  <a href="https://arxiv.org/pdf/1704.03847.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/nsavinov/semantic3dnet">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Semi-Supervised Classification with Graph Convolutional Networks.
  <a href="https://arxiv.org/pdf/1609.02907.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  SoundNet: Learning Sound Representations from Unlabeled Video.
  <a href="http://web.mit.edu/vondrick/soundnet.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/eborboihuc/SoundNet-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Structured Receptive Fields in CNNs.
  <a href="https://arxiv.org/pdf/1605.02971.pdfv2">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/jhjacobsen/RFNN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Tagger: Deep Unsupervised Perceptual Grouping.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjp-razjufQAhWFLSYKHSF_CFcQFggsMAI&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F6067-tagger-deep-unsupervised-perceptual-grouping.pdf&amp;usg=AFQjCNG2BMZI5bfamUYu5Kbba9EbDsc9mw">
   url
  </a>
  ]
 </li>
 <li>
  Temporal Ensembling for Semi-Supervised Learning.
  <a href="https://arxiv.org/pdf/1610.02242.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/smlaine2/tempens">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  TensorFlow- A system for large-scale machine learning.
  <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Tensors and algebra give interpretable groups for crosstalk mechanisms in breast cancer.
  <a href="https://arxiv.org/pdf/1612.08116.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  The Inevitability of Probability- Probabilistic Inference in Generic Neural Networks Trained with Non-Probabilistic Feedback.  [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiAq9iqsNjQAhUEjpQKHUZjBq0QFggbMAA&amp;url=https%3A%2F%2F128.84.21.199%2Fabs%2F1601.03060v1&amp;usg=AFQjCNG5CeOHSBphHdIAmvp8U_iTvsBiEA">
   url
  </a>
  ]
 </li>
 <li>
  The Predictron: End-To-End Learning and Planning.
  <a href="https://arxiv.org/pdf/1612.08810.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/zhongwen/predictron">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Towards an integration of deep learning and neuroscience.
  <a href="https://arxiv.org/pdf/1606.03813.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Training Recurrent Neural Networks by Diffusion.
  <a href="https://arxiv.org/pdf/1601.04114.pdf">
   <code>
    arxiv
   </code>
  </a>
  ]
 </li>
 <li>
  Tutorial on Variational Autoencoders.
  <a href="https://arxiv.org/pdf/1606.05908.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Understanding Deep Convolutional Networks.
  <a href="https://arxiv.org/pdf/1601.04920.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [ICLR:Best Paper]
  </b>
  Understanding deep learning requires rethinking generalization.
  <a href="https://arxiv.org/pdf/1611.03530.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Understanding deep learning requires rethinking generalization.
  <a href="https://arxiv.org/pdf/1611.03530.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/pluskid/fitting-random-labels">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Understanding Neural Networks through Representation Erasure.
  <a href="https://arxiv.org/pdf/1612.08220.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Unsupervised Perceptual Rewards for Imitation Learning.
  <a href="https://scirate.com/arxiv/1612.06699">
   <code>
    arxiv
   </code>
  </a>
  ]
 </li>
 <li>
  Using Fast Weights to Attend to the Recent Past.
  <a href="https://arxiv.org/pdf/1610.06258.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/jiamings/fast-weights">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Value Iteration Networks.
  <a href="https://arxiv.org/pdf/1602.02867.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/karpathy/paper-notes/blob/master/vin.md">
   <code>
    code
   </code>
  </a>
  ] :star:
 </li>
 <li>
  Variable Computation in Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1611.06188.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks.
  <a href="https://arxiv.org/pdf/1607.02586.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/next_frame_prediction">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Weight Normalization-A Simple Reparameterization to Accelerate Training of Deep Neural Networks.
  <a href="https://arxiv.org/pdf/1602.07868.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/openai/weightnorm">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Wide Residual Networks.
  <a href="https://arxiv.org/pdf/1605.07146.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/xternalz/WideResNet-pytorch">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Xception]
  </b>
  Deep Learning with Depthwise Separable Convolutions.
  <a href="https://arxiv.org/pdf/1610.02357.pdfv2">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/fchollet/deep-learning-models/blob/master/xception.py">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Zoneout- Regularizing RNNs by Randomly Preserving Hidden Activations.
  <a href="https://arxiv.org/pdf/1606.01305.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
</ul>
<h3>
 Attention and memory
</h3>
<ul>
 <li>
  Attention Based Recurrent Neural Networks for Online Advertising.
  <a href="http://www2016.net/proceedings/companion/p141.pdf">
   <code>
    pdf
   </code>
  </a>
  ]
 </li>
 <li>
  Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling.
  <a href="https://arxiv.org/pdf/1609.01454.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/HadoopIt/rnn-nlu">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Can Active Memory Replace Attention?
  <a href="https://arxiv.org/pdf/1610.08613.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation.
  <a href="https://arxiv.org/pdf/1606.04199.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Emergent Logical Structure in Vector Representations of Neural Readers.
  <a href="https://arxiv.org/pdf/1611.07954.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Gated End-to-End Memory Networks.
  <a href="https://arxiv.org/pdf/1610.04211.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Generating Images from Captions with Attention.
  <a href="https://arxiv.org/pdf/1511.02793.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  GRAM: Graph-based Attention Model for Healthcare Representation Learning.
  <a href="https://arxiv.org/pdf/1611.07012.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mp2893/gram">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Hybrid computing using a neural network with dynamic external memory.
  <a href="https://news.ycombinator.com/item?id=12694779">
   <code>
    url
   </code>
  </a>
  :star:
 </li>
 <li>
  Hierarchical Memory Networks.
  <a href="https://arxiv.org/pdf/1605.07427.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning.
  <a href="https://arxiv.org/pdf/1612.01887.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [LightRNN]
  </b>
  LightRNN: Memory and Computation-Efficient Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1610.09893.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/YisenWang/LightRNN-NIPS2016-Tensorflow_code">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer.
  <a href="https://arxiv.org/pdf/1612.03928.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/szagoruyko/attention-transfer">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Prioritizing Attention in Fast Data: Principles and Promise.
  <a href="http://www.bailis.org/papers/fastdata-cidr2017.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Recursive Recurrent Nets with Attention Modeling for OCR in the Wild.
  <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lee_Recursive_Recurrent_Nets_CVPR_2016_paper.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Reducing Redundant Computations with Flexible Attention.
  <a href="https://arxiv.org/pdf/1612.06043.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Scan, Attend and Read- End-to-End Handwritten Paragraph Recognition with MDLSTM Attention.
  <a href="https://arxiv.org/pdf/1604.03286.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Structural Attention Neural Networks for improved sentiment analysis.
  <a href="https://arxiv.org/pdf/1701.01811.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Survey on the attention based RNN model and its applications in computer vision.
  <a href="https://arxiv.org/pdf/1601.06823.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h3>
 Generative learning
</h3>
<ul>
 <li>
  Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics.
  <a href="https://arxiv.org/pdf/1612.07767.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Adversarial examples in the physical world.
  <a href="https://arxiv.org/pdf/1607.02533.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Adversarially Learned Inference.
  <a href="https://arxiv.org/pdf/1606.00704.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/IshmaelBelghazi/ALI">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Adversarial Multiclass Classification: A Risk Minimization Perspective.
  <a href="https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/rizalzaf/adversarial-multiclass">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Adversarial Perturbations Against Deep Neural Networks for Malware Classification.
  <a href="https://arxiv.org/pdf/1606.04435.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Adversarial Training For Sketch Retrieval.
  <a href="https://arxiv.org/pdf/1607.02748.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A Point Set Generation Network for 3D Object Reconstruction from a Single Image.
  <a href="https://arxiv.org/pdf/1612.00603.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/fanhqme/PointSetGeneration">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Automatic Description Generation from Images- A Survey of Models, Datasets, and Evaluation Measures.
  <a href="https://www.jair.org/media/4900/live-4900-9139-jair.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Automatic Colorization with Deep Convolutional Generative Adversarial Networks.
  <a href="http://cs231n.stanford.edu/reports2016/224_Report.pdf">
   <code>
    stanford
   </code>
  </a>
 </li>
 <li>
  Auxiliary Deep Generative Models.
  <a href="https://arxiv.org/pdf/1602.05473.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/larsmaaloee/auxiliary-deep-generative-models">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [b-GAN]
  </b>
  Unified Framework of Generative Adversarial Networks.
  <a href="https://openreview.net/pdf?id=S1JG13oee">
   <code>
    pdf
   </code>
  </a>
  ] :star:
 </li>
 <li>
  Conditional Image Synthesis With Auxiliary Classifier GANs.
  <a href="https://arxiv.org/pdf/1610.09585.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/lukedeo/keras-acgan">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Connecting Generative Adversarial Networks and Actor-Critic Methods.
  <a href="https://arxiv.org/pdf/1610.01945.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Coupled Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1606.07536.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mingyuliutw/CoGAN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  DARN: a Deep Adversial Residual Network for Intrinsic Image Decomposition.
  <a href="https://128.84.21.199/abs/1612.07899?context=cs">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  DeMIAN: Deep Modality Invariant Adversarial Network. [
  <a href="http://www.mathpubs.com/detail/1612.07976v1/DeMIAN-Deep-Modality-Invariant-Adversarial-Network">
   url
  </a>
  ]
 </li>
 <li>
  Deep Learning Adversarial Examples.
  <a href="http://www.kdnuggets.com/2015/07/deep-learning-adversarial-examples-misconceptions.html">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  DeepFace: Face Generation using Deep Learning.
  <a href="http://cs231n.stanford.edu/reports2016/006_Report.pdf">
   <code>
    stanford
   </code>
  </a>
 </li>
 <li>
  Enabling Dark Energy Science with Deep Generative Models of Galaxy Images.
  <a href="https://arxiv.org/pdf/1609.05796.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [EnergyGAN]
  </b>
  Energy-based Generative Adversarial Network.
  <a href="https://arxiv.org/pdf/1609.03126">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/buriburisuri/ebgan">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [f-GAN]
  </b>
  f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization.
  <a href="https://arxiv.org/pdf/1606.00709.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Generative Image Modeling using Style and Structure Adversarial Networks.
  <a href="https://arxiv.org/pdf/1603.05631.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Generating Images Part by Part with Composite Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1607.05387.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [GRAN]
  </b>
  Generating images with recurrent adversarial networks.
  <a href="https://pdfs.semanticscholar.org/c98e/9b2922a76b3cb3c3e8cfcda93c09c31ec5e6.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Generating Images with Perceptual Similarity Metrics based on Deep Networks.
  <a href="https://arxiv.org/pdf/1602.02644.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Generative Adversarial Imitation Learning.
  <a href="https://arxiv.org/pdf/1606.03476.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/openai/imitation">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  <b>
   [VGNA]
  </b>
  Generative Adversarial Networks as Variational Training of Energy Based Models.
  <a href="https://arxiv.org/pdf/1611.01799.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/Shuangfei/vgan">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Generative Adversarial Nets from a Density Ratio Estimation Perspective.
  <a href="https://arxiv.org/pdf/1610.02920.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [iGNA]
  </b>
  Generative Visual Manipulation on the Natural Image Manifold.
  <a href="http://people.eecs.berkeley.edu/~junyanz/projects/gvm/">
   <code>
    berkeley
   </code>
  </a>
  <a href="https://github.com/junyanz/iGAN">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Generating Videos with Scene Dynamics.
  <a href="http://web.mit.edu/vondrick/tinyvideo/paper.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/cvondrick/videogan">
   <code>
    code
   </code>
  </a>
  <a href="https://github.com/Yuliang-Zou/tf_videogan">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  How to Train a GAN.
  <a href="https://github.com/soumith/ganhacks">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Pix2Pix]
  </b>
  Image-to-Image Translation with Conditional Adversarial Networks.
  <a href="https://arxiv.org/pdf/1611.07004.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/yenchenlin/pix2pix-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Improved GAN]
  </b>
  Image-Text Multi-Modal Representation Learning by Adversarial Backpropagation.
  <a href="https://arxiv.org/pdf/1612.08354.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <a href="http://blog.csdn.net/layumi1993/article/details/52413235">
   Improved Techniques for Training GANs.
  </a>
  <a href="https://arxiv.org/pdf/1606.03498.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/openai/improved-gan">
   <code>
    code
   </code>
  </a>
  <a href="https://github.com/shaohua0116/SSGAN-Tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [InfoGAN]
  </b>
  <a href="http://blog.csdn.net/Layumi1993/article/details/52474554">
   Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.
  </a>
  <a href="https://arxiv.org/pdf/1606.03657.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/InfoGAN">
   <code>
    code
   </code>
  </a>
  <a href="https://github.com/buriburisuri/supervised_infogan">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling.
  <a href="https://arxiv.org/pdf/1610.07584.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/meetshah1995/tf-3dgan">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  <b>
   [SimGAN]
  </b>
  Learning from Simulated and Unsupervised Images through Adversarial Training.
  <a href="https://arxiv.org/pdf/1612.07828.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/wayaai/SimGAN">
   <code>
    keras
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning in Implicit Generative Models.
  <a href="https://arxiv.org/pdf/1610.03483.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning to Protect Communications with Adversarial Neural Cryptography.
  <a href="https://arxiv.org/pdf/1610.06918.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Least Squares Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1611.04076.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Medical Image Synthesis with Context-Aware Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1612.05362.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Mode Regularized Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1612.02136.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Neural Fill: Content Aware Image Fill with Generative Adversarial Neural Networks.
  <a href="http://cs231n.stanford.edu/reports2016/209_Report.pdf">
   <code>
    stanford
   </code>
  </a>
 </li>
 <li>
  NIPS 2016 Tutorial: Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1701.00160.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [SRGAN]
  </b>
  Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.
  <a href="https://arxiv.org/pdf/1609.04802.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [DCGAN use]
  </b>
  Semantic Image Inpainting with Perceptual and Contextual Losses.
  <a href="https://arxiv.org/pdf/1607.07539.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Semi-Supervised Learning with Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1606.01583.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [SeqGAN]
  </b>
  Sequence Generative Adversarial Nets with Policy Gradient.
  <a href="https://arxiv.org/pdf/1609.05473.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/LantaoYu/SeqGAN">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Simple black-box adversarial perturbations for deep networks.
  <a href="https://openreview.net/pdf?id=SJCscQcge">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Stick-Breaking Variational Autoencoders.
  <a href="https://arxiv.org/pdf/1605.06197.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/enalisnick/stick-breaking_dgms">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Stochastic Video Prediction with Deep Conditional Generative Models.
  <a href="http://cs231n.stanford.edu/reports2016/215_Report.pdf">
   <code>
    stanford
   </code>
  </a>
 </li>
 <li>
  Task Specific Adversarial Cost Function.
  <a href="https://arxiv.org/pdf/1609.08661.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Temporal Generative Adversarial Nets with Singular Value Clipping.
  <a href="https://arxiv.org/pdf/1611.06624.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/pfnet-research/tgan">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Towards Principled Methods for Training Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1701.04862.pdf">
   <code>
    arxiv
   </code>
  </a>
  ]
 </li>
 <li>
  <a href="https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/">
   Understanding deep learning requires rethinking generalization.
  </a>
  <a href="https://arxiv.org/pdf/1611.03530.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Unsupervised domain adaptation in brain lesion segmentation with adversarial networks.
  <a href="https://arxiv.org/pdf/1612.08894.pdfv1">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/Kamnitsask/deepmedic">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Unrolled Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1611.02163.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/poolio/unrolled_gan">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Variational Graph Auto-Encoders.
  <a href="https://arxiv.org/pdf/1611.07308.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tkipf/gae">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
</ul>
<h3>
 Transfer learning
</h3>
<ul>
 <li>
  A survey of transfer learning.
  <a href="https://link.springer.com/article/10.1186/s40537-016-0043-6">
   <code>
    url
   </code>
  </a>
  :star:
 </li>
 <li>
  Building Machines That Learn and Think Like People.
  <a href="https://arxiv.org/pdf/1604.00289.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Fast color transfer from multiple images.
  <a href="https://arxiv.org/pdf/1612.08927.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Perceptual Losses for Real-Time Style Transfer and Super-Resolution.
  <a href="https://arxiv.org/pdf/1603.08155.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/jcjohnson/fast-neural-style">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Personalizing a Dialogue System with Transfer Learning.
  <a href="https://arxiv.org/pdf/1610.02891.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Pixel-Level Domain Transfer.
  <a href="https://arxiv.org/pdf/1603.07442.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <a href="http://www.cnblogs.com/wangxiaocvpr/p/6002214.html">
   Progressive Neural Networks.
  </a>
  <a href="https://arxiv.org/pdf/1606.04671.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.
  <a href="https://arxiv.org/pdf/1603.01768.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/alexjc/neural-doodle">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Best Paper]
  </b>
  Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data.
  <a href="https://arxiv.org/pdf/1610.05755.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/differential_privacy/multiple_teachers">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  FastMask: Segment Multi-scale Object Candidates in One Shot.
  <a href="https://arxiv.org/pdf/1612.08843.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning feed-forward one-shot learners.
  <a href="https://arxiv.org/pdf/1606.05233.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Low-shot Visual Recognition by Shrinking and Hallucinating Features.
  <a href="https://arxiv.org/pdf/1606.02819.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Matching Networks for One Shot Learning.
  <a href="https://arxiv.org/pdf/1606.04080.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  One-Shot Generalization in Deep Generative Models.
  <a href="https://arxiv.org/pdf/1603.05106.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  One-shot Learning with Memory-Augmented Neural Networks.
  <a href="https://arxiv.org/pdf/1605.06065.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/hmishra2250/NTM-One-Shot-TF">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  One-Shot Video Object Segmentation.
  <a href="https://arxiv.org/pdf/1611.05198.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/scaelles/OSVOS-TensorFlow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Tinkering Under the Hood: Interactive Zero-Shot Learning with Net Surgery.
  <a href="https://arxiv.org/pdf/1612.04901.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
