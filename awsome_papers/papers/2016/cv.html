<h2>
 Computer vision
</h2>
<ul>
 <li>
  Accurate Image Super-Resolution Using Very Deep Convolutional Networks.
  <a href="https://arxiv.org/pdf/1511.04587.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Action Recognition Based on Joint Trajectory Maps Using Convolutional Neural Networks.
  <a href="https://arxiv.org/pdf/1611.02447.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Adult Content Recognition from Images Using a Mixture of Convolutional Neural Networks.
  <a href="https://arxiv.org/pdf/1612.09506.pdf?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Asynchronous Temporal Fields for Action Recognition.
  <a href="https://arxiv.org/pdf/1612.06371.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/gsig/temporal-fields/">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Automatic Portrait Segmentation for Image Stylization.
  <a href="http://www.cse.cuhk.edu.hk/leojia/papers/portrait_eg16.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/PetroWu/AutoPortraitMatting">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection.
  <a href="https://arxiv.org/pdf/1606.05413.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Colorful Image Colorization.
  <a href="https://arxiv.org/pdf/1603.08511.pdfv1">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/nilboy/colorization-tf">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [PCNN]
  </b>
  Conditional Image Generation with PixelCNN Decoders.
  <a href="https://arxiv.org/pdf/1606.05328.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kundan2510/pixelCNN">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  DA-RNN: Semantic Mapping with Data Associated Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1703.03098.pdf">
   <code>
    arXiv
   </code>
  </a>
  <a href="https://github.com/yuxng/DA-RNN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  <b>
   [Use VGG19]
  </b>
  Deep Feature Interpolation for Image Content Changes.
  <a href="https://arxiv.org/pdf/1611.05507.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/slang03/dfi-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs.
  <a href="https://arxiv.org/pdf/1606.00915.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep Learning Logo Detection with Data Expansion by Synthesising Context.
  <a href="https://arxiv.org/pdf/1612.09322.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deep Learning on Lie Groups for Skeleton-based Action Recognition.
  <a href="https://arxiv.org/pdf/1612.05877.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Differential Geometry Boosts Convolutional Neural Networks for Object Detection.
  <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Efficient Action Detection in Untrimmed Videos via Multi-Task Learning.
  <a href="https://arxiv.org/pdf/1612.07403.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation.
  <a href="https://arxiv.org/pdf/1606.02147.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kwotsin/TensorFlow-ENet">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  <b>
   [EnhanceNet]
  </b>
  EnhanceNet: Single Image Super-Resolution through Automated Texture Synthesis.
  <a href="https://arxiv.org/pdf/1612.07919.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Factorized Bilinear Models for Image Recognition.
  <a href="https://arxiv.org/pdf/1611.05709.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/lyttonhao/Factorized-Bilinear-Network">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Feature Pyramid Networks for Object Detection.
  <a href="https://arxiv.org/pdf/1612.03144.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/xmyqsh/FPN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Finding Tiny Faces.
  <a href="https://arxiv.org/pdf/1612.04402.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com//cydonia999/Tiny_Faces_in_Tensorflow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Fully Convolutional Networks for Semantic Segmentation.
  <a href="https://arxiv.org/pdf/1605.06211.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Fully-Convolutional Siamese Networks for Object Tracking.
  <a href="https://arxiv.org/pdf/1606.09549.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/torrvision/siamfc-tf">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Full Resolution Image Compression with Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1608.05148.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/compression">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization.
  <a href="https://arxiv.org/pdf/1610.02391.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/Ankush96/grad-cam.tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Hardware for Machine Learning: Challenges and Opportunities.
  <a href="https://arxiv.org/pdf/1612.07625.pdf?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%253A+arxiv%252Fcs%252FCV+%2528ArXiv.cs.CV%2529">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Inception Recurrent Convolutional Neural Network for Object Recognition.
  <a href="https://arxiv.org/pdf/1704.07709.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [Inception-V4]
  </b>
  Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.
  <a href="https://arxiv.org/pdf/1602.07261.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Internet-Based Image Retrieval Using End-to-End Trained Deep Distributions.
  <a href="https://arxiv.org/pdf/1612.07697.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning Non-Lambertian Object Intrinsics across ShapeNet Categories.
  <a href="https://arxiv.org/pdf/1612.08510.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning Residual Images for Face Attribute Manipulation.
  <a href="https://arxiv.org/pdf/1612.05363.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Maxmin convolutional neural networks for image classification.
  <a href="https://arxiv.org/pdf/1610.07882.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Movie Description.
  <a href="https://arxiv.org/pdf/1605.03705.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  OctNet: Learning Deep 3D Representations at High Resolutions.
  <a href="https://arxiv.org/pdf/1611.05009.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/griegler/octnet">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Multivariate LSTM-FCNs for Time Series Classification.
  <a href="https://arxiv.org/pdf/1611.05198.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kmaninis/OSVOS-PyTorch">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  <b>
   [PRNN]
  </b>
  Pixel Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1601.06759.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space.
  <a href="https://arxiv.org/pdf/1612.00005.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks.
  <a href="https://arxiv.org/pdf/1612.07429.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  PVANet: Lightweight Deep Neural Networks for Real-time Object Detection.
  <a href="https://arxiv.org/pdf/1611.08588.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/sanghoon/pva-faster-rcnn">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields.
  <a href="https://arxiv.org/pdf/1611.08050.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com//last-one/Pytorch_Realtime_Multi-Person_Pose_Estimation">
   <code>
    pytorch
   </code>
  </a>
 </li>
 <li>
  Richer Convolutional Features for Edge Detection.
  <a href="https://arxiv.org/pdf/1612.02103.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/yun-liu/rcf">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  <b>
   [R-FCN]
  </b>
  <a href="http://blog.csdn.net/u012361214/article/details/51507590">
   R-FCN: Object Detection via Region-based Fully Convolutional Networks
  </a>
  .
  <a href="https://arxiv.org/pdf/1605.06409.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/Orpine/py-R-FCN">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Robust LSTM-Autoencoders for Face De-Occlusion in the Wild.
  <a href="https://arxiv.org/pdf/1612.08534.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Semantic Video Segmentation by Gated Recurrent Flow Propagation.
  <a href="https://arxiv.org/pdf/1612.08871.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Shape Completion using 3D-Encoder-Predictor CNNs and Shape Synthesis.
  <a href="https://arxiv.org/pdf/1612.00101.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/angeladai/cnncomplete">
   <code>
    torch
   </code>
  </a>
  :star:
 </li>
 <li>
  Spatially Adaptive Computation Time for Residual Networks.
  <a href="https://arxiv.org/pdf/1612.02297.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mfigurnov/sact">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  <b>
   [SqueezeNet]
  </b>
  <a href="http://blog.csdn.net/human_recognition/article/details/51902285">
   SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size.
  </a>
  <a href="https://arxiv.org/pdf/1602.07360.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/songhan/SqueezeNet-Deep-Compression">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge.
  <a href="http://arxiv.org/abs/1609.06647">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/im2txt">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  sk_p- a neural program corrector for MOOCs.
  <a href="http://dl.acm.org/citation.cfm?id=2989222">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Stacked Hourglass Networks for Human Pose Estimation.
  <a href="https://arxiv.org/pdf/1603.06937.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/anewell/pose-hg-train">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  The Predictron: End-To-End Learning and Planning.
  <a href="https://arxiv.org/pdf/1612.08810.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/zhongwen/predictron">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Unsupervised Cross-Domain Image Generation.
  <a href="https://arxiv.org/pdf/1611.02200.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/yunjey/dtn-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Unsupervised Learning for Physical Interaction through Video Prediction.
  <a href="https://arxiv.org/pdf/1605.07157.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/video_prediction">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.
  <a href="https://arxiv.org/pdf/1603.09246.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Video Pixel Networks.
  <a href="https://arxiv.org/pdf/1610.00527.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Visual Genome-Connecting Language and Vision Using Crowdsourced Dense Image Annotations.
  <a href="https://arxiv.org/pdf/1602.07332.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [WaveNet]
  </b>
  WaveNet- A Generative Model For Raw Audio.
  <a href="https://arxiv.org/pdf/1609.03499.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  YOLO9000: Better, Faster, Stronger.
  <a href="https://arxiv.org/pdf/1612.08242.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/allanzelener/YAD2K">
   <code>
    keras
   </code>
  </a>
  :star:
 </li>
</ul>
