<h1>
 Deep Learning
</h1>
<ul>
 <li>
  A First Look at the Crypto-Mining Malware Ecosystem: A Decade of Unrestricted Wealth.
  <a href="https://arxiv.org/pdf/1901.00846.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A Gentle Introduction to Deep Learning for Graphs.
  <a href="https://arxiv.org/pdf/1912.12693.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty.
  <a href="https://arxiv.org/pdf/1912.02781.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/google-research/augmix">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  diffGrad: An Optimization Method for Convolutional Neural Networks.
  <a href="https://arxiv.org/pdf/1909.11015.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/lessw2020/Best-Deep-Learning-Optimizers">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation Function for Neural Networks.
  <a href="https://arxiv.org/pdf/1901.05894.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  One-Class Convolutional Neural Network.
  <a href="https://arxiv.org/pdf/1901.08688.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  On the effect of the activation function on the distribution of hidden nodes in a deep network.
  <a href="https://arxiv.org/pdf/1901.02104.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  TactileGCN: A Graph Convolutional Network for Predicting Grasp Stability with Tactile Sensors.
  <a href="https://arxiv.org/pdf/1901.06181.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h2>
 Attention
</h2>
<ul>
 <li>
  Attentive Neural Processes.
  <a href="https://arxiv.org/pdf/1901.05761.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  FAN: Focused Attention Networks.
  <a href="https://arxiv.org/pdf/1905.11498.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h2>
 Auto ML
</h2>
<ul>
 <li>
  A Unified Stochastic Gradient Approach to Designing Bayesian-Optimal Experiments.
  <a href="https://arxiv.org/pdf/1911.00294.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Combinatorial Bayesian Optimization using the Graph Cartesian Product.
  <a href="https://arxiv.org/pdf/1902.00448.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/QUVA-Lab/COMBO">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  EAT-NAS: Elastic Architecture Transfer for Accelerating Large-scale Neural Architecture Search.
  <a href="https://arxiv.org/pdf/1901.05884.pdfv1">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h2>
 Transfer Learning
</h2>
<ul>
 <li>
  Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer Learning.
  <a href="https://arxiv.org/pdf/1905.13628.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails.
  <a href="https://arxiv.org/pdf/1901.05599.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
