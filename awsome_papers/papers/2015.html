<h2>
 2015
</h2>
<h3>
 Deep Learning
</h3>
<ul>
 <li>
  <b>
   [ADAM]
  </b>
  A Method for Stochastic Optimization.
  <a href="https://arxiv.org/pdf/1412.6980.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  A Diversity-Promoting Objective Function for Neural Conversation Models.
  <a href="http://www.aclweb.org/anthology/N16-1014">
   <code>
    acl
   </code>
  </a>
  ]
 </li>
 <li>
  A Neural Conversational Model.
  <a href="https://arxiv.org/pdf/1506.05869.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A Neural Network Approach to Context-Sensitive Generation of Conversational Responses.
  <a href="http://www-etud.iro.umontreal.ca/~sordonia/pdf/naacl15.pdf">
   <code>
    acl
   </code>
  </a>
 </li>
 <li>
  A Roadmap towards Machine Intelligence.
  <a href="https://arxiv.org/pdf/1511.08130.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A Survey- Time Travel in Deep Learning Space- An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas.
  <a href="https://arxiv.org/pdf/1510.04781.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  An Empirical Exploration of Recurrent Network Architectures.
  <a href="http://proceedings.mlr.press/v37/jozefowicz15.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Inception V2]
  </b>
  <a href="http://blog.csdn.net/happynear/article/details/44238541">
   Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift.
  </a>
  <a href="https://arxiv.org/pdf/1502.03167.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.
  <a href="https://arxiv.org/pdf/1507.04808.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Correlational Neural Networks.
  <a href="https://arxiv.org/pdf/1504.07225.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/GauravBh1010tt/DeepLearn/tree/master/corrnet">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Deconstructing the Ladder Network Architecture.
  <a href="https://arxiv.org/pdf/1511.06430.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding.
  <a href="https://arxiv.org/pdf/1510.00149.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deep Knowledge Tracing.
  <a href="https://web.stanford.edu/~cpiech/bio/papers/deepKnowledgeTracing.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Deep learning.
  <a href="http://www.nature.com/nature/journal/v521/n7553/abs/nature14539.html">
   <code>
    nature
   </code>
  </a>
  :star:
 </li>
 <li>
  Distilling the Knowledge in a Neural Network.
  <a href="https://www.cs.toronto.edu/~hinton/absps/distillation.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Dropout as a Bayesian Approximation- Representing Model Uncertainty in Deep Learning.
  <a href="https://arxiv.org/pdf/1506.02142">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Effective LSTMs for Target-Dependent Sentiment Classification.
  <a href="https://arxiv.org/pdf/1512.01100.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [ELUs]
  </b>
  Fast and Accurate Deep Network Learning by Exponential Linear Units.
  <a href="https://arxiv.org/pdf/1511.07289.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Human-level concept learning through probabilistic program induction
  <a href="http://science.sciencemag.org/content/350/6266/1332">
   <code>
    science
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning Simple Algorithms from Examples.
  <a href="http://proceedings.mlr.press/v48/zaremba16.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Learning to Transduce with Unbounded Memory.
  <a href="https://arxiv.org/pdf/1506.02516.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Listen, Attend and Spell.
  <a href="https://arxiv.org/pdf/1508.01211.pdfv2">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/XenderLiu/Listen-Attend-and-Spell-Pytorch">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  LSTM A Search Space Odyssey.
  <a href="https://arxiv.org/pdf/1503.04069.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  LSTM-based Deep Learning Models for non-factoid answer selection.
  <a href="https://arxiv.org/pdf/1511.04108.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Neural GPUs Learn Algorithms.
  <a href="https://arxiv.org/pdf/1511.08228.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/neural_gpu">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Neural Programmer- Inducing Latent Programs with Gradient Descent.
  <a href="https://people.cs.umass.edu/~arvind/np.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Pointer Networks.
  <a href="https://arxiv.org/pdf/1506.03134.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/devsisters/pointer-network-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Poker-CNN- A Pattern Learning Strategy for Making Draws and Bets in Poker Games.
  <a href="http://colinraffel.com/publications/aaai2016poker.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Policy distillation.
  <a href="https://arxiv.org/pdf/1511.06295.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Regularizing RNNs by Stabilizing Activations.
  <a href="https://arxiv.org/pdf/1511.08400.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  ReNet- A Recurrent Neural Network Based Alternative to Convolutional Networks.
  <a href="https://arxiv.org/pdf/1505.00393.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Semi-Supervised Learning with Ladder Networks.
  <a href="https://arxiv.org/pdf/1507.02672.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Session-based Recommendations with Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1511.06939.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Skip-Thought Vectors.
  <a href="https://arxiv.org/pdf/1506.06726.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Training Very Deep Networks.
  <a href="https://arxiv.org/pdf/1507.06228.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Tree-structured composition in neural networks without tree-structured architectures.
  <a href="http://ceur-ws.org/Vol-1583/CoCoNIPS_2015_paper_5.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
</ul>
<h3>
 Computer vision
</h3>
<ul>
 <li>
  A Neural Algorithm of Artistic Style.
  <a href="https://arxiv.org/pdf/1508.06576.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/titu1994/Neural-Style-Transfer">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Autoencoding beyond pixels using a learned similarity metric.
  <a href="https://arxiv.org/pdf/1512.09300.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/zhangqianhui/vae-gan-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images.
  <a href="https://arxiv.org/pdf/1506.07365.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/ethanluoyc/e2c-pytorch">
   <code>
    pytorch
   </code>
  </a>
 </li>
 <li>
  <b>
   [ResNet]
  </b>
  <a href="http://blog.csdn.net/cv_family_z/article/details/50328175">
   Deep Residual Learning for Image Recognition
  </a>
  .
  <a href="https://arxiv.org/pdf/1512.03385.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/resnet">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [ResNet]
  </b>
  Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification.
  <a href="https://arxiv.org/pdf/1502.01852.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [FaceNet]
  </b>
  <a href="http://blog.csdn.net/chenriwei2/article/details/45031677">
   A Unified Embedding for Face Recognition and Clustering.
  </a>
  <a href="https://arxiv.org/pdf/1503.03832.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/davidsandberg/facenet">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Faster R-CNN]
  </b>
  Towards Real-Time Object Detection with Region Proposal Networks.
  <a href="https://arxiv.org/pdf/1506.01497.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/rbgirshick/py-faster-rcnn">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Fast R-CNN]
  </b>
  <a href="http://lib.csdn.net/article/deeplearning/53862?knId=1734">
   Fast R-CNN
  </a>
  <a href="https://arxiv.org/pdf/1504.08083.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/rbgirshick/fast-rcnn">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition.
  <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Inceptionism: Going Deeper into Neural Networks.
  <a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">
   <code>
    google
   </code>
  </a>
  :star:
 </li>
 <li>
  Inside-Outside Net- Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks.
  <a href="http://image-net.org/challenges/talks/ion-coco-talk-bell2015.pdf">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Multi-view 3D Models from Single Images with a Convolutional Network.
  <a href="https://arxiv.org/pdf/1511.06702.pdfv2">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/mtatarchenko/mv3d">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  ReSeg- A Recurrent Neural Network for Object Segmentation.
  <a href="https://arxiv.org/pdf/1511.07053.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Inception V3]
  </b>
  Rethinking the Inception Architecture for Computer Vision.
  <a href="https://arxiv.org/pdf/1512.00567.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/inception">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Unsupervised Learning of Video Representations using LSTMs.
  <a href="https://arxiv.org/pdf/1502.04681.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/iwyoo/LSTM-autoencoder">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [FCNT]
  </b>
  Visual Tracking with fully Convolutional Networks.
  <a href="http://www.ee.cuhk.edu.hk/~xgwang/papers/wangOWLiccv15.pdf">
   <code>
    cuhk
   </code>
  </a>
  <a href="https://github.com/scott89/FCNT">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  You Only Look Once: Unified, Real-Time Object Detection.
  <a href="https://arxiv.org/pdf/1506.02640.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h3>
 Generative learning
</h3>
<ul>
 <li>
  Adversarial Autoencoders.
  <a href="https://arxiv.org/pdf/1511.05644.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  A note on the evaluation of generative models.
  <a href="https://arxiv.org/pdf/1511.01844.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Autoencoding beyond pixels using a learned similarity metric.
  <a href="https://arxiv.org/pdf/1512.09300.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Censoring Representations with an Adversary.
  <a href="https://arxiv.org/pdf/1511.05897.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Conditional generative adversarial nets for convolutional face generation.
  <a href="http://www.foldl.me/uploads/2015/conditional-gans-face-generation/paper.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  <b>
   [LAPGAN]
  </b>
  <a href="http://blog.csdn.net/solomon1558/article/details/52562851">
   Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks
  </a>
  <a href="https://arxiv.org/pdf/1506.05751.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/facebook/eyescream">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Distributional Smoothing with Virtual Adversarial Training.
  <a href="https://arxiv.org/pdf/1507.00677.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Exploring the Space of Adversarial Images.
  <a href="https://arxiv.org/pdf/1510.05328.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tabacof/adversarial">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Generative Adversarial Networks in Estimation of Distribution Algorithms for Combinatorial Optimization.
  <a href="https://arxiv.org/pdf/1509.09235.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/wohnjayne/eda-suite">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Generative Image Modeling Using Spatial LSTMs.
  <a href="https://arxiv.org/pdf/1506.03478.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Generative Moment Matching Networks.
  <a href="https://arxiv.org/pdf/1502.02761.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Improving Semi-Supervised Learning with Auxiliary Deep Generative Models.
  <a href="http://approximateinference.org/2015/accepted/MaaloeEtAl2015.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  <b>
   [CVAE]
  </b>
  Learning Structured Output Representation using Deep Conditional Generative Models.
  <a href="https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models">
   <code>
    nips
   </code>
  </a>
  :star:
 </li>
 <li>
  Max-margin Deep Generative Models.
  <a href="https://arxiv.org/pdf/1504.06787.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/zhenxuan00/mmdgm">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Semi-Supervised Learning with Ladder Networks.
  <a href="https://arxiv.org/pdf/1507.02672.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [CatGAN]
  </b>
  Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks.
  <a href="https://arxiv.org/pdf/1511.06390.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [DCGAN]
  </b>
  <a href="http://blog.csdn.net/solomon1558/article/details/52573596">
   Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks
  </a>
  .
  <a href="https://arxiv.org/pdf/1511.06434.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/carpedm20/DCGAN-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
</ul>
<h3>
 Attention and memory
</h3>
<ul>
 <li>
  <b>
   [ABCNN]
  </b>
  Attention-Based Convolutional Neural Network for Modeling Sentence Pairs.
  <a href="https://arxiv.org/pdf/1512.05193.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Action Recognition using Visual Attention.
  <a href="https://arxiv.org/pdf/1511.04119.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kracwarlock/action-recognition-visual-attention">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Ask Me Anything- Dynamic Memory Networks for Natural Language Processing.
  <a href="https://arxiv.org/pdf/1506.07285.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Attention-Based Models for Speech Recognition.
  <a href="https://arxiv.org/pdf/1506.07503.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Attention with Intention for a Neural Network Conversation Model.
  <a href="https://arxiv.org/pdf/1510.08565.pdf">
   <code>
    arxiv
   </code>
  </a>
  ]
 </li>
 <li>
  <b>
   [VAE with attention]
  </b>
  A Recurrent Neural Network For Image Generation.
  <a href="https://arxiv.org/pdf/1502.04623.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/ericjang/draw">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Show, Attend and Tell- Neural Image Caption Generation with Visual Attention.
  <a href="https://arxiv.org/pdf/1502.03044.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation.
  <a href="https://arxiv.org/pdf/1512.04650.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.
  <a href="https://arxiv.org/pdf/1506.07285.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  A Neural Attention Model for Sentence Summarization.
  <a href="https://www.aclweb.org/anthology/D/D15/D15-1044.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Global And Local Attention]
  </b>
  <a href="http://blog.csdn.net/u011414416/article/details/51057789">
   Effective Approaches to Attention-based Neural Machine Translation.
  </a>
  <a href="https://arxiv.org/pdf/1508.04025.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/lmthang/nmt.matlab">
   <code>
    code
   </code>
  </a>
  <a href="https://github.com/giancds/tsf_nmt">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  End-to-End Attention-based Large Vocabulary Speech Recognition.
  <a href="https://arxiv.org/pdf/1508.04395.pdf">
   <code>
    arxiv.
   </code>
  </a>
 </li>
 <li>
  End-To-End Memory Networks.
  <a href="https://arxiv.org/pdf/1503.08895.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Grammar as a Foreign Language.
  <a href="https://arxiv.org/pdf/1412.7449.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Large-scale Simple Question Answering with Memory Networks.
  <a href="https://arxiv.org/pdf/1506.02075.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Learning Deep Neural Network Policies with Continuous Memory States.
  <a href="http://arxiv.org/abs/1507.01273">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  <b>
   [LAS]
  </b>
  Listen, Attend and Spell.
  <a href="https://arxiv.org/pdf/1508.01211.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences.
  <a href="http://arxiv.org/abs/1506.04089">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Memory-based control with recurrent neural networks.
  <a href="http://arxiv.org/abs/1512.04455">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Not All Contexts Are Created Equal: Better Word Representations with Variable Attention.
  <a href="https://www.cs.cmu.edu/~lingwang/papers/emnlp2015-2.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Reinforcement Learning Neural Turing Machines.
  <a href="https://arxiv.org/pdf/1505.00521.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [Soft And Hard Attention]
  </b>
  Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.
  <a href="https://arxiv.org/pdf/1502.03044.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/kelvinxu/arctic-captions">
   <code>
    code
   </code>
  </a>
  <a href="https://github.com/yunjey/show-attend-and-tell-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Teaching Machines to Read and Comprehend.
  <a href="https://arxiv.org/pdf/1506.03340.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Video Description Generation Incorporating Spatio-Temporal Features and a Soft-Attention Mechanism.
  <a href="https://128.84.21.199/abs/1502.08029v1">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h3>
 Transfer learning
</h3>
<ul>
 <li>
  Heterogeneous defect prediction.
  <a href="http://www.cs.ust.hk/~hunkim/papers/nam-HDP-fse2015.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Learning Transferred Weights From Co-Occurrence Data for Heterogeneous Transfer Learning.
  <a href="http://ieeexplore.ieee.org/document/7243354/">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Net2Net-Accelerating Learning via Knowledge Transfer.
  <a href="https://arxiv.org/pdf/1511.05641.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Siamese Neural Networks for One-shot Image Recognition.
  <a href="http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  <a href="http://blog.csdn.net/shaoxiaohu1/article/details/51809605">
   Spatial Transformer Networks.
  </a>
  <a href="https://arxiv.org/pdf/1506.02025.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/tensorflow/models/tree/master/transformer">
   <code>
    tensorflow
   </code>
  </a>
  :star:
 </li>
 <li>
  Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping.
  <a href="https://arxiv.org/pdf/1510.00098.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Transfer learning using computational intelligence: A survey.
  <a href="https://pdfs.semanticscholar.org/21bb/ec954226c5fdf53560cb072188a18051683c.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Transfer learning used to analyze the dynamic evolution of the dust aerosol.
  <a href="https://www.researchgate.net/publication/272403336_Transfer_learning_used_to_analyze_the_dynamic_evolution_of_the_dust_aerosol">
   <code>
    url
   </code>
  </a>
 </li>
 <li>
  Transferring Rich Feature Hierarchies for Robust Visual Tracking.
  <a href="https://arxiv.org/pdf/1501.04587.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
</ul>
<h3>
 Deep reinforcement learning
</h3>
<ul>
 <li>
  ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources.
  <a href="http://arxiv.org/abs/1510.02879">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Action-Conditional Video Prediction using Deep Networks in Atari Games.
  <a href="http://arxiv.org/abs/1507.08750">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning.
  <a href="https://arxiv.org/pdf/1511.06342.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [DDPG]
  </b>
  Continuous control with deep reinforcement learning.
  <a href="https://arxiv.org/pdf/1509.02971.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  <b>
   [NAF]
  </b>
  Continuous Deep Q-Learning with Model-based Acceleration.
  <a href="https://arxiv.org/pdf/1603.00748.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Dueling Network Architectures for Deep Reinforcement Learning.
  <a href="http://arxiv.org/abs/1511.06581">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep Reinforcement Learning with an Action Space Defined by Natural Language.
  <a href="http://arxiv.org/abs/1511.04636">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Deep Reinforcement Learning with Double Q-learning.
  <a href="http://arxiv.org/abs/1509.06461">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Deep Recurrent Q-Learning for Partially Observable MDPs.
  <a href="http://arxiv.org/abs/1507.06527">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  DeepMPC: Learning Deep Latent Features for Model Predictive Control.
  <a href="http://deepmpc.cs.cornell.edu/DeepMPC.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Deterministic Policy Gradient Algorithms.
  <a href="http://jmlr.org/proceedings/papers/v32/silver14.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Dueling Network Architectures for Deep Reinforcement Learning.
  <a href="https://arxiv.org/pdf/1511.06581.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  End-to-End Training of Deep Visuomotor Policies.
  <a href="http://arxiv.org/abs/1504.00702">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Giraffe: Using Deep Reinforcement Learning to Play Chess.
  <a href="http://arxiv.org/abs/1509.01549">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Generating Text with Deep Reinforcement Learning.
  <a href="http://arxiv.org/abs/1510.09202">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies.
  <a href="http://arxiv.org/abs/1512.02011">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Human-level control through deep reinforcement learning.
  <a href="http://www.nature.com/nature/journal/v518/n7540/pdf/nature14236.pdf">
   <code>
    nature
   </code>
  </a>
  :star:
 </li>
 <li>
  Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models.
  <a href="http://arxiv.org/abs/1507.00814">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning Simple Algorithms from Examples.
  <a href="http://arxiv.org/abs/1511.07275">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Language Understanding for Text-based Games Using Deep Reinforcement Learning.
  <a href="http://people.csail.mit.edu/karthikn/pdfs/mud-play15.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Learning Continuous Control Policies by Stochastic Value Gradients.
  <a href="http://papers.nips.cc/paper/5796-learning-continuous-control-policies-by-stochastic-value-gradients.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Multiagent Cooperation and Competition with Deep Reinforcement Learning.
  <a href="http://arxiv.org/abs/1511.08779">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Maximum Entropy Deep Inverse Reinforcement Learning.
  <a href="http://arxiv.org/abs/1507.04888">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Massively Parallel Methods for Deep Reinforcement Learning.
  <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/gorila.pdf">
   <code>
    pdf
   </code>
  </a>
  ] :star:
 </li>
 <li>
  On Learning to Think- Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models.
  <a href="https://arxiv.org/pdf/1511.09249">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Playing Atari with Deep Reinforcement Learning.
  <a href="https://arxiv.org/pdf/1312.5602.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Recurrent Reinforcement Learning: A Hybrid Approach.
  <a href="http://arxiv.org/abs/1509.03044">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Strategic Dialogue Management via Deep Reinforcement Learning.
  <a href="http://arxiv.org/abs/1511.08099">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control.
  <a href="http://arxiv.org/abs/1511.03791">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Trust Region Policy Optimization.
  <a href="http://jmlr.org/proceedings/papers/v37/schulman15.pdf">
   <code>
    pdf
   </code>
  </a>
  :star:
 </li>
 <li>
  Universal Value Function Approximators.
  <a href="http://schaul.site44.com/publications/uvfa.pdf">
   <code>
    pdf
   </code>
  </a>
 </li>
 <li>
  Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning.
  <a href="http://arxiv.org/abs/1509.08731">
   <code>
    arxiv
   </code>
  </a>
 </li>
</ul>
<h3>
 Natural language process
</h3>
<ul>
 <li>
  A Primer on Neural Network Models for Natural Language Processing. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjr-I3b-9LQAhVEVbwKHVo8A70QFggsMAE&amp;url=http%3A%2F%2Fcs.biu.ac.il%2F~yogo%2Fnnlp.pdf&amp;usg=AFQjCNEZEkggUYseGdLhpFy_iG5mBA3X9g">
   url
  </a>
  ]
 </li>
 <li>
  A Unified Tagging Solution- Bidirectional LSTM Recurrent Neural Network with Word Embedding.  [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj-t_LG_NLQAhVES7wKHWTtCmIQFgguMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.00215&amp;usg=AFQjCNECqO7dKUb1L7bkvFFR_8-hgPy52w">
   url
  </a>
  ]
 </li>
 <li>
  Alternative structures for character-level RNNs. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiyx_iZ_dLQAhUBT7wKHUE0A38QFggqMAE&amp;url=http%3A%2F%2Fwww.di.ens.fr%2F~bojanowski%2Fpapers%2Fbojanowski16alternative.pdf&amp;usg=AFQjCNF0ds1vVOijyqtBX-g_s9x8OedIbg">
   url
  </a>
  ]
 </li>
 <li>
  Ask Me Anything- Dynamic Memory Networks for Natural Language Processing. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiH8Kjf_dLQAhXIxLwKHU7QAb8QFggpMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.07285&amp;usg=AFQjCNFjdb3GPe1IrNPSh8zevJazf58JwQ">
   url
  </a>
  ] :star:
 </li>
 <li>
  BlackOut- Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies.
  <a href="https://arxiv.org/pdf/1511.06909.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Character-Aware Neural Language Models. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjJ7JjA_9LQAhVDwLwKHbmaCskQFgguMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.06615&amp;usg=AFQjCNG3RqYNgZfsn7zIez3SEzwB70cEKg">
   url
  </a>
  ] :star:
 </li>
 <li>
  Character-level Convolutional Networks for Text Classification.[
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiE5qTl_9LQAhUEWLwKHcHaDQgQFggsMAE&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5782-character-level-convolutional-networks-for-text-classification.pdf&amp;usg=AFQjCNFInMceTBvIU8_8XmtKfoizKGpOVA">
   url
  </a>
  ]
 </li>
 <li>
  Deep Speech 2- End-to-End Speech Recognition in English and Mandarin.  [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi5uvCDgdPQAhVFwLwKHSJ6B0MQFggvMAE&amp;url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv48%2Famodei16.pdf&amp;usg=AFQjCNFE5u2Xu81DH2gQUoyHVtC4AzLhYg">
   url
  </a>
  ] :star:
 </li>
 <li>
  Deep Unordered Composition Rivals Syntactic Methods for Text Classification.
  <a href="http://cs.umd.edu/~miyyer/pubs/2015_acl_dan.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/miyyer/dan">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Distributed Representations of Sentences and Documents. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjf2ZyrgtPQAhWJvrwKHTV4BqsQFgguMAE&amp;url=http%3A%2F%2Fcs.stanford.edu%2F~quocle%2Fparagraph_vector.pdf&amp;usg=AFQjCNESECVF_9eXAkAjfSqqHrqlxkVQgg">
   url
  </a>
  ] :star:
 </li>
 <li>
  Dynamic Capacity Networks.  [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiN_Yj0gtPQAhVPQLwKHVz0BZwQFgguMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.07838&amp;usg=AFQjCNFR0AEK2z-pT8ulDl98QWXP0M3fCw">
   url
  </a>
  ]
 </li>
 <li>
  Exploring Models and Data for Image Question Answering.
  <a href="https://arxiv.org/pdf/1505.02074.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/paarthneekhara/neural-vqa-tensorflow">
   <code>
    tensorflow
   </code>
  </a>
 </li>
 <li>
  From Word Embeddings To Document Distances.
  <a href="http://www.cs.cornell.edu/~kilian/papers/wmd_metric.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/src-d/wmd-relax">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks.
  <a href="https://arxiv.org/pdf/1503.00007.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/dasguptar/treelstm.pytorch">
   <code>
    pytorch
   </code>
  </a>
  :star:
 </li>
 <li>
  Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs.
  <a href="https://www.aclweb.org/anthology/D/D15/D15-1041.pdf">
   <code>
    acl
   </code>
  </a>
 </li>
 <li>
  Larger-Context Language Modeling. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjHlvWshNPQAhWLybwKHTiuB-0QFgguMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.03729&amp;usg=AFQjCNG88NnFeKSPKis1dVnVNYa0Tu50Gw">
   url
  </a>
  ]
 </li>
 <li>
  <a href="http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html">
   Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks.
  </a>
  <a href="http://ttic.uchicago.edu/~kgimpel/papers/he+etal.emnlp15.pdf">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/tonyabracadabra/Multi-Perspective-Sentence-Similarity-Modeling-with-CNN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Multi-task Sequence to Sequence Learning. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiu7MbphdPQAhWDUrwKHeo3DO8QFggpMAE&amp;url=http%3A%2F%2Fjan.stanford.edu%2Fpubs%2Fluong2016iclr_multi.pdf&amp;usg=AFQjCNGYWAqWnjbi6p3ZXWe0hBcNMSWawA">
   url
  </a>
  ]
 </li>
 <li>
  Natural Language Understanding with Distributed Representation.  [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjhm4yThtPQAhWJVrwKHY-fDusQFggiMAA&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.07916&amp;usg=AFQjCNEXqHl1eNACFv-e99vq-omz4TcY_Q">
   url
  </a>
  ]
 </li>
 <li>
  Neural Machine Translation of Rare Words with Subword Units.
  <a href="https://arxiv.org/pdf/1508.07909.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  Neural Responding Machine for Short-Text Conversation. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiT-aOMntPQAhXHwbwKHXcqAzYQFggpMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1503.02364&amp;usg=AFQjCNETeT0aqPYSdo-fP-DYyl7WZg2BqQ">
   url
  </a>
  ]
 </li>
 <li>
  Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwigxZnPntPQAhUCybwKHRJrCc8QFggiMAA&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1510.06168&amp;usg=AFQjCNEIDEbarhumVAtwYDPin-r5-10mSQ">
   url
  </a>
  ]
 </li>
 <li>
  Conditional Random Fields as Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1502.03240.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Reading Scene Text in Deep Convolutional Sequences. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjnwcaJpY7RAhVnwlQKHdQhBMkQFggrMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.04395&amp;usg=AFQjCNFwWEe1FlLYwTvy5JrYCme9M_QREA">
   url
  </a>
  ]
 </li>
 <li>
  Recurrent Convolutional Neural Networks for Text Classification.
  <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9745/9552">
   <code>
    pdf
   </code>
  </a>
  <a href="https://github.com/knok/rcnn-text-classification">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Semi-supervised Sequence Learning. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj28pOnodPQAhUJT7wKHb_eDpIQFggiMAA&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5949-semi-supervised-sequence-learning.pdf&amp;usg=AFQjCNFi_8bOPu361mtaI13MWB_aHDlspg">
   url
  </a>
  ]
 </li>
 <li>
  Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems.
  <a href="https://arxiv.org/pdf/1508.01745.pdf">
   <code>
    arxiv
   </code>
  </a>
 </li>
 <li>
  sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiQ_aHDodPQAhUITLwKHYP2B2kQFgg5MAM&amp;url=https%3A%2F%2Fpdfs.semanticscholar.org%2F36f9%2F886ad1cb9ee3f66c5af0282ae7a3359b86b2.pdf&amp;usg=AFQjCNE7oWW1uaAuK2skjRUnPXhykGFeMw">
   url
  </a>
  ]
 </li>
 <li>
  Sequence Level Training with Recurrent Neural Networks. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjEgIbnodPQAhUKyrwKHXJICVUQFgghMAA&amp;url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.06732&amp;usg=AFQjCNGEymvqFAIJnyEUAh0Ok7dImTDJjg">
   url
  </a>
  ]
 </li>
 <li>
  Strategies for Training Large Vocabulary Neural Language Models. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjE1KCTo9PQAhXHwrwKHeTfDZ8QFggsMAE&amp;url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP%2FP16%2FP16-1186.pdf&amp;usg=AFQjCNGUJ0zFy2G4j9x9enwYuu2iTN5cig">
   url
  </a>
  ]
 </li>
 <li>
  Towards Universal Paraphrastic Sentence Embeddings. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjM-u3Jo9PQAhUDbrwKHXETBuAQFggtMAE&amp;url=http%3A%2F%2Fttic.uchicago.edu%2F~wieting%2Fwieting2016ICLR.pdf&amp;usg=AFQjCNFMW6NpxCP9FMXpati4GbmkkCgPWQ">
   url
  </a>
  ]
 </li>
 <li>
  Visualizing and Understanding Neural Models in NLP. [
  <a href="https://www.google.co.jp/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjszoDFpNPQAhWIxbwKHYlEAV0QFgg2MAI&amp;url=https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fpubs%2Fvisualizing16.pdf&amp;usg=AFQjCNECNXN2Cf42XcZokv2o5sE6RNM41Q">
   url
  </a>
  ]
 </li>
</ul>
