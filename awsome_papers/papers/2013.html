<h1>
 2013
</h1>
<h3>
 Deep Learning
</h3>
<ul>
 <li>
  Adaptive dropout for training deep neural networks. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjDrbLe0NDQAhULrFQKHXfIBOcQFgggMAA&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5032-adaptive-dropout-for-training-deep-neural-networks.pdf&amp;usg=AFQjCNEIvLpW_VwelyHjOxQ7up1Wc4djkA">
   url
  </a>
  ]
 </li>
 <li>
  <b>
   [VAE]
  </b>
  <a href="http://zhouchang.info/blog/2016-04-11/VAE.html">
   Auto-Encoding Variational Bayes.
  </a>
  <a href="https://arxiv.org/pdf/1312.6114.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="http://dpkingma.com/wordpress/wp-content/uploads/2014/05/2014-03_talk_iclr.pdf">
   <code>
    url
   </code>
  </a>
  :star:
 </li>
 <li>
  Better Mixing via Deep Representations.
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj629740dDQAhUmi1QKHRjaB4AQFgguMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1207.4404&amp;usg=AFQjCNEVC3VegGSWQXm-XJvWXOjjlk1VIA">
   url
  </a>
 </li>
 <li>
  Deep Fisher Networks for Large-Scale Image Classification.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwifnNeg0tDQAhWpsVQKHU3wB4sQFgggMAA&amp;url=https%3A%2F%2Fwww.robots.ox.ac.uk%2F~vgg%2Fpublications%2F2013%2FSimonyan13b%2Fsimonyan13b.pdf&amp;usg=AFQjCNEixGKMTXtLPadNICunAuLHvv-iog">
   url
  </a>
  ]
 </li>
 <li>
  Deep Learning of Representations-looking forward. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiVocvG0tDQAhWLhVQKHRcvAIcQFggpMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1305.0445&amp;usg=AFQjCNFmv3e_Pd6z34Er4V3zvUqO77QXog">
   url
  </a>
  ]
 </li>
 <li>
  Deep Neural Networks for Object Detection. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwie1brk0tDQAhWhxlQKHVSQACIQFggiMAA&amp;url=https%3A%2F%2Fpdfs.semanticscholar.org%2F713f%2F73ce5c3013d9fb796c21b981dc6629af0bd5.pdf&amp;usg=AFQjCNF79vro3uwWMO53Sqh9Imh62uCl_A">
   url
  </a>
  ] :star:
 </li>
 <li>
  Dropout Training as Adaptive Regularization. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjmzZCU09DQAhXpz1QKHYuNC1AQFgguMAE&amp;url=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4882-dropout-training-as-adaptive-regularization.pdf&amp;usg=AFQjCNEChKFYrerSVjmcTeUW8JdtiLisGw">
   url
  </a>
  ]
 </li>
 <li>
  Efficient Estimation of Word Representations in Vector Space. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjYx_TI09DQAhXihFQKHcNpBeQQFgggMAA&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1301.3781&amp;usg=AFQjCNFo6E4qrQLPJrMm4O4UzOEivh0Crw">
   url
  </a>
  ] :star:
 </li>
 <li>
  Exploiting Similarities among Languages for Machine Translation. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj245_009DQAhWEjFQKHSLHDTkQFggsMAE&amp;url=http%3A%2F%2Fresearch.google.com%2Fpubs%2Farchive%2F44931.pdf&amp;usg=AFQjCNEIiCd3WIURIXZY0fch73RrpgnhvQ">
   url
  </a>
  ]
 </li>
 <li>
  Generalized Denoising Auto-Encoders as Generative Models.
  <a href="http://papers.nips.cc/paper/5023-generalized-denoising-auto-encoders-as-generative-models">
   <code>
    url
   </code>
  </a>
  <a href="https://github.com/yaoli/GSN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Generating Sequences With Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1308.0850.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Generative Stochastic Networks Trainable by Backprop.
  <a href="https://arxiv.org/pdf/1306.1091.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/yaoli/GSN">
   <code>
    code
   </code>
  </a>
 </li>
 <li>
  Learning a Deep Compact Image Representation for Visual Tracking. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi3zYW01tDQAhWIwFQKHUmCCnMQFggqMAE&amp;url=http%3A%2F%2Fwinsty.net%2Fpapers%2Fdlt.pdf&amp;usg=AFQjCNFUQTWp6bQNt1AhJ50sXR7Gj-azAA">
   url
  </a>
  ]
 </li>
 <li>
  Learning Hierarchical Features for Scene Labeling. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjip9nP1tDQAhWs0FQKHVE3CiUQFggiMAA&amp;url=http%3A%2F%2Fyann.lecun.com%2Fexdb%2Fpublis%2Fpdf%2Ffarabet-pami-13.pdf&amp;usg=AFQjCNGaHp1t2JKhTOWjhqAzmWrcMbnQ-A">
   url
  </a>
  ] :star:
 </li>
 <li>
  Learning Multi-level Sparse Representations. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjG5_uX19DQAhVCrlQKHSiqB64QFggiMAA&amp;url=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5076-learning-multi-level-sparse-representations.pdf&amp;usg=AFQjCNGnJjQja7ddxoLTaC6Zr_VR4tqKaw">
   url
  </a>
  ]
 </li>
 <li>
  <b>
   [Maxout]
  </b>
  Maxout Networks. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj5vpjM19DQAhUos1QKHZ6zAQcQFggnMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1302.4389&amp;usg=AFQjCNHCC8d-MyLhvu0kw2dsmCZHa17OXA">
   url
  </a>
  ] :star:
 </li>
 <li>
  No More Pesky Learning Rates. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjby9Lu19DQAhXCilQKHVuJA0MQFggdMAA&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1206.1106&amp;usg=AFQjCNFM0JupBcHvTGZck8kaO4xEvcYXdg">
   url
  </a>
  ]
 </li>
 <li>
  On autoencoder scoring.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjAnuio2NDQAhWHh1QKHf3PAXIQFggdMAA&amp;url=http%3A%2F%2Fwww.jmlr.org%2Fproceedings%2Fpapers%2Fv28%2Fkamyshanska13.pdf&amp;usg=AFQjCNGNvTTTRcMXCdGjbhaekXcIqEMjOw">
   url
  </a>
  ]
 </li>
 <li>
  On the difficulty of training recurrent neural networks. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj3z4LN2NDQAhXjjlQKHSPhCaAQFgggMAA&amp;url=http%3A%2F%2Fwww.jmlr.org%2Fproceedings%2Fpapers%2Fv28%2Fpascanu13.pdf&amp;usg=AFQjCNEATfq_Z8jFkNJ_zO566QBDMyyaSw">
   url
  </a>
  ]
 </li>
 <li>
  On the importance of initialization and momentum in deep learning. [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwifhdjp2NDQAhXCq1QKHarVB2cQFggdMAA&amp;url=http%3A%2F%2Fwww.cs.toronto.edu%2F~hinton%2Fabsps%2Fmomentum.pdf&amp;usg=AFQjCNF_On1gl-3iNj7fJ6EYSrP1RBckPg">
   url
  </a>
  ]
 </li>
 <li>
  Provable Bounds for Learning Some Deep Representations.
  <a href="https://arxiv.org/pdf/1310.6343.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Regularization of Neural Networks using DropConnect.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjL_5GH2dDQAhVhq1QKHVzuBzIQFggiMAA&amp;url=http%3A%2F%2Fwww.matthewzeiler.com%2Fpubs%2Ficml2013%2Ficml2013.pdf&amp;usg=AFQjCNFy6eyEr7XS251AkptfvV537UPQAA">
   url
  </a>
  ]
 </li>
 <li>
  Representation Learning A Review and New Perspectives.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj9zK6s2tDQAhWjjVQKHXq1A5oQFggiMAA&amp;url=http%3A%2F%2Fwww.cl.uni-heidelberg.de%2Fcourses%2Fws14%2Fdeepl%2FBengioETAL12.pdf&amp;usg=AFQjCNEQI9Rst49wWNFRe1TG9nZscxS2QQ">
   url
  </a>
  ] :star:
 </li>
 <li>
  <b>
   [RCNN]
  </b>
  <a href="http://lib.csdn.net/article/deeplearning/46183?knId=1734">
   Rich feature hierarchies for accurate object detection and semantic segmentation.
  </a>
  <a href="https://arxiv.org/pdf/1311.2524.pdf">
   <code>
    arxiv
   </code>
  </a>
  <a href="https://github.com/rbgirshick/rcnn">
   <code>
    code
   </code>
  </a>
  :star:
 </li>
 <li>
  Scaling up Spike-and-Slab Models for Unsupervised Feature Learning.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjb2dzP2tDQAhXKyVQKHSxGCB8QFggqMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1201.3382&amp;usg=AFQjCNEgFUQgcIZqlcsOnuFAJwCiid4_QQ">
   url
  </a>
  ]
 </li>
 <li>
  Speech Recognition with Deep Recurrent Neural Networks.
  <a href="https://arxiv.org/pdf/1303.5778.pdf">
   <code>
    arxiv
   </code>
  </a>
  :star:
 </li>
 <li>
  Stochastic Pooling for Regularization of Deep Convolutional Neural Networks.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiB8sbr2tDQAhWFiFQKHQa_CosQFgggMAA&amp;url=http%3A%2F%2Fwww.matthewzeiler.com%2Fpubs%2Ficlr2013%2Ficlr2013.pdf&amp;usg=AFQjCNGBzD7QvKjhVqEfTqx52q3Fgvz3IA">
   url
  </a>
  ]
 </li>
 <li>
  <b>
   [ZFNet]
  </b>
  Visualizing and Understanding Convolutional Networks.  [
  <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjkzKeI29DQAhXCqlQKHZMCDRAQFggiMAA&amp;url=http%3A%2F%2Fwww.cs.nyu.edu%2F~fergus%2Fpapers%2FzeilerECCV2014.pdf&amp;usg=AFQjCNFRXYdMaGmpHegQP_bccZWSKDgmlw">
   url
  </a>
  ] :star:
 </li>
</ul>
<h3>
 Transfer learning
</h3>
<ul>
 <li>
  Active transfer learning for cross-system recommendation. [
  <a href="http://www.cs.ust.hk/~qyang/Docs/2013/Zhao.pdf">
   pdf
  </a>
  ]
 </li>
 <li>
  Combating Negative Transfer From Predictive Distribution Differences. [
  <a href="https://www.researchgate.net/publication/260586601_Combating_Negative_Transfer_From_Predictive_Distribution_Differences">
   url
  </a>
  ]
 </li>
 <li>
  Feature Ensemble Plus Sample Selection: Domain Adaptation for Sentiment Classification. [
  <a href="http://www.nlpr.ia.ac.cn/2013papers/gjkw/gk107.pdf">
   pdf
  </a>
  ] :star:
 </li>
 <li>
  On handling negative transfer and imbalanced distributions in multiple source transfer learning. [
  <a href="http://www.cse.buffalo.edu/DBGROUP/bioinformatics/papers/Liang_SDM13_SLW.pdf">
   pdf
  </a>
  ]
 </li>
 <li>
  Transfer feature learning with joint distribution adaptation. [
  <a href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Long_Transfer_Feature_Learning_2013_ICCV_paper.pdf">
   pdf
  </a>
  ]
 </li>
</ul>
<h3>
 Deep Reinforcement Learning
</h3>
<ul>
 <li>
  Evolving large-scale neural networks for vision-based reinforcement learning. [
  <a href="http://people.idsia.ch/~juergen/gecco2013torcs.pdf">
   idsia
  </a>
  ] :star:
 </li>
 <li>
  <a href="http://www.cnblogs.com/wangxiaocvpr/p/5601972.html">
   Playing Atari with Deep Reinforcement Learning.
  </a>
  [
  <a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">
   toronto
  </a>
  ] :star:
 </li>
</ul>
