# 00_2.2.1_Local_Search_Algorithms_and_Optimization_Problems

"""

Lecture: 2_Problem-solving/2.2_Beyond_Classical_Search
Content: 00_2.2.1_Local_Search_Algorithms_and_Optimization_Problems

"""

## 4.1 本地搜索算法与优化问题

本节探讨了传统搜索算法以外的另一类搜索算法，即本地搜索算法。这些算法主要用于解决那些路径本身并不重要，而仅仅关注最终状态的问题。以下是本地搜索算法及其应用的详细分析：

### 4.1.1 爬山法搜索

爬山法（Hill Climbing）是一种基本的本地搜索技术，其基本思想是从一个初始状态出发，不断向邻近状态移动，使目标函数值逐步增加，直至达到局部最大值。其算法如下图所示：

``` 
function HILL-CLIMBING(problem) returns a state that is a local maximum
  current←MAKE-NODE(problem .INITIAL-STATE)
  loop do
    neighbor ← a highest-valued successor of current
    if neighbor.VALUE ≤ current.VALUE then return current .STATE
    current←neighbor
```

#### 优点

1. **内存消耗低**：爬山法只需要存储当前节点，因此内存占用极少。
2. **适用于大规模或无限状态空间**：在大规模或连续状态空间中，爬山法能够快速找到合理的解。

#### 缺点

1. **局部最大值**：算法可能会陷入局部最大值而无法继续前进。
2. **山脊效应**：在状态空间中，算法可能难以跨越山脊。
3. **高原效应**：算法可能会在高原区域停滞不前，难以找到最优解。

### 4.1.2 模拟退火

模拟退火（Simulated Annealing）是一种基于统计物理的随机搜索算法，它通过允许一定概率的“退步”来避免陷入局部最优。模拟退火的核心思想是模拟物理退火过程，通过逐渐降低“温度”来达到全局最优状态。其算法如下图所示：

```
function SIMULATED-ANNEALING(problem , schedule) returns a solution state
  current←MAKE-NODE(problem .INITIAL-STATE)
  for t = 1 to ∞ do
    T ← schedule(t)
    if T = 0 then return current
    next← a randomly selected successor of current
    ΔE ←next .VALUE – current .VALUE
    if ΔE > 0 then current←next
    else current←next only with probability e^ΔE/T
```

### 4.1.3 局部光束搜索

局部光束搜索（Local Beam Search）保留k个状态，并在每一步生成所有k个状态的所有后继状态，选择k个最佳状态继续搜索。与多次随机重启爬山法不同，局部光束搜索允许并行搜索之间传递有用信息，从而提高搜索效率。其算法特点如下：

1. **保留多个状态**：在内存允许的情况下，同时保留多个状态进行搜索。
2. **信息共享**：状态间的信息共享使得算法能快速集中资源于更有希望的搜索路径。

### 4.1.4 遗传算法

遗传算法（Genetic Algorithm, GA）是一种模拟自然选择和遗传机制的搜索算法，通过选择、交叉和变异操作生成新的状态。其步骤如下：

1. **初始化种群**：随机生成一组初始状态。
2. **适应度评估**：计算每个状态的适应度值。
3. **选择**：根据适应度值选择下一代的父母。
4. **交叉**：通过交叉操作生成新的状态。
5. **变异**：对新状态进行变异操作以引入多样性。

遗传算法通常用于复杂的优化问题，其优点是能够在大规模状态空间中找到全局最优或近似最优解。

### 优化问题的应用

本地搜索算法特别适用于纯优化问题，例如集成电路设计、工厂布局、工作调度、自动编程、电信网络优化、车辆路径规划和投资组合管理等。这些问题的共同特点是路径并不重要，而目标是找到某种意义上的最佳状态。

通过本地搜索算法，可以高效地处理大规模或连续的状态空间，尤其在实际应用中具有显著优势。例如，模拟退火算法在解决VLSI布局问题和工厂调度等大规模优化任务中表现优异；遗传算法在天线设计和计算机辅助设计等领域也有广泛应用   。

---
以下是关于几种主要的本地搜索算法及其优化问题的详细比较表：

| **算法**               | **基本思想**                               | **优点**                                                    | **缺点**                                                     | **典型应用**                     |
|----------------------|---------------------------------------|---------------------------------------------------------|----------------------------------------------------------|----------------------------------|
| **爬山法**              | 从初始状态开始，不断移动到邻近状态中目标函数值更高的状态               | 1. 内存消耗低<br>2. 适用于大规模或无限状态空间                             | 1. 容易陷入局部最大值<br>2. 山脊效应<br>3. 高原效应            | 图像处理、路径规划                     |
| **模拟退火**            | 模拟物理退火过程，通过逐渐降低温度来避免陷入局部最优                   | 1. 能够跳出局部最优<br>2. 理论上能达到全局最优                           | 1. 参数调整复杂<br>2. 收敛速度慢                                | VLSI布局、工厂调度                    |
| **局部光束搜索**          | 保留多个状态，并行搜索状态的所有后继状态，选择最优的几个继续搜索          | 1. 并行搜索提高效率<br>2. 信息共享提高搜索质量                         | 1. 内存消耗大<br>2. 可能仍陷入局部最优                            | AI规划、机器学习                     |
| **遗传算法**            | 模拟自然选择，通过选择、交叉和变异生成新状态                       | 1. 强大的全局搜索能力<br>2. 能处理复杂搜索空间                         | 1. 参数选择困难<br>2. 收敛不确定性                               | 天线设计、自动编程、投资组合管理            |
| **禁忌搜索**            | 通过记录一段时间内访问过的状态来避免循环搜索                         | 1. 能够跳出局部最优<br>2. 对参数设置不敏感                            | 1. 需要维护禁忌表，内存消耗大<br>2. 收敛速度慢                     | 生产调度、资源分配                    |
| **粒子群优化**          | 模拟生物群体行为，通过粒子间的相互协作找到最优解                       | 1. 简单易实现<br>2. 收敛速度快                                    | 1. 容易陷入局部最优<br>2. 对参数敏感                              | 函数优化、神经网络训练                 |
| **差分进化**            | 通过变异操作和选择机制迭代改进解的质量                              | 1. 全局搜索能力强<br>2. 参数少且易调整                              | 1. 计算量大<br>2. 对初始参数敏感                                | 参数优化、函数优化                   |

### 详细比较

1. **爬山法（Hill Climbing）**
   - **基本思想**：从当前状态移动到其邻居状态中目标函数值更高的状态，直到达到局部最优。
   - **优点**：内存消耗低，适用于大规模或无限状态空间。
   - **缺点**：容易陷入局部最大值、山脊效应和高原效应。
   - **典型应用**：常用于图像处理和路径规划等领域。

2. **模拟退火（Simulated Annealing）**
   - **基本思想**：通过允许一定概率的退步来避免陷入局部最优，并逐渐降低温度以接近全局最优。
   - **优点**：能跳出局部最优，理论上能达到全局最优。
   - **缺点**：参数调整复杂，收敛速度慢。
   - **典型应用**：广泛应用于VLSI布局和工厂调度等大规模优化任务。

3. **局部光束搜索（Local Beam Search）**
   - **基本思想**：保留k个状态，并行搜索所有状态的所有后继状态，选择k个最佳状态继续搜索。
   - **优点**：并行搜索提高效率，信息共享提高搜索质量。
   - **缺点**：内存消耗大，可能仍会陷入局部最优。
   - **典型应用**：用于AI规划和机器学习等领域。

4. **遗传算法（Genetic Algorithm）**
   - **基本思想**：模拟自然选择，通过选择、交叉和变异操作生成新的状态。
   - **优点**：全局搜索能力强，能处理复杂的搜索空间。
   - **缺点**：参数选择困难，收敛不确定性高。
   - **典型应用**：天线设计、自动编程和投资组合管理等领域。

5. **禁忌搜索（Tabu Search）**
   - **基本思想**：通过记录一段时间内访问过的状态来避免搜索循环。
   - **优点**：能跳出局部最优，对参数设置不敏感。
   - **缺点**：需要维护禁忌表，内存消耗较大，收敛速度较慢。
   - **典型应用**：生产调度和资源分配等领域。

6. **粒子群优化（Particle Swarm Optimization）**
   - **基本思想**：模拟生物群体行为，通过粒子间的相互协作找到最优解。
   - **优点**：简单易实现，收敛速度快。
   - **缺点**：容易陷入局部最优，对参数敏感。
   - **典型应用**：函数优化和神经网络训练等领域。

7. **差分进化（Differential Evolution）**
   - **基本思想**：通过变异操作和选择机制迭代改进解的质量。
   - **优点**：全局搜索能力强，参数少且易调整。
   - **缺点**：计算量大，对初始参数敏感。
   - **典型应用**：参数优化和函数优化等领域。