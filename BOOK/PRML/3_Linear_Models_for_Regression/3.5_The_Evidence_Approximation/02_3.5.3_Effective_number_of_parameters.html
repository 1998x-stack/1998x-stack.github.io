
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.5.3 Effective number of parameters</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>02_3.5.3_Effective_number_of_parameters</h1>
<pre><code>Lecture: 3_Linear_Models_for_Regression/3.5_The_Evidence_Approximation
Content: 02_3.5.3_Effective_number_of_parameters
</code></pre>
<h3>3.5.3 有效参数数目</h3>
<p>在贝叶斯线性回归模型中，有效参数数目是一个非常重要的概念，用于理解模型的复杂度和数据拟合能力之间的平衡。在这一节中，我们将详细探讨如何定义和计算有效参数数目 $ \gamma $，并理解其在贝叶斯框架中的意义。</p>
<h3>有效参数数目的定义</h3>
<p>有效参数数目 $ \gamma $ 定义为：
$$ \gamma = \sum_{i=1}^{M} \frac{\lambda_i}{\alpha + \lambda_i} $$
其中 $ \lambda_i $ 是矩阵 $ \beta \Phi^T \Phi $ 的特征值。</p>
<p>这个定义表明，对于每一个参数 $ w_i $，其贡献的权重由特征值 $ \lambda_i $ 和先验参数 $ \alpha $ 共同决定。当特征值 $ \lambda_i $ 远大于 $ \alpha $ 时，参数 $ w_i $ 对数据的拟合度较高；反之，当 $ \lambda_i $ 远小于 $ \alpha $ 时，参数 $ w_i $ 的贡献较小。</p>
<h3>理论解释</h3>
<p>通过上述公式，可以看出有效参数数目 $ \gamma $ 的范围是从 0 到 $ M $。当所有特征值 $ \lambda_i $ 都远大于 $ \alpha $ 时，$ \gamma $ 接近于 $ M $，表明模型中的所有参数都被有效利用。而当所有特征值 $ \lambda_i $ 都远小于 $ \alpha $ 时，$ \gamma $ 接近于 0，表明模型中的参数大部分被先验抑制，模型复杂度较低。</p>
<p>这种平衡机制是贝叶斯方法的一个关键特性，它通过自动调整参数的有效数量来适应数据的复杂度，从而避免过拟合和欠拟合问题。</p>
<h3>计算有效参数数目</h3>
<p>为了计算有效参数数目 $ \gamma $，我们需要以下步骤：</p>
<ol>
<li><strong>计算特征值</strong>：计算矩阵 $ \beta \Phi^T \Phi $ 的特征值 $ \lambda_i $。</li>
<li><strong>计算有效参数数目</strong>：根据公式 $ \gamma = \sum_{i=1}^{M} \frac{\lambda_i}{\alpha + \lambda_i} $ 计算有效参数数目。</li>
</ol>
<h3>代码实现</h3>
<p>以下是一个示例代码，用于计算贝叶斯线性回归模型的有效参数数目：</p>
<pre><code class="language-python">import numpy as np
from scipy.linalg import inv

class BayesianLinearRegression:
    def __init__(self, alpha: float, beta: float):
        self.alpha = alpha
        self.beta = beta
        self.m_N = None
        self.S_N = None

    def fit(self, X: np.ndarray, t: np.ndarray):
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        S_0_inv = self.alpha * np.eye(X.shape[1])
        self.S_N = inv(S_0_inv + self.beta * X.T @ X)
        self.m_N = self.beta * self.S_N @ X.T @ t

    def effective_number_of_parameters(self, X: np.ndarray) -&gt; float:
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        eigvals = np.linalg.eigvalsh(self.beta * X.T @ X)
        gamma = np.sum(eigvals / (self.alpha + eigvals))
        return gamma

if __name__ == &quot;__main__&quot;:
    X_train = np.array([[0.1], [0.4], [0.7], [1.0]])
    t_train = np.array([1.1, 1.9, 3.0, 4.2])
    
    model = BayesianLinearRegression(alpha=1.0, beta=25.0)
    model.fit(X_train, t_train)
    gamma = model.effective_number_of_parameters(X_train)
    
    print(&quot;有效参数数目 γ: &quot;, gamma)
</code></pre>
<h3>代码解释</h3>
<ol>
<li><strong>类定义</strong>:
<ul>
<li><code>BayesianLinearRegression</code> 类用于实现贝叶斯线性回归模型，并计算有效参数数目。</li>
<li>初始化时需要指定先验分布的方差参数 <code>alpha</code> 和噪声精度参数 <code>beta</code>。</li>
</ul>
</li>
<li><strong>拟合模型</strong>:
<ul>
<li><code>fit</code> 方法用于拟合模型，计算后验分布的均值向量 <code>m_N</code> 和协方差矩阵 <code>S_N</code>。</li>
</ul>
</li>
<li><strong>有效参数数目</strong>:
<ul>
<li><code>effective_number_of_parameters</code> 方法计算有效参数数目 $ \gamma $。</li>
</ul>
</li>
<li><strong>示例</strong>:
<ul>
<li>在 <code>__main__</code> 中，通过示例数据演示了模型的拟合和有效参数数目的计算过程。</li>
</ul>
</li>
</ol>
<h3>检查代码逻辑</h3>
<ul>
<li>使用 <code>np.hstack</code> 添加偏置项，确保输入数据包含截距。</li>
<li>使用矩阵运算和线性代数库确保计算的准确性和高效性。</li>
<li>通过打印重要信息（如有效参数数目 $ \gamma $）来验证模型的正确性。</li>
</ul>

    <h3>Python 文件</h3>
    <pre><code># 02_3.5.3_Effective_number_of_parameters

"""
Lecture: 3_Linear_Models_for_Regression/3.5_The_Evidence_Approximation
Content: 02_3.5.3_Effective_number_of_parameters
"""

import numpy as np
from scipy.linalg import inv

class BayesianLinearRegression:
    def __init__(self, alpha: float, beta: float):
        self.alpha = alpha
        self.beta = beta
        self.m_N = None
        self.S_N = None

    def fit(self, X: np.ndarray, t: np.ndarray):
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        S_0_inv = self.alpha * np.eye(X.shape[1])
        self.S_N = inv(S_0_inv + self.beta * X.T @ X)
        self.m_N = self.beta * self.S_N @ X.T @ t

    def effective_number_of_parameters(self, X: np.ndarray) -> float:
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        eigvals = np.linalg.eigvalsh(self.beta * X.T @ X)
        gamma = np.sum(eigvals / (self.alpha + eigvals))
        return gamma

if __name__ == "__main__":
    X_train = np.array([[0.1], [0.4], [0.7], [1.0]])
    t_train = np.array([1.1, 1.9, 3.0, 4.2])
    
    model = BayesianLinearRegression(alpha=1.0, beta=25.0)
    model.fit(X_train, t_train)
    gamma = model.effective_number_of_parameters(X_train)
    
    print("有效参数数目 γ: ", gamma)
</code></pre>
  </div>
</body>
</html>
  