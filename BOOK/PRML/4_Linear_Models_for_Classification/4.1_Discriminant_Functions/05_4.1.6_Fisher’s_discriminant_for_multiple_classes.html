
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>4.1.6 Fisher’s discriminant for multiple classes</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>05_4.1.6_Fisher’s_discriminant_for_multiple_classes</h1>
<pre><code>Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 05_4.1.6_Fisher’s_discriminant_for_multiple_classes
</code></pre>
<h2>探索PRML.pdf中的知识</h2>
<p>PRML (Pattern Recognition and Machine Learning) 是Christopher M. Bishop所著的一本经典教材，涵盖了模式识别和机器学习领域的核心知识。在本书中，第4章介绍了线性分类模型，包括判别函数、最小二乘法分类、Fisher线性判别、感知器算法等。在第4.1.6节中，作者详细讨论了多类Fisher线性判别的方法。</p>
<h3>第4.1.6节：多类Fisher线性判别</h3>
<p>在这一节中，作者探讨了将Fisher线性判别法推广到多类分类问题的思路。通过引入多个线性“特征”，并使用特征值分解的方法，作者展示了如何在多类分类问题中应用Fisher判别法。</p>
<h2>深入分析</h2>
<h3>背景介绍</h3>
<p>Fisher线性判别（Fisher's Linear Discriminant, FLD）是一种用于寻找能够最大化类间方差和最小化类内方差的投影方向的技术。在二类分类问题中，FLD可以通过投影数据到一维空间来最大化两类之间的距离，同时最小化每类内部的散布。然而，在多类分类问题中，需要对这种方法进行推广，以处理多个类别之间的分类。</p>
<h3>多类Fisher线性判别的步骤</h3>
<ol>
<li>
<p><strong>线性特征的引入</strong>：</p>
<ul>
<li>对于多类分类问题，我们假设输入空间的维数 $D$ 大于类的数量 $K$。接下来，我们引入 $D' &gt; 1$ 个线性“特征” $y_k = w_k^T x$，其中 $k = 1, \ldots, D'$。</li>
<li>这些特征值可以组合在一起形成一个向量 $y$。类似地，权重向量 ${w_k}$ 可以看作是矩阵 $W$ 的列，从而有：
$$
y = W^T x
$$</li>
<li>这里我们不包含偏置参数。</li>
</ul>
</li>
<li>
<p><strong>类内协方差矩阵的推广</strong>：</p>
<ul>
<li>类内协方差矩阵 $S_W$ 的推广形式如下：
$$
S_W = \sum_{k=1}^{K} S_k
$$</li>
<li>其中，$S_k$ 表示第 $k$ 类的协方差矩阵：
$$
S_k = \sum_{n \in C_k} (x_n - m_k)(x_n - m_k)^T
$$</li>
<li>这里 $m_k$ 是第 $k$ 类的均值向量，定义为：
$$
m_k = \frac{1}{N_k} \sum_{n \in C_k} x_n
$$
$N_k$ 是第 $k$ 类中的样本数量。</li>
</ul>
</li>
<li>
<p><strong>类间协方差矩阵的推广</strong>：</p>
<ul>
<li>总协方差矩阵 $S_T$ 可以表示为：
$$
S_T = \sum_{n=1}^{N} (x_n - m)(x_n - m)^T
$$</li>
<li>其中 $m$ 是总数据集的均值：
$$
m = \frac{1}{N} \sum_{n=1}^{N} x_n = \frac{1}{N} \sum_{k=1}^{K} N_k m_k
$$</li>
<li>总协方差矩阵可以分解为类内协方差矩阵和类间协方差矩阵之和：
$$
S_T = S_W + S_B
$$</li>
<li>类间协方差矩阵 $S_B$ 定义为：
$$
S_B = \sum_{k=1}^{K} N_k (m_k - m)(m_k - m)^T
$$</li>
</ul>
</li>
<li>
<p><strong>特征值分解</strong>：</p>
<ul>
<li>我们的目标是找到投影矩阵 $W$，使得投影后的数据在类间有最大的方差，同时在类内有最小的方差。</li>
<li>为此，我们最大化如下目标函数：
$$
J(W) = \mathrm{Tr} \left( (W^T S_W W)^{-1} (W^T S_B W) \right)
$$</li>
<li>这一目标可以通过求解如下特征值问题来实现：
$$
S_W^{-1} S_B w = \lambda w
$$</li>
<li>其中，$w$ 是特征向量，$\lambda$ 是特征值。选择对应最大特征值的特征向量作为投影矩阵的列。</li>
</ul>
</li>
</ol>
<h3>结论</h3>
<p>通过以上分析可以看出，Fisher线性判别法在处理多类分类问题时，通过引入多个线性特征，并通过特征值分解的方法，可以有效地找到投影矩阵，使得投影后的数据在类间方差最大，类内方差最小。这种方法为多类分类问题提供了一种有效的解决方案，有助于在实际应用中提高分类模型的性能。</p>
<p>这种分析为理解不同机器学习方法之间的关系提供了有价值的视角，有助于我们在实际应用中选择合适的模型和算法。</p>

    <h3>Python 文件</h3>
    <pre><code># 05_4.1.6_Fisher’s_discriminant_for_multiple_classes

"""
Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 05_4.1.6_Fisher’s_discriminant_for_multiple_classes
"""
import numpy as np
from scipy.linalg import eigh
from typing import Tuple

class MultiClassFLDA:
    """
    多类Fisher线性判别分析 (FLDA) 分类器

    Parameters:
    -----------
    n_components : int
        需要保留的线性判别维度数量

    Attributes:
    -----------
    W_ : np.ndarray
        投影矩阵
    """
    def __init__(self, n_components: int) -> None:
        self.n_components = n_components
        self.W_ = None

    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        训练FLDA分类器

        Parameters:
        -----------
        X : np.ndarray, shape = [n_samples, n_features]
            训练向量
        y : np.ndarray, shape = [n_samples]
            目标值
        """
        n_features = X.shape[1]
        class_labels = np.unique(y)

        # 计算类内散布矩阵
        S_W = np.zeros((n_features, n_features))
        for label in class_labels:
            X_c = X[y == label]
            mean_vec = np.mean(X_c, axis=0)
            S_W += np.cov(X_c, rowvar=False) * (X_c.shape[0] - 1)

        # 计算总均值
        mean_overall = np.mean(X, axis=0)

        # 计算类间散布矩阵
        S_B = np.zeros((n_features, n_features))
        for label in class_labels:
            X_c = X[y == label]
            n_c = X_c.shape[0]
            mean_vec = np.mean(X_c, axis=0)
            mean_diff = (mean_vec - mean_overall).reshape(n_features, 1)
            S_B += n_c * (mean_diff @ mean_diff.T)

        # 解决特征值问题
        A = np.linalg.inv(S_W) @ S_B
        eigenvalues, eigenvectors = eigh(A)
        
        # 选择前k个最大的特征值对应的特征向量
        sorted_indices = np.argsort(eigenvalues)[::-1]
        self.W_ = eigenvectors[:, sorted_indices[:self.n_components]]

    def transform(self, X: np.ndarray) -> np.ndarray:
        """
        将输入数据投影到FLDA新空间

        Parameters:
        -----------
        X : np.ndarray, shape = [n_samples, n_features]
            输入向量

        Returns:
        --------
        np.ndarray
            投影后的数据
        """
        return X @ self.W_

def generate_data(n_samples: int = 300, n_features: int = 4, n_classes: int = 3) -> Tuple[np.ndarray, np.ndarray]:
    """
    生成多类分类数据集

    Parameters:
    -----------
    n_samples : int
        样本数量 (默认值为 300)
    n_features : int
        特征数量 (默认值为 4)
    n_classes : int
        类别数量 (默认值为 3)

    Returns:
    --------
    Tuple[np.ndarray, np.ndarray]
        特征矩阵和目标值向量
    """
    np.random.seed(0)
    X = np.random.randn(n_samples, n_features)
    y = np.random.choice(range(n_classes), n_samples)
    return X, y

def main() -> None:
    """
    主函数，运行FLDA并打印结果
    """
    X, y = generate_data()
    flda = MultiClassFLDA(n_components=2)
    flda.fit(X, y)
    X_projected = flda.transform(X)
    
    print("投影矩阵 W:")
    print(flda.W_)
    print("投影后的数据形状:", X_projected.shape)

if __name__ == "__main__":
    main()</code></pre>
  </div>
</body>
</html>
  