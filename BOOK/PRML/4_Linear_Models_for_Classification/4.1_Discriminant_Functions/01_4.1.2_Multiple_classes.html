
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>4.1.2 Multiple classes</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>01_4.1.2_Multiple_classes</h1>
<pre><code>Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 01_4.1.2_Multiple_classes
</code></pre>
<h3>4.1.2 多类分类问题</h3>
<p>在《模式识别与机器学习》（PRML）一书的第4章中，Bishop博士详细介绍了线性分类模型的概念。第4.1节专注于判别函数，并在4.1.2节中讨论了多类分类问题。以下是对4.1.2节内容的详细分析。</p>
<h4>多类分类</h4>
<p>对于多类分类问题，我们需要扩展线性判别函数，以处理多个类别 $ K $。最直接的方法是组合多个两类判别函数，但这种方法存在一些严重的问题。</p>
<h5>一对其余分类器（One-versus-the-Rest Classifier）</h5>
<p>首先，我们可以使用 $ K-1 $ 个分类器，每个分类器解决一个特定类别 $ C_k $ 与非该类别的点的分类问题。这种方法称为“一对其余”分类器。图4.2左侧显示了一个示例，其中该方法导致输入空间中的某些区域分类不明确。</p>
<h5>一对一分类器（One-versus-One Classifier）</h5>
<p>另一种方法是引入 $ K(K-1)/2 $ 个二元判别函数，每个函数用于每对可能的类别。这种方法称为“一对一”分类器。然后，根据判别函数的多数投票对每个点进行分类。然而，这种方法同样会遇到分类不明确的问题，如图4.2右侧所示。</p>
<h5>单一 K 类判别函数（Single K-Class Discriminant Function）</h5>
<p>为了避免这些困难，我们可以考虑一个单一的 $ K $ 类判别函数，其中包含 $ K $ 个线性函数：</p>
<p>$$ y_k(\mathbf{x}) = \mathbf{w}<em k0="">k^T \mathbf{x} + w</em> $$</p>
<p>然后，如果 $ y_k(\mathbf{x}) &gt; y_j(\mathbf{x}) $ 对所有 $ j \neq k $ 成立，则将点 $ \mathbf{x} $ 分配到类 $ C_k $。类 $ C_k $ 和类 $ C_j $ 之间的决策边界由 $ y_k(\mathbf{x}) = y_j(\mathbf{x}) $ 定义，因此对应于一个 $ (D-1) $ 维超平面，其定义如下：</p>
<p>$$ (\mathbf{w}<em j0="">k - \mathbf{w}<em k0="">j)^T \mathbf{x} + (w</em> - w</em>) = 0 $$</p>
<p>这与第4.1.1节讨论的两类情况下的决策边界形式相同，因此适用类似的几何属性。</p>
<h5>决策区域的几何属性</h5>
<p>这种判别函数的决策区域总是单连通和凸的。</p>
<h3>结论</h3>
<p>在第4.1.2节中，Bishop博士详细阐述了多类分类问题中的线性判别函数。为了有效处理多类分类问题，可以使用单一的 $ K $ 类判别函数，而不是简单地组合多个两类判别函数。这种方法不仅可以避免分类不明确的问题，还能确保决策区域的单连通性和凸性。这部分内容为后续章节中讨论更复杂的非线性分类方法奠定了基础。</p>

    <h3>Python 文件</h3>
    <pre><code># 01_4.1.2_Multiple_classes

"""
Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 01_4.1.2_Multiple_classes
"""

import numpy as np
from scipy.optimize import minimize
from typing import Tuple, List

class MultiClassLDA:
    """多类判别分析（Multi-class Linear Discriminant Analysis, LDA）用于多类分类问题的类。
    
    该类实现了多类线性判别函数 y_k(x) = w_k^T x + w_k0，其中 w_k 为类别 k 的权重向量，w_k0 为偏置。
    """
    
    def __init__(self):
        self.weights = None
        self.biases = None
        self.classes = None

    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """拟合LDA模型。
        
        参数:
        X (np.ndarray): 输入数据，形状为 (n_samples, n_features)
        y (np.ndarray): 标签数据，形状为 (n_samples,)
        """
        self.classes = np.unique(y)
        n_samples, n_features = X.shape
        n_classes = len(self.classes)
        
        X_with_bias = np.hstack([np.ones((n_samples, 1)), X])
        
        def objective(W):
            W = W.reshape((n_classes, n_features + 1))
            scores = X_with_bias @ W.T
            probs = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)
            loss = -np.sum(np.log(probs[np.arange(n_samples), y]))
            return loss
        
        initial_weights = np.zeros((n_classes, n_features + 1)).flatten()
        result = minimize(objective, initial_weights, method='L-BFGS-B')
        
        if not result.success:
            raise ValueError("优化失败")
        
        W_optimal = result.x.reshape((n_classes, n_features + 1))
        self.biases = W_optimal[:, 0]
        self.weights = W_optimal[:, 1:]

    def predict(self, X: np.ndarray) -> np.ndarray:
        """预测新数据的类别。
        
        参数:
        X (np.ndarray): 输入数据，形状为 (n_samples, n_features)
        
        返回:
        np.ndarray: 预测的类别，形状为 (n_samples,)
        """
        scores = X @ self.weights.T + self.biases
        return self.classes[np.argmax(scores, axis=1)]

    def decision_function(self, X: np.ndarray) -> np.ndarray:
        """计算判别函数的值。
        
        参数:
        X (np.ndarray): 输入数据，形状为 (n_samples, n_features)
        
        返回:
        np.ndarray: 判别函数的值，形状为 (n_samples, n_classes)
        """
        return X @ self.weights.T + self.biases

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        """计算模型的准确率。
        
        参数:
        X (np.ndarray): 输入数据，形状为 (n_samples, n_features)
        y (np.ndarray): 标签数据，形状为 (n_samples,)
        
        返回:
        float: 准确率
        """
        predictions = self.predict(X)
        return np.mean(predictions == y)

# 数据生成和模型测试
def generate_data(n_samples: int = 100, n_classes: int = 3) -> Tuple[np.ndarray, np.ndarray]:
    """生成多类分类问题的模拟数据。
    
    参数:
    n_samples (int): 样本数量
    n_classes (int): 类别数量
    
    返回:
    Tuple[np.ndarray, np.ndarray]: 输入数据和标签
    """
    np.random.seed(0)
    X = np.random.randn(n_samples, 2)
    y = np.random.randint(n_classes, size=n_samples)
    return X, y

def main():
    """主函数，用于测试多类LDA模型。
    """
    X, y = generate_data(200, 3)
    lda = MultiClassLDA()
    lda.fit(X, y)
    accuracy = lda.score(X, y)
    print(f"模型的准确率为: {accuracy * 100:.2f}%")

if __name__ == "__main__":
    main()
</code></pre>
  </div>
</body>
</html>
  