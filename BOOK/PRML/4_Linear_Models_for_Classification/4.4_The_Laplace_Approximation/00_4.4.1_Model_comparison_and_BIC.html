
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>4.4.1 Model comparison and BIC</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>00_4.4.1_Model_comparison_and_BIC</h1>
<pre><code>Lecture: 4_Linear_Models_for_Classification/4.4_The_Laplace_Approximation
Content: 00_4.4.1_Model_comparison_and_BIC
</code></pre>
<h3>详解PRML中的4.4.1节：模型比较与BIC</h3>
<p>在《模式识别与机器学习》（Pattern Recognition and Machine Learning, PRML）的第4.4节中，作者介绍了拉普拉斯近似（Laplace Approximation）。具体来说，第4.4.1节探讨了模型比较和贝叶斯信息准则（Bayesian Information Criterion, BIC）。以下是对这一节内容的详细分析。</p>
<h4>模型比较</h4>
<p>模型比较是统计学习中一个重要的主题。在贝叶斯框架下，模型比较基于模型证据（model evidence），即数据在某一特定模型下的边际似然（marginal likelihood）。对于给定的数据集 $ D $ 和一组模型 ${M_i}$，每个模型具有参数 ${\theta_i}$，我们可以定义每个模型的似然函数 $ p(D|\theta_i, M_i) $。通过引入先验分布 $ p(\theta_i|M_i) $，我们可以计算各个模型的证据 $ p(D|M_i) $，该证据用于比较不同的模型。根据贝叶斯定理，模型证据为：</p>
<p>$$ p(D|M_i) = \int p(D|\theta_i, M_i) p(\theta_i|M_i) d\theta_i $$</p>
<p>在实际应用中，直接计算上述积分往往是不可行的，因此需要近似方法。拉普拉斯近似是一种常用的方法，它假设后验分布在其峰值附近呈高斯分布，从而将积分转化为高斯积分。</p>
<h4>拉普拉斯近似</h4>
<p>拉普拉斯近似的关键在于找到后验分布的最大后验估计（MAP估计）$\theta_{\text{MAP}}$，并在此基础上近似后验分布为高斯分布。具体过程如下：</p>
<ol>
<li><strong>寻找MAP估计</strong>：找到使得后验概率 $ p(\theta|D) $ 最大的参数值 $\theta_{\text{MAP}}$。</li>
<li><strong>构造高斯近似</strong>：在 $\theta_{\text{MAP}}$ 附近，用高斯分布来近似后验分布，其均值为 $\theta_{\text{MAP}}$，协方差矩阵为负对数后验分布的二阶导数的逆。</li>
</ol>
<p>利用上述近似，可以得到模型证据的近似值：</p>
<p>$$ \ln p(D|M_i) \approx \ln p(D|\theta_{\text{MAP}}, M_i) + \ln p(\theta_{\text{MAP}}|M_i) - \frac{M}{2} \ln N $$</p>
<p>其中，$ M $ 为参数的维数，$ N $ 为数据点的数量。第一项为对数似然，第二项为先验分布的对数，最后一项为对模型复杂度的惩罚项。</p>
<h4>贝叶斯信息准则（BIC）</h4>
<p>贝叶斯信息准则（BIC）是一种简化的模型选择准则，近似于拉普拉斯近似。其表达式为：</p>
<p>$$ \text{BIC} = -2 \ln p(D|\theta_{\text{MAP}}, M_i) + M \ln N $$</p>
<p>BIC在大样本情况下提供了一个方便的模型选择工具，其中包含了对模型复杂度的惩罚，防止过拟合。BIC的优点在于计算简单，只需最大似然估计即可。</p>
<h3>结论</h3>
<p>通过上述分析可以看出，模型比较和BIC在统计学习和贝叶斯方法中具有重要的地位。拉普拉斯近似提供了一种计算模型证据的有效方法，而BIC则提供了一个简化的模型选择准则。掌握这些方法有助于在实际问题中选择合适的模型，提高预测和分类的准确性。</p>

    <h3>Python 文件</h3>
    <pre><code># 00_4.4.1_Model_comparison_and_BIC

"""
Lecture: 4_Linear_Models_for_Classification/4.4_The_Laplace_Approximation
Content: 00_4.4.1_Model_comparison_and_BIC
"""

</code></pre>
  </div>
</body>
</html>
  