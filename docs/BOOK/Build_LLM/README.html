
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>README</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>Build Large Language Model</h1>
<p>这是一个关于Build Large Language Model的目录结构。</p>
<ul>
<li>https://github.com/rasbt/LLMs-from-scratch</li>
<li>https://chatgpt.com/share/b8ecb0bb-3f85-48ff-aaae-768851d8910e</li>
</ul>
<h1>2_Understanding_Large_Language_Models</h1>
<ul>
<li><a href=".//2_Understanding_Large_Language_Models/00_2.1_What_is_a_LLM.py">00_2.1_What_is_a_LLM</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/00_2.1_What_is_a_LLM.md">00_2.1_What_is_a_LLM</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/01_2.2_Applications_of_LLMs.py">01_2.2_Applications_of_LLMs</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/01_2.2_Applications_of_LLMs.md">01_2.2_Applications_of_LLMs</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/02_2.3_Stages_of_building_and_using_LLMs.py">02_2.3_Stages_of_building_and_using_LLMs</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/02_2.3_Stages_of_building_and_using_LLMs.md">02_2.3_Stages_of_building_and_using_LLMs</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/03_2.4_Utilizing_large_datasets.py">03_2.4_Utilizing_large_datasets</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/03_2.4_Utilizing_large_datasets.md">03_2.4_Utilizing_large_datasets</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/04_2.5_A_closer_look_at_the_GPT_architecture.py">04_2.5_A_closer_look_at_the_GPT_architecture</a></li>
<li><a href=".//2_Understanding_Large_Language_Models/04_2.5_A_closer_look_at_the_GPT_architecture.md">04_2.5_A_closer_look_at_the_GPT_architecture</a></li>
</ul>
<h1>3_Working_with_Text_Data</h1>
<ul>
<li><a href=".//3_Working_with_Text_Data/00_3.1_Understanding_word_embeddings.py">00_3.1_Understanding_word_embeddings</a></li>
<li><a href=".//3_Working_with_Text_Data/00_3.1_Understanding_word_embeddings.md">00_3.1_Understanding_word_embeddings</a></li>
<li><a href=".//3_Working_with_Text_Data/01_3.2_Tokenizing_text.py">01_3.2_Tokenizing_text</a></li>
<li><a href=".//3_Working_with_Text_Data/01_3.2_Tokenizing_text.md">01_3.2_Tokenizing_text</a></li>
<li><a href=".//3_Working_with_Text_Data/02_3.3_Converting_tokens_into_token_IDs.py">02_3.3_Converting_tokens_into_token_IDs</a></li>
<li><a href=".//3_Working_with_Text_Data/02_3.3_Converting_tokens_into_token_IDs.md">02_3.3_Converting_tokens_into_token_IDs</a></li>
<li><a href=".//3_Working_with_Text_Data/03_3.4_Adding_special_context_tokens.py">03_3.4_Adding_special_context_tokens</a></li>
<li><a href=".//3_Working_with_Text_Data/03_3.4_Adding_special_context_tokens.md">03_3.4_Adding_special_context_tokens</a></li>
<li><a href=".//3_Working_with_Text_Data/04_3.5_Byte_pair_encoding.py">04_3.5_Byte_pair_encoding</a></li>
<li><a href=".//3_Working_with_Text_Data/04_3.5_Byte_pair_encoding.md">04_3.5_Byte_pair_encoding</a></li>
</ul>
<h1>4_Coding_Attention_Mechanisms</h1>
<ul>
<li><a href=".//4_Coding_Attention_Mechanisms/00_4.1_Introduction_to_attention_mechanisms.py">00_4.1_Introduction_to_attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/00_4.1_Introduction_to_attention_mechanisms.md">00_4.1_Introduction_to_attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/01_4.2_Self_attention_mechanisms.py">01_4.2_Self-attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/01_4.2_Self_attention_mechanisms.md">01_4.2_Self-attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/02_4.3_Multi_head_attention_mechanisms.py">02_4.3_Multi-head_attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/02_4.3_Multi_head_attention_mechanisms.md">02_4.3_Multi-head_attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/03_4.4_Encoder_and_decoder_architectures.py">03_4.4_Encoder_and_decoder_architectures</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/03_4.4_Encoder_and_decoder_architectures.md">03_4.4_Encoder_and_decoder_architectures</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/04_4.5_Implementing_self_attention_mechanisms.py">04_4.5_Implementing_self-attention_mechanisms</a></li>
<li><a href=".//4_Coding_Attention_Mechanisms/04_4.5_Implementing_self_attention_mechanisms.md">04_4.5_Implementing_self-attention_mechanisms</a></li>
</ul>
<h1>5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text</h1>
<ul>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/00_5.1_Basics_of_GPT_model.py">00_5.1_Basics_of_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/00_5.1_Basics_of_GPT_model.md">00_5.1_Basics_of_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/01_5.2_Implementing_GPT_model.py">01_5.2_Implementing_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/01_5.2_Implementing_GPT_model.md">01_5.2_Implementing_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/02_5.3_Training_GPT_model.py">02_5.3_Training_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/02_5.3_Training_GPT_model.md">02_5.3_Training_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/03_5.4_Applications_of_GPT_model.py">03_5.4_Applications_of_GPT_model</a></li>
<li><a href=".//5_Implementing_a_GPT_model_from_Scratch_To_Generate_Text/03_5.4_Applications_of_GPT_model.md">03_5.4_Applications_of_GPT_model</a></li>
</ul>
<h1>6_Pretraining_on_Unlabeled_Data</h1>
<ul>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/00_6.1_Concept_of_pretraining.py">00_6.1_Concept_of_pretraining</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/00_6.1_Concept_of_pretraining.md">00_6.1_Concept_of_pretraining</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/01_6.2_Data_preparation.py">01_6.2_Data_preparation</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/01_6.2_Data_preparation.md">01_6.2_Data_preparation</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/02_6.3_Pretraining_process.py">02_6.3_Pretraining_process</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/02_6.3_Pretraining_process.md">02_6.3_Pretraining_process</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/03_6.4_Evaluating_pretrained_model.py">03_6.4_Evaluating_pretrained_model</a></li>
<li><a href=".//6_Pretraining_on_Unlabeled_Data/03_6.4_Evaluating_pretrained_model.md">03_6.4_Evaluating_pretrained_model</a></li>
</ul>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  