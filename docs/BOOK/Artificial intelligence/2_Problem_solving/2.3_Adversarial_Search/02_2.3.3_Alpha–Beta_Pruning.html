
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>2.3.3 Alpha–Beta Pruning</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>02_2.3.3_Alpha–Beta_Pruning</h1>
<pre><code>
Lecture: 2_Problem-solving/2.3_Adversarial_Search
Content: 02_2.3.3_Alpha–Beta_Pruning

</code></pre>
<h3>2.3.3 Alpha–Beta 剪枝</h3>
<p>在博弈论和对抗性搜索中，Alpha–Beta 剪枝（Alpha–Beta Pruning）是一种用于优化最小最大算法（Minimax Algorithm）的技术。它通过剪去那些不影响最终决策的分支，大大减少了需要评估的节点数量，从而提高搜索效率。在本节中，我们将深入探讨Alpha–Beta 剪枝的原理、实现以及其在实际应用中的重要性。</p>
<h4>1. 引言</h4>
<p>Alpha–Beta 剪枝的核心思想是通过在搜索过程中维护两个值：α和β，来剪除那些不可能影响最终决策的节点。α值表示当前节点的最大下界，β值表示当前节点的最小上界。当在某个节点发现其子节点的值不可能影响最终决策时，就可以停止进一步搜索该子节点。</p>
<h4>2. 最小最大算法回顾</h4>
<p>在最小最大算法中，玩家交替进行动作，试图最大化自己的最小收益。具体步骤如下：</p>
<ul>
<li><strong>最大化层</strong>（Max Layer）：当前玩家选择能够最大化其收益的动作。</li>
<li><strong>最小化层</strong>（Min Layer）：对手选择能够最小化当前玩家收益的动作。</li>
</ul>
<p>最小最大算法通过递归地计算博弈树中各个节点的值，最终确定最佳策略。然而，这种方法在复杂的博弈中可能非常耗时。</p>
<h4>3. Alpha–Beta 剪枝原理</h4>
<p>Alpha–Beta 剪枝通过在搜索过程中维护两个值来优化最小最大算法：</p>
<ul>
<li><strong>α（Alpha）</strong>：当前节点的最大值下界。最大化层中，α值初始化为负无穷，在遍历子节点时更新。</li>
<li><strong>β（Beta）</strong>：当前节点的最小值上界。最小化层中，β值初始化为正无穷，在遍历子节点时更新。</li>
</ul>
<p>剪枝规则如下：</p>
<ul>
<li><strong>在最大化层</strong>：如果当前子节点的值大于或等于β，则可以剪掉剩余的子节点，因为对手不会允许达到这个值。</li>
<li><strong>在最小化层</strong>：如果当前子节点的值小于或等于α，则可以剪掉剩余的子节点，因为当前玩家不会选择使其收益低于α的动作。</li>
</ul>
<h4>4. Alpha–Beta 剪枝的效率</h4>
<p>Alpha–Beta 剪枝显著提高了最小最大算法的效率。理论上，Alpha–Beta 剪枝能够将完全展开的博弈树的搜索复杂度从 O(b^d) 降低到 O(b^(d/2))，其中 b 是每个节点的分支因子，d 是搜索深度。这意味着在最佳情况下，Alpha–Beta 剪枝可以使搜索效率提高一倍。</p>
<h4>5. Alpha–Beta 剪枝的伪代码</h4>
<p>以下是Alpha–Beta 剪枝算法的伪代码：</p>
<pre><code>function ALPHA-BETA-SEARCH(state) returns an action
    v = MAX-VALUE(state, -∞, +∞)
    return the action in ACTIONS(state) with value v

function MAX-VALUE(state, α, β) returns a utility value
    if TERMINAL-TEST(state) then return UTILITY(state)
    v = -∞
    for each a in ACTIONS(state) do
        v = MAX(v, MIN-VALUE(RESULT(state, a), α, β))
        if v ≥ β then return v
        α = MAX(α, v)
    return v

function MIN-VALUE(state, α, β) returns a utility value
    if TERMINAL-TEST(state) then return UTILITY(state)
    v = +∞
    for each a in ACTIONS(state) do
        v = MIN(v, MAX-VALUE(RESULT(state, a), α, β))
        if v ≤ α then return v
        β = MIN(β, v)
    return v
</code></pre>
<p>在这个伪代码中，<code>MAX-VALUE</code>和<code>MIN-VALUE</code>函数递归地评估博弈树的节点，并根据α和β的值进行剪枝。</p>
<h4>6. 应用实例</h4>
<p>Alpha–Beta 剪枝广泛应用于各种博弈和对抗性游戏中，如国际象棋、围棋和跳棋等。在这些游戏中，玩家需要在有限时间内评估大量的可能走法，Alpha–Beta 剪枝通过减少需要评估的节点数量，使得玩家能够在合理的时间内作出最佳决策。</p>
<h4>7. 实际应用中的挑战</h4>
<p>尽管Alpha–Beta 剪枝在理论上能够显著提高搜索效率，但在实际应用中仍然面临一些挑战：</p>
<ul>
<li><strong>节点排序</strong>：Alpha–Beta 剪枝的效率依赖于节点的访问顺序。在实际应用中，通过启发式方法对节点进行排序，可以最大化剪枝效果。</li>
<li><strong>搜索深度限制</strong>：在非常复杂的博弈中，完全展开的博弈树仍然过于庞大，因此需要结合深度限制和迭代加深搜索等方法。</li>
<li><strong>资源限制</strong>：计算资源和时间的限制使得在实际应用中需要对搜索过程进行优化和调整，以达到平衡。</li>
</ul>
<h3>总结</h3>
<p>Alpha–Beta 剪枝是优化最小最大算法的一种关键技术，通过剪除不必要的分支，大大提高了搜索效率。在对抗性游戏和博弈中，Alpha–Beta 剪枝帮助玩家在有限的时间内作出最佳决策。尽管在实际应用中面临一些挑战，但通过结合其他优化方法，Alpha–Beta 剪枝仍然是解决复杂博弈问题的有效工具。</p>

    <h3>Python 文件</h3>
    <pre><code># 02_2.3.3_Alpha–Beta_Pruning

"""

Lecture: 2_Problem-solving/2.3_Adversarial_Search
Content: 02_2.3.3_Alpha–Beta_Pruning

"""

import numpy as np
from typing import List, Tuple, Callable, Any

class GameState:
    """
    游戏状态类，用于表示博弈中的一个状态。
    """
    def __init__(self, board: np.ndarray, player: int):
        """
        初始化游戏状态。

        参数:
        - board (np.ndarray): 当前的棋盘状态。
        - player (int): 当前玩家（1或-1）。
        """
        self.board = board
        self.player = player

    def get_legal_actions(self) -> List[Tuple[int, int]]:
        """
        获取当前状态下的所有合法动作。

        返回:
        - List[Tuple[int, int]]: 合法动作的列表。
        """
        raise NotImplementedError("子类应实现 get_legal_actions 方法。")

    def apply_action(self, action: Tuple[int, int]) -> 'GameState':
        """
        在当前状态下应用一个动作，返回新的游戏状态。

        参数:
        - action (Tuple[int, int]): 要应用的动作。

        返回:
        - GameState: 应用动作后的新游戏状态。
        """
        raise NotImplementedError("子类应实现 apply_action 方法。")

    def is_terminal(self) -> bool:
        """
        判断当前状态是否为终局状态。

        返回:
        - bool: 如果是终局状态，返回 True；否则返回 False。
        """
        raise NotImplementedError("子类应实现 is_terminal 方法。")

    def get_utility(self) -> int:
        """
        获取当前状态的效用值（仅对终局状态调用）。

        返回:
        - int: 当前状态的效用值。
        """
        raise NotImplementedError("子类应实现 get_utility 方法。")


class AlphaBetaPruning:
    """
    Alpha-Beta剪枝算法类。
    """
    def __init__(self, initial_state: GameState):
        """
        初始化Alpha-Beta剪枝算法。

        参数:
        - initial_state (GameState): 初始游戏状态。
        """
        self.initial_state = initial_state

    def alpha_beta_search(self) -> Tuple[Any, int]:
        """
        执行Alpha-Beta剪枝搜索，返回最佳动作及其效用值。

        返回:
        - Tuple[Any, int]: 最佳动作及其效用值。
        """
        def max_value(state: GameState, alpha: float, beta: float) -> int:
            if state.is_terminal():
                return state.get_utility()
            value = -np.inf
            for action in state.get_legal_actions():
                value = max(value, min_value(state.apply_action(action), alpha, beta))
                if value >= beta:
                    return value
                alpha = max(alpha, value)
            return value

        def min_value(state: GameState, alpha: float, beta: float) -> int:
            if state.is_terminal():
                return state.get_utility()
            value = np.inf
            for action in state.get_legal_actions():
                value = min(value, max_value(state.apply_action(action), alpha, beta))
                if value <= alpha:
                    return value
                beta = min(beta, value)
            return value

        best_action = None
        best_value = -np.inf
        for action in self.initial_state.get_legal_actions():
            value = min_value(self.initial_state.apply_action(action), -np.inf, np.inf)
            if value > best_value:
                best_value = value
                best_action = action
        return best_action, best_value

# 示例游戏状态类（以井字棋为例）
class TicTacToeState(GameState):
    """
    井字棋游戏状态类。
    """
    def get_legal_actions(self) -> List[Tuple[int, int]]:
        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]

    def apply_action(self, action: Tuple[int, int]) -> 'TicTacToeState':
        new_board = np.copy(self.board)
        new_board[action] = self.player
        return TicTacToeState(new_board, -self.player)

    def is_terminal(self) -> bool:
        # 检查行、列和对角线是否有相同的标记
        for i in range(3):
            if abs(np.sum(self.board[i, :])) == 3 or abs(np.sum(self.board[:, i])) == 3:
                return True
        if abs(np.sum(self.board.diagonal())) == 3 or abs(np.sum(np.fliplr(self.board).diagonal())) == 3:
            return True
        # 检查是否还有空位
        if not np.any(self.board == 0):
            return True
        return False

    def get_utility(self) -> int:
        for i in range(3):
            if np.sum(self.board[i, :]) == 3 or np.sum(self.board[:, i]) == 3:
                return 1
            if np.sum(self.board[i, :]) == -3 or np.sum(self.board[:, i]) == -3:
                return -1
        if np.sum(self.board.diagonal()) == 3 or np.sum(np.fliplr(self.board).diagonal()) == 3:
            return 1
        if np.sum(self.board.diagonal()) == -3 or np.sum(np.fliplr(self.board).diagonal()) == -3:
            return -1
        return 0

# 示例用法：
if __name__ == "__main__":
    # 初始化井字棋初始状态
    initial_board = np.zeros((3, 3), dtype=int)
    initial_state = TicTacToeState(initial_board, 1)

    # 创建Alpha-Beta剪枝算法实例
    alpha_beta = AlphaBetaPruning(initial_state)

    # 执行Alpha-Beta剪枝搜索
    best_action, best_value = alpha_beta.alpha_beta_search()
    print(f"最佳动作: {best_action}, 最优值: {best_value}")
</code></pre>
  </div>
</body>
</html>
  