
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>02-Kmeans</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <blockquote>
<p>详细手推Kmeans</p>
</blockquote>
<h3>K-means聚类算法详细推导</h3>
<p>K-means是一种非监督学习算法，用于将数据分成 $ k $ 个簇。它的目标是通过迭代优化来最小化簇内样本的平方误差和（Sum of Squared Errors, SSE）。</p>
<h4>算法步骤</h4>
<ol>
<li>
<p><strong>初始化</strong>：</p>
<ul>
<li>随机选择 $ k $ 个簇中心（质心）。</li>
</ul>
</li>
<li>
<p><strong>分配样本到最近的簇中心</strong>：</p>
<ul>
<li>对于每个样本 $ x_i $，计算它到每个簇中心的距离，将其分配到距离最近的簇。</li>
</ul>
</li>
<li>
<p><strong>更新簇中心</strong>：</p>
<ul>
<li>计算每个簇的中心（均值），即所有属于该簇的样本的均值。</li>
</ul>
</li>
<li>
<p><strong>重复步骤2和步骤3</strong>，直到簇中心不再变化或变化很小。</p>
</li>
</ol>
<h4>数学推导</h4>
<p>假设我们有 $ n $ 个样本 $ {x_1, x_2, \ldots, x_n} $，每个样本都是 $ d $ 维向量，目标是将它们分成 $ k $ 个簇。</p>
<ol>
<li>
<p><strong>初始化簇中心</strong>：</p>
<ul>
<li>随机选择 $ k $ 个初始簇中心 $ {\mu_1, \mu_2, \ldots, \mu_k} $。</li>
</ul>
</li>
<li>
<p><strong>样本分配</strong>：</p>
<ul>
<li>对于每个样本 $ x_i $，计算它到每个簇中心的距离：
$$
d(x_i, \mu_j) = |x_i - \mu_j|^2
$$</li>
<li>将样本 $ x_i $ 分配到距离最近的簇 $ C_j $：
$$
C_j = { x_i : |x_i - \mu_j|^2 \leq |x_i - \mu_l|^2, \forall l = 1, 2, \ldots, k }
$$</li>
</ul>
</li>
<li>
<p><strong>更新簇中心</strong>：</p>
<ul>
<li>对于每个簇 $ C_j $，计算新的簇中心（均值）：
$$
\mu_j = \frac{1}{|C_j|} \sum_{x_i \in C_j} x_i
$$</li>
</ul>
</li>
<li>
<p><strong>重复步骤2和步骤3</strong>，直到簇中心不再变化或变化很小。</p>
</li>
</ol>
<h4>目标函数</h4>
<p>K-means的目标是最小化簇内样本的平方误差和（SSE）：
$$
J = \sum_{j=1}^{k} \sum_{x_i \in C_j} |x_i - \mu_j|^2
$$</p>
<p>通过迭代优化样本分配和簇中心更新，K-means算法试图找到一个局部最优解，使得SSE最小。</p>
<h3>示例</h3>
<p>假设我们有一组二维数据点：</p>
<p>$$
{(1,2), (2,3), (3,4), (8,7), (9,8), (10,9)}
$$</p>
<p>我们希望将它们分成 $ k = 2 $ 个簇。</p>
<ol>
<li>
<p><strong>初始化</strong>：</p>
<ul>
<li>随机选择两个初始簇中心，如 $ \mu_1 = (1,2) $ 和 $ \mu_2 = (8,7) $。</li>
</ul>
</li>
<li>
<p><strong>样本分配</strong>：</p>
<ul>
<li>计算每个样本到簇中心的距离，并进行分配。</li>
<li>例如，点 (1,2) 到 $ \mu_1 $ 的距离为 0，到 $ \mu_2 $ 的距离为 $ \sqrt{(1-8)^2 + (2-7)^2} = \sqrt{49 + 25} = 8.6 $，因此 (1,2) 分配给簇 $ C_1 $。</li>
</ul>
</li>
<li>
<p><strong>更新簇中心</strong>：</p>
<ul>
<li>计算每个簇的新中心。</li>
<li>例如，新的 $ \mu_1 $ 是 $ C_1 $ 中所有点的均值。</li>
</ul>
</li>
<li>
<p><strong>重复</strong>：</p>
<ul>
<li>继续分配样本到新的簇中心，并更新簇中心，直到簇中心不再变化。</li>
</ul>
</li>
</ol>
<h3>参考资料</h3>
<ol>
<li>
<p><strong>Pattern Recognition and Machine Learning by Christopher M. Bishop</strong>：</p>
<ul>
<li>提供了K-means算法的详细理论和推导。</li>
<li><a href="https://www.springer.com/gp/book/9780387310732">书籍链接</a></li>
</ul>
</li>
<li>
<p><strong>The Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</strong>：</p>
<ul>
<li>介绍了K-means聚类及其他机器学习算法。</li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">书籍链接</a></li>
</ul>
</li>
</ol>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  