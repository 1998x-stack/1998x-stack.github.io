
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>08-multi LR</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <blockquote>
<p>逻辑回归如何处理多分类？</p>
</blockquote>
<p>逻辑回归（Logistic Regression）通常用于二分类问题，但可以通过扩展方法处理多分类问题。以下是几种常用的方法：</p>
<h3>1. 一对多（One-vs-Rest, OvR）</h3>
<p><strong>原理</strong>：</p>
<ul>
<li>将多分类问题转化为多个二分类问题。对于每一个类别，训练一个分类器，将该类别作为正类，其他类别作为负类。</li>
</ul>
<p><strong>步骤</strong>：</p>
<ol>
<li>对于每个类别 $k$，训练一个二分类器 $h_k(\mathbf{x})$，假设当前类别为正类，其余类别为负类。</li>
<li>对于一个新的输入 $\mathbf{x}$，计算所有分类器的输出，选择输出最大的类别作为预测类别。</li>
</ol>
<p><strong>优势</strong>：</p>
<ul>
<li>简单易实现，适用于大多数逻辑回归模型。</li>
<li>可以并行训练多个二分类器。</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>对于每个输入样本，需计算所有分类器的输出，计算量较大。</li>
<li>如果类别之间不平衡，可能导致性能不佳。</li>
</ul>
<h3>2. 一对一（One-vs-One, OvO）</h3>
<p><strong>原理</strong>：</p>
<ul>
<li>将多分类问题转化为多个二分类问题。每个分类器只在两个类别之间进行分类。</li>
</ul>
<p><strong>步骤</strong>：</p>
<ol>
<li>对于每对类别 $ (i, j) $，训练一个分类器 $ h_{i,j}(\mathbf{x}) $，只使用类别 $i$ 和类别 $j$ 的样本。</li>
<li>对于一个新的输入 $\mathbf{x}$，计算所有分类器的输出，选择得票最多的类别作为预测类别。</li>
</ol>
<p><strong>优势</strong>：</p>
<ul>
<li>训练样本较少，每个分类器只需处理两个类别的数据。</li>
<li>适用于类别数较少的情况。</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>分类器数量随类别数的平方增加，对于类别数较多的情况，计算和存储开销较大。</li>
<li>需要处理多个分类器的投票结果。</li>
</ul>
<h3>3. Softmax回归（Multinomial Logistic Regression）</h3>
<p><strong>原理</strong>：</p>
<ul>
<li>将逻辑回归直接扩展到多分类问题。Softmax回归模型为每个类别计算一个概率，选择概率最大的类别作为预测类别。</li>
</ul>
<p><strong>步骤</strong>：</p>
<ol>
<li>假设有 $K$ 个类别，对于每个类别 $k$，计算线性组合：
$$
z_k = \mathbf{w}_k^T \mathbf{x}
$$</li>
<li>计算每个类别的概率：
$$
P(y=k|\mathbf{x}) = \frac{\exp(z_k)}{\sum_{j=1}^{K} \exp(z_j)}
$$</li>
<li>对于一个新的输入 $\mathbf{x}$，选择概率最大的类别作为预测类别。</li>
</ol>
<p><strong>优势</strong>：</p>
<ul>
<li>直接建模多分类问题，计算效率较高。</li>
<li>可以输出每个类别的概率，适用于需要概率输出的应用场景。</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>对于类别数较多的情况，计算和存储开销较大。</li>
<li>需要处理多分类交叉熵损失函数，优化难度较大。</li>
</ul>
<h3>实现示例（使用scikit-learn）</h3>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 加载数据集
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 使用One-vs-Rest方法
clf_ovr = LogisticRegression(multi_class='ovr', solver='liblinear')
clf_ovr.fit(X_train, y_train)
y_pred_ovr = clf_ovr.predict(X_test)
print(&quot;Accuracy with One-vs-Rest:&quot;, accuracy_score(y_test, y_pred_ovr))

# 使用Softmax回归
clf_softmax = LogisticRegression(multi_class='multinomial', solver='lbfgs')
clf_softmax.fit(X_train, y_train)
y_pred_softmax = clf_softmax.predict(X_test)
print(&quot;Accuracy with Softmax:&quot;, accuracy_score(y_test, y_pred_softmax))
</code></pre>
<h3>参考文献</h3>
<ol>
<li>
<p><strong>Pattern Recognition and Machine Learning by Christopher M. Bishop</strong>：</p>
<ul>
<li>提供了逻辑回归和多分类扩展的详细理论和推导。</li>
<li><a href="https://www.springer.com/gp/book/9780387310732">书籍链接</a></li>
</ul>
</li>
<li>
<p><strong>The Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</strong>：</p>
<ul>
<li>介绍了逻辑回归、多分类问题及其他机器学习算法。</li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">书籍链接</a></li>
</ul>
</li>
<li>
<p><strong>scikit-learn文档</strong>：</p>
<ul>
<li>提供了逻辑回归、多分类扩展的实际实现和案例。</li>
<li><a href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">scikit-learn文档</a></li>
</ul>
</li>
</ol>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  