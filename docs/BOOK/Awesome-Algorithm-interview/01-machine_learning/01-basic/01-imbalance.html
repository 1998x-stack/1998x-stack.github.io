
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>01-imbalance</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <blockquote>
<p>机器学习中，样本不均衡如何处理？</p>
</blockquote>
<p>样本不均衡是机器学习中常见的问题，特别是在分类任务中。当一个类别的样本数量远远少于其他类别时，模型可能会偏向于预测样本较多的类别。以下是几种常用的处理样本不均衡的方法：</p>
<h3>1. 数据层面的解决方案</h3>
<ol>
<li>
<p><strong>欠采样（Under-sampling）</strong>：</p>
<ul>
<li>减少多数类样本的数量，使其与少数类样本的数量平衡。常见的方法包括随机欠采样和近邻清除（NearMiss）。</li>
</ul>
<p><strong>优点</strong>：简单易行，减少计算负担。
<strong>缺点</strong>：可能丢失重要信息，导致模型性能下降。</p>
</li>
<li>
<p><strong>过采样（Over-sampling）</strong>：</p>
<ul>
<li>增加少数类样本的数量，使其与多数类样本的数量平衡。常见的方法包括随机过采样和合成少数类过采样技术（SMOTE）。</li>
</ul>
<p><strong>优点</strong>：保留多数类的所有数据，增加少数类样本的数量。
<strong>缺点</strong>：可能导致过拟合，增加计算负担。</p>
</li>
<li>
<p><strong>混合采样（Hybrid Sampling）</strong>：</p>
<ul>
<li>结合欠采样和过采样的方法，如SMOTE+ENN（Edited Nearest Neighbors）。</li>
</ul>
<p><strong>优点</strong>：结合两者优点，效果较好。
<strong>缺点</strong>：复杂度增加，需要调试多个参数。</p>
</li>
</ol>
<h3>2. 算法层面的解决方案</h3>
<ol>
<li>
<p><strong>调整类权重</strong>：</p>
<ul>
<li>在模型训练时，为少数类样本赋予更高的权重，以平衡不同类别对损失函数的贡献。许多机器学习算法（如SVM、决策树和神经网络）都支持类权重调整。</li>
</ul>
<p><strong>优点</strong>：不改变数据分布，直接在训练过程中调整。
<strong>缺点</strong>：需要选择合适的权重比例，可能需要多次试验。</p>
</li>
<li>
<p><strong>集成方法（Ensemble Methods）</strong>：</p>
<ul>
<li>使用集成方法如提升树（Boosting）和袋装（Bagging）来平衡样本不均衡问题。特别是提升方法（如AdaBoost、Gradient Boosting）在处理不均衡数据时效果较好。</li>
</ul>
<p><strong>优点</strong>：集成方法通常能提升模型的泛化能力。
<strong>缺点</strong>：训练时间较长，模型复杂度增加。</p>
</li>
</ol>
<h3>3. 评价指标调整</h3>
<ol>
<li>
<p><strong>选择合适的评价指标</strong>：</p>
<ul>
<li>在不均衡数据集上，传统的准确率（Accuracy）往往不适用。可以选择其他评价指标如精确率（Precision）、召回率（Recall）、F1-score和ROC AUC（Receiver Operating Characteristic Area Under Curve）等。</li>
</ul>
<p><strong>优点</strong>：更加全面地评价模型性能。
<strong>缺点</strong>：需要理解和解释多个指标。</p>
</li>
</ol>
<h3>4. 其他高级技术</h3>
<ol>
<li>
<p><strong>生成对抗网络（GANs）</strong>：</p>
<ul>
<li>使用生成对抗网络生成少数类样本，从而增加少数类样本的数量。</li>
</ul>
<p><strong>优点</strong>：生成高质量的少数类样本。
<strong>缺点</strong>：训练复杂，需要大量计算资源。</p>
</li>
<li>
<p><strong>集成样本合成</strong>：</p>
<ul>
<li>结合SMOTE和集成方法，如SMOTEBoost，将样本合成与提升方法结合。</li>
</ul>
<p><strong>优点</strong>：有效结合数据层面和算法层面的优势。
<strong>缺点</strong>：算法复杂度较高，调试难度大。</p>
</li>
</ol>
<h3>参考文献</h3>
<ol>
<li>
<p><strong>Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning</strong>:</p>
<ul>
<li>提供了多个处理样本不均衡问题的技术实现。</li>
<li><a href="https://arxiv.org/abs/1609.06570">文献链接</a></li>
</ul>
</li>
<li>
<p><strong>SMOTE: Synthetic Minority Over-sampling Technique</strong>:</p>
<ul>
<li>详细介绍了SMOTE方法及其变种。</li>
<li><a href="https://www.jair.org/index.php/jair/article/view/10302">文献链接</a></li>
</ul>
</li>
<li>
<p><strong>Class Imbalance in Machine Learning</strong>:</p>
<ul>
<li>文章详细讨论了处理样本不均衡的各种方法和技巧。</li>
<li><a href="https://towardsdatascience.com/class-imbalance-in-machine-learning-8e4d41a25f3e">文章链接</a></li>
</ul>
</li>
</ol>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  