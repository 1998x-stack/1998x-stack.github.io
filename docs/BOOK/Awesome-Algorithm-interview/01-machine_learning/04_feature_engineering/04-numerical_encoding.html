
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>04-numerical encoding</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <blockquote>
<p>连续值变量如何构造特征？</p>
</blockquote>
<p>构造连续值变量的特征是提高机器学习模型性能的关键步骤。通过特征工程，可以从原始数据中提取更多有用的信息，使模型更好地捕捉数据中的模式和趋势。以下是几种常用的连续值变量特征构造方法：</p>
<h3>1. 标准化和归一化</h3>
<p><strong>标准化（Standardization）</strong>：
将特征值转化为均值为0、标准差为1的分布。
$$ z = \frac{x - \mu}{\sigma} $$
其中，$ x $ 是原始值，$ \mu $ 是均值，$ \sigma $ 是标准差。</p>
<p><strong>归一化（Normalization）</strong>：
将特征值缩放到[0, 1]范围内。
$$ x' = \frac{x - \min(x)}{\max(x) - \min(x)} $$</p>
<p><strong>优点</strong>：</p>
<ul>
<li>提高模型收敛速度。</li>
<li>防止某些特征对模型的影响过大。</li>
</ul>
<p><strong>实现示例</strong>：</p>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np

# 示例数据
data = np.array([[1, 2], [3, 4], [5, 6]])

# 标准化
scaler = StandardScaler()
standardized_data = scaler.fit_transform(data)

# 归一化
minmax_scaler = MinMaxScaler()
normalized_data = minmax_scaler.fit_transform(data)

print(&quot;标准化后的数据：\n&quot;, standardized_data)
print(&quot;归一化后的数据：\n&quot;, normalized_data)
</code></pre>
<h3>2. 多项式特征（Polynomial Features）</h3>
<p><strong>原理</strong>：
将原始特征扩展为多项式特征，用于捕捉非线性关系。
$$ x_1, x_2 \rightarrow x_1, x_2, x_1^2, x_2^2, x_1 x_2 $$</p>
<p><strong>优点</strong>：</p>
<ul>
<li>提高模型的表达能力，捕捉非线性关系。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>可能导致维度灾难，增加计算复杂度。</li>
</ul>
<p><strong>实现示例</strong>：</p>
<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures

# 示例数据
data = np.array([[1, 2], [3, 4], [5, 6]])

# 多项式特征
poly = PolynomialFeatures(degree=2, include_bias=False)
poly_features = poly.fit_transform(data)

print(&quot;多项式特征：\n&quot;, poly_features)
</code></pre>
<h3>3. 交互特征（Interaction Features）</h3>
<p><strong>原理</strong>：
通过组合不同特征生成交互特征，捕捉特征之间的交互作用。
$$ x_1, x_2 \rightarrow x_1 x_2 $$</p>
<p><strong>优点</strong>：</p>
<ul>
<li>能捕捉到特征之间的相互作用，提高模型性能。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>特征数量增加，可能导致过拟合。</li>
</ul>
<p><strong>实现示例</strong>：</p>
<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures

# 示例数据
data = np.array([[1, 2], [3, 4], [5, 6]])

# 交互特征
poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
interaction_features = poly.fit_transform(data)

print(&quot;交互特征：\n&quot;, interaction_features)
</code></pre>
<h3>4. 分箱（Binning）</h3>
<p><strong>原理</strong>：
将连续值变量分成若干个区间，每个区间视为一个类别。</p>
<p><strong>优点</strong>：</p>
<ul>
<li>提高模型的鲁棒性，减少噪声影响。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>可能导致信息丢失，依赖于区间划分方式。</li>
</ul>
<p><strong>实现示例</strong>：</p>
<pre><code class="language-python">import pandas as pd

# 示例数据
data = pd.DataFrame({'value': [1, 7, 5, 4, 6, 2, 3, 8]})

# 分箱
data['binned'] = pd.cut(data['value'], bins=3, labels=[&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;])

print(&quot;分箱后的数据：\n&quot;, data)
</code></pre>
<h3>5. 时间特征提取</h3>
<p><strong>原理</strong>：
从时间数据中提取有用的特征，如年、月、日、小时、星期等。</p>
<p><strong>优点</strong>：</p>
<ul>
<li>能捕捉时间序列数据中的周期性和趋势。</li>
</ul>
<p><strong>实现示例</strong>：</p>
<pre><code class="language-python">import pandas as pd

# 示例时间数据
data = pd.DataFrame({'datetime': pd.date_range('2023-01-01', periods=5, freq='D')})

# 提取时间特征
data['year'] = data['datetime'].dt.year
data['month'] = data['datetime'].dt.month
data['day'] = data['datetime'].dt.day
data['weekday'] = data['datetime'].dt.weekday

print(&quot;提取时间特征后的数据：\n&quot;, data)
</code></pre>
<h3>参考文献</h3>
<ol>
<li>
<p><strong>Feature Engineering and Selection: A Practical Approach for Predictive Models by Max Kuhn and Kjell Johnson</strong>：</p>
<ul>
<li>提供了特征工程的详细理论和方法。</li>
<li><a href="https://www.amazon.com/Feature-Engineering-Selection-Approach-Predictive/dp/1491953241">书籍链接</a></li>
</ul>
</li>
<li>
<p><strong>&quot;The Elements of Statistical Learning&quot; by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</strong>：</p>
<ul>
<li>介绍了各种特征构造方法及其应用。</li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">书籍链接</a></li>
</ul>
</li>
<li>
<p><strong>Python Data Science Handbook by Jake VanderPlas</strong>：</p>
<ul>
<li>提供了使用Python进行数据科学和特征工程的实用指南。</li>
<li><a href="https://jakevdp.github.io/PythonDataScienceHandbook/">书籍链接</a></li>
</ul>
</li>
</ol>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  