
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>12-deepFM</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <blockquote>
<p>详细介绍一下deepFM，以及其优缺点</p>
</blockquote>
<h3>DeepFM（Deep Factorization Machine）详解</h3>
<p>DeepFM 是由 Guo Huifeng 等人在 2017 年提出的一种融合了因子分解机（Factorization Machines, FM）和深度神经网络（Deep Neural Network, DNN）的模型。它旨在结合 FM 和 DNN 的优势，既能高效地捕捉特征的低阶交互，又能建模复杂的高阶特征交互。</p>
<h4>DeepFM 的原理</h4>
<p>DeepFM 由两个部分组成：FM 部分和 DNN 部分，这两部分共享同样的输入特征。这意味着模型同时学习低阶和高阶特征交互。</p>
<p><strong>模型结构</strong>：</p>
<ol>
<li>
<p><strong>输入层</strong>：</p>
<ul>
<li>处理原始输入特征，包括稀疏和密集特征。</li>
<li>将输入特征映射到隐向量表示。</li>
</ul>
</li>
<li>
<p><strong>FM 部分</strong>：</p>
<ul>
<li>负责捕捉特征的低阶交互。</li>
<li>使用因子分解机模型来计算特征交互。</li>
</ul>
</li>
<li>
<p><strong>DNN 部分</strong>：</p>
<ul>
<li>负责捕捉特征的高阶交互。</li>
<li>使用多层神经网络来建模复杂的特征交互。</li>
</ul>
</li>
<li>
<p><strong>融合层</strong>：</p>
<ul>
<li>将 FM 部分和 DNN 部分的输出进行融合。</li>
<li>最终输出预测结果。</li>
</ul>
</li>
</ol>
<p><strong>公式</strong>：</p>
<ol>
<li><strong>FM 部分</strong>：</li>
</ol>
<p>$$ y_{FM} = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j $$</p>
<ol start="2">
<li><strong>DNN 部分</strong>：</li>
</ol>
<p>$$ y_{DNN} = DNN(\mathbf{x}) $$</p>
<ol start="3">
<li><strong>融合层</strong>：</li>
</ol>
<p>$$ y = \sigma (y_{FM} + y_{DNN}) $$</p>
<p>其中：</p>
<ul>
<li>$ w_0 $ 是全局偏置。</li>
<li>$ w_i $ 是一阶特征的权重。</li>
<li>$ x_i $ 和 $ x_j $ 是特征值。</li>
<li>$ \mathbf{v}_i $ 和 $ \mathbf{v}_j $ 是特征的隐向量。</li>
<li>$ \sigma $ 是激活函数（如 sigmoid）。</li>
</ul>
<h4>优点</h4>
<ol>
<li><strong>捕捉低阶和高阶特征交互</strong>：DeepFM 通过结合 FM 和 DNN 的优点，能够同时捕捉低阶和高阶特征交互，提升了模型的表达能力。</li>
<li><strong>端到端训练</strong>：与传统的分阶段训练方法不同，DeepFM 可以通过一个损失函数进行端到端训练，简化了训练过程。</li>
<li><strong>特征共享</strong>：FM 部分和 DNN 部分共享同样的输入特征，减少了特征工程的工作量。</li>
<li><strong>适应性强</strong>：DeepFM 适用于各种类型的数据，特别是在推荐系统和广告点击率预估等任务中表现优异。</li>
</ol>
<h4>缺点</h4>
<ol>
<li><strong>计算复杂度高</strong>：由于包含 FM 和 DNN 两个部分，DeepFM 的计算复杂度较高，训练和推理的时间较长。</li>
<li><strong>参数较多</strong>：DNN 部分引入了大量的参数，增加了模型的复杂性，可能导致过拟合，需要进行正则化处理。</li>
<li><strong>依赖数据规模</strong>：DeepFM 需要大量数据来充分训练模型，以便学习到有效的特征交互。</li>
</ol>
<h4>应用场景</h4>
<ol>
<li><strong>推荐系统</strong>：DeepFM 在推荐系统中能够有效捕捉用户和物品的交互信息，提高推荐的准确性。</li>
<li><strong>广告点击率预估</strong>：DeepFM 在广告点击率预估任务中表现优异，能够处理广告和用户特征的复杂交互。</li>
<li><strong>其他分类任务</strong>：在需要捕捉特征交互的分类任务中，DeepFM 也能提供较好的性能。</li>
</ol>
<h3>实现示例</h3>
<p>以下是使用 Python 和 TensorFlow 实现 DeepFM 的示例代码：</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate
from tensorflow.keras.models import Model

# 示例数据
n_features = 1000
embedding_size = 10

# 输入层
input_layer = Input(shape=(n_features,), dtype=tf.float32)

# 嵌入层
embedding_layer = Embedding(input_dim=n_features, output_dim=embedding_size, input_length=n_features)(input_layer)
embedding_layer = Flatten()(embedding_layer)

# FM 部分
linear_part = Dense(1, activation=None)(input_layer)
interaction_part = tf.reduce_sum(
    tf.multiply(embedding_layer[:, :embedding_size // 2], embedding_layer[:, embedding_size // 2:]), axis=1, keepdims=True
)

# DNN 部分
dnn_part = Dense(128, activation='relu')(embedding_layer)
dnn_part = Dense(64, activation='relu')(dnn_part)
dnn_part = Dense(1, activation=None)(dnn_part)

# 融合层
output_layer = tf.nn.sigmoid(linear_part + interaction_part + dnn_part)

# 构建模型
model = Model(inputs=input_layer, outputs=output_layer)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 打印模型结构
model.summary()
</code></pre>
<h3>参考文献</h3>
<ol>
<li>
<p><strong>Guo, H., Tang, R., Ye, Y., Li, Z., &amp; He, X. (2017). &quot;DeepFM: A Factorization-Machine based Neural Network for CTR Prediction.&quot; arXiv preprint arXiv:1703.04247.</strong>
<a href="https://arxiv.org/abs/1703.04247">论文链接</a></p>
</li>
<li>
<p><strong>He, X., Pan, J., Jin, O., Xu, T., Liu, B., Xu, T., ... &amp; Li, T. (2014). &quot;Practical Lessons from Predicting Clicks on Ads at Facebook.&quot; In Proceedings of the Eighth International Workshop on Data Mining for Online Advertising (pp. 1-9).</strong>
<a href="https://dl.acm.org/doi/10.1145/2648584.2648589">论文链接</a></p>
</li>
</ol>

    <h3>Python 文件</h3>
    <pre><code>对应的 Python 文件不存在。</code></pre>
  </div>
</body>
</html>
  