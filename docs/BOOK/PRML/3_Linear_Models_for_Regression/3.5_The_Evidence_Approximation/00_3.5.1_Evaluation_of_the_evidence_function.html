
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.5.1 Evaluation of the evidence function</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>00_3.5.1_Evaluation_of_the_evidence_function</h1>
<pre><code>Lecture: 3_Linear_Models_for_Regression/3.5_The_Evidence_Approximation
Content: 00_3.5.1_Evaluation_of_the_evidence_function
</code></pre>
<h3>3.5.1 证据函数的评估</h3>
<p>在贝叶斯框架下，为了进行模型比较和超参数选择，我们需要评估边缘似然（也称为证据）函数。证据函数提供了一种客观的模型选择标准，而无需依赖于交叉验证。通过最大化证据，我们可以确定超参数 $ \alpha $ 和 $ \beta $ 的最佳值。</p>
<h3>边缘似然函数</h3>
<p>边缘似然函数 $ p(t|\alpha, \beta) $ 是通过对权重参数 $ \mathbf{w} $ 进行积分得到的：</p>
<p>$$ p(t|\alpha, \beta) = \int p(t|\mathbf{w}, \beta)p(\mathbf{w}|\alpha) d\mathbf{w} $$</p>
<p>其中：</p>
<ul>
<li>$ p(t|\mathbf{w}, \beta) $ 是给定参数 $ \mathbf{w} $ 和噪声精度 $ \beta $ 下的似然函数。</li>
<li>$ p(\mathbf{w}|\alpha) $ 是参数 $ \mathbf{w} $ 的先验分布。</li>
</ul>
<h3>证据函数的形式</h3>
<p>为了计算这个积分，我们利用线性高斯模型的条件分布结果，通过完成指数中的平方项并使用高斯分布的标准化系数的形式来评估证据函数。根据公式 (3.11)、(3.12) 和 (3.52)，我们可以将证据函数写成如下形式：</p>
<p>$$ p(t|\alpha, \beta) = \left( \frac{\beta}{2\pi} \right)^{N/2} \left( \frac{\alpha}{2\pi} \right)^{M/2} \int \exp{-E(\mathbf{w})} d\mathbf{w} $$</p>
<p>其中 $ M $ 是 $ \mathbf{w} $ 的维度，定义 $ E(\mathbf{w}) $ 如下：</p>
<p>$$ E(\mathbf{w}) = \beta E_D(\mathbf{w}) + \alpha E_W(\mathbf{w}) $$</p>
<p>$$ E_D(\mathbf{w}) = \frac{1}{2} |\mathbf{t} - \Phi \mathbf{w}|^2 $$</p>
<p>$$ E_W(\mathbf{w}) = \frac{1}{2} \mathbf{w}^T \mathbf{w} $$</p>
<h3>完成平方并评估积分</h3>
<p>我们识别 $ E(\mathbf{w}) $ 等于正则化的平方和误差函数。接下来我们通过完成平方项得到：</p>
<p>$$ E(\mathbf{w}) = E(\mathbf{m}_N) + \frac{1}{2} (\mathbf{w} - \mathbf{m}_N)^T \mathbf{A} (\mathbf{w} - \mathbf{m}_N) $$</p>
<p>其中：</p>
<p>$$ \mathbf{A} = \alpha \mathbf{I} + \beta \Phi^T \Phi $$</p>
<p>$$ E(\mathbf{m}_N) = \frac{\beta}{2} |\mathbf{t} - \Phi \mathbf{m}_N|^2 + \frac{\alpha}{2} \mathbf{m}_N^T \mathbf{m}_N $$</p>
<p>接下来，我们可以使用多元高斯分布的标准化系数的标准结果来评估 $ \mathbf{w} $ 的积分：</p>
<p>$$ \int \exp{-E(\mathbf{w})} d\mathbf{w} = \exp{-E(\mathbf{m}_N)} (2\pi)^{M/2} |\mathbf{A}|^{-1/2} $$</p>
<h3>对数边缘似然</h3>
<p>使用上述结果，我们可以将边缘似然的对数形式写成：</p>
<p>$$ \ln p(t|\alpha, \beta) = \frac{M}{2} \ln \alpha + \frac{N}{2} \ln \beta - E(\mathbf{m}_N) - \frac{1}{2} \ln |\mathbf{A}| - \frac{N}{2} \ln (2\pi) $$</p>
<p>这是我们所需的证据函数表达式。</p>
<h3>示例和代码实现</h3>
<p>为了更好地理解上述公式，我们可以实现一个Python代码来计算证据函数。以下是使用numpy和scipy实现的代码示例：</p>
<pre><code class="language-python">import numpy as np
from scipy.linalg import inv, det

class BayesianLinearRegression:
    def __init__(self, alpha: float, beta: float):
        self.alpha = alpha
        self.beta = beta
        self.m_N = None
        self.S_N = None

    def fit(self, X: np.ndarray, t: np.ndarray):
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        S_0_inv = self.alpha * np.eye(X.shape[1])
        self.S_N = inv(S_0_inv + self.beta * X.T @ X)
        self.m_N = self.beta * self.S_N @ X.T @ t

    def evidence(self, X: np.ndarray, t: np.ndarray) -&gt; float:
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        A = self.alpha * np.eye(X.shape[1]) + self.beta * X.T @ X
        E_mN = (self.beta / 2) * np.sum((t - X @ self.m_N)**2) + (self.alpha / 2) * np.sum(self.m_N**2)
        log_evidence = (X.shape[1] / 2) * np.log(self.alpha) + (X.shape[0] / 2) * np.log(self.beta) - E_mN - (1 / 2) * np.log(det(A)) - (X.shape[0] / 2) * np.log(2 * np.pi)
        return log_evidence

if __name__ == &quot;__main__&quot;:
    X_train = np.array([[0.1], [0.4], [0.7], [1.0]])
    t_train = np.array([1.1, 1.9, 3.0, 4.2])
    
    model = BayesianLinearRegression(alpha=1.0, beta=25.0)
    model.fit(X_train, t_train)
    evidence = model.evidence(X_train, t_train)
    
    print(&quot;证据函数对数值: &quot;, evidence)
</code></pre>
<h3>代码解释</h3>
<ol>
<li><strong>类定义</strong>:
<ul>
<li><code>BayesianLinearRegression</code> 类用于实现贝叶斯线性回归模型。</li>
<li>初始化时需要指定先验分布的方差参数 <code>alpha</code> 和噪声精度参数 <code>beta</code>。</li>
</ul>
</li>
<li><strong>拟合模型</strong>:
<ul>
<li><code>fit</code> 方法用于拟合模型，计算后验分布的均值向量 <code>m_N</code> 和协方差矩阵 <code>S_N</code>。</li>
</ul>
</li>
<li><strong>证据函数</strong>:
<ul>
<li><code>evidence</code> 方法计算证据函数的对数值。</li>
</ul>
</li>
<li><strong>示例</strong>:
<ul>
<li>在 <code>__main__</code> 中，通过示例数据演示了模型的拟合和证据函数的计算过程。</li>
</ul>
</li>
</ol>
<h3>检查代码逻辑</h3>
<ul>
<li>使用 <code>np.hstack</code> 添加偏置项，确保输入数据包含截距。</li>
<li>使用矩阵运算和线性代数库确保计算的准确性和高效性。</li>
<li>通过打印重要信息（如证据函数的对数值）来验证模型的正确性。</li>
</ul>

    <h3>Python 文件</h3>
    <pre><code># 00_3.5.1_Evaluation_of_the_evidence_function

"""
Lecture: 3_Linear_Models_for_Regression/3.5_The_Evidence_Approximation
Content: 00_3.5.1_Evaluation_of_the_evidence_function
"""

import numpy as np
from scipy.linalg import inv, det

class BayesianLinearRegression:
    def __init__(self, alpha: float, beta: float):
        self.alpha = alpha
        self.beta = beta
        self.m_N = None
        self.S_N = None

    def fit(self, X: np.ndarray, t: np.ndarray):
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        S_0_inv = self.alpha * np.eye(X.shape[1])
        self.S_N = inv(S_0_inv + self.beta * X.T @ X)
        self.m_N = self.beta * self.S_N @ X.T @ t

    def evidence(self, X: np.ndarray, t: np.ndarray) -> float:
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        A = self.alpha * np.eye(X.shape[1]) + self.beta * X.T @ X
        E_mN = (self.beta / 2) * np.sum((t - X @ self.m_N)**2) + (self.alpha / 2) * np.sum(self.m_N**2)
        log_evidence = (X.shape[1] / 2) * np.log(self.alpha) + (X.shape[0] / 2) * np.log(self.beta) - E_mN - (1 / 2) * np.log(det(A)) - (X.shape[0] / 2) * np.log(2 * np.pi)
        return log_evidence

if __name__ == "__main__":
    X_train = np.array([[0.1], [0.4], [0.7], [1.0]])
    t_train = np.array([1.1, 1.9, 3.0, 4.2])
    
    model = BayesianLinearRegression(alpha=1.0, beta=25.0)
    model.fit(X_train, t_train)
    evidence = model.evidence(X_train, t_train)
    
    print("证据函数对数值: ", evidence)</code></pre>
  </div>
</body>
</html>
  