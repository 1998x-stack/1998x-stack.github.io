
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>6.4.5 Gaussian processes for classification</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>04_6.4.5_Gaussian_processes_for_classification</h1>
<pre><code>Lecture: 6_Kernel_Methods/6.4_Gaussian_Processes
Content: 04_6.4.5_Gaussian_processes_for_classification
</code></pre>
<h2>详细分析第6.4.5节：用于分类的高斯过程</h2>
<h3>引言</h3>
<p>高斯过程（Gaussian Processes, GPs）不仅可以用于回归，还可以用于分类任务。与回归不同的是，分类问题中的目标变量是离散的，这需要对高斯过程进行相应的扩展和修改。第6.4.5节详细介绍了高斯过程在分类任务中的应用。</p>
<h3>二分类高斯过程分类器</h3>
<p>对于二分类问题，目标变量 $ y $ 取值为 ${0, 1}$。高斯过程分类的核心思想是引入一个潜在函数 $ f(x) $，然后通过一个激活函数（如sigmoid函数）将其映射到[0, 1]区间，以表示类别概率。</p>
<h4>模型定义</h4>
<p>假设 $ f(x) $ 是一个高斯过程，即：
$$ f(x) \sim \mathcal{GP}(m(x), k(x, x')) $$
其中，$ m(x) $ 是均值函数，通常设为0，$ k(x, x') $ 是协方差函数。</p>
<p>对于二分类问题，类别概率表示为：
$$ p(y=1|x) = \sigma(f(x)) $$
其中，$ \sigma(\cdot) $ 是sigmoid函数：
$$ \sigma(f) = \frac{1}{1 + \exp(-f)} $$</p>
<h4>似然函数</h4>
<p>给定训练数据 ${(x_n, y_n)}<em n="1">{n=1}^{N}$，似然函数表示为：
$$ p(y|f) = \prod</em>^{N} \sigma(f(x_n))^{y_n} (1 - \sigma(f(x_n)))^{1 - y_n} $$</p>
<h3>边际似然和后验分布</h3>
<p>为了进行预测，我们需要计算潜在函数 $ f $ 的后验分布。然而，由于sigmoid函数的非线性，后验分布不是标准的高斯分布。我们可以通过拉普拉斯近似或变分推断来近似后验分布。</p>
<h4>拉普拉斯近似</h4>
<ol>
<li><strong>找到后验分布的最大值</strong> $ f_{MAP} $：通过最大化对数似然函数来实现：
$$ \ln p(y|f) - \frac{1}{2} f^T K^{-1} f $$
其中，$ K $ 是核矩阵。</li>
<li><strong>计算Hessian矩阵</strong> $ A $：这是对数似然函数的二阶导数矩阵。</li>
<li><strong>高斯近似</strong>：在 $ f_{MAP} $ 处进行二阶泰勒展开，得到高斯近似：
$$ q(f|X, y) = \mathcal{N}(f_{MAP}, A^{-1}) $$</li>
</ol>
<h3>预测</h3>
<p>对于新的输入 $ x_* $，预测分布通过对潜在函数进行积分得到：
$$ p(y_<em>=1|x_</em>, X, y) = \int \sigma(f_<em>) p(f_</em>|x_<em>, X, y) df_</em> $$
其中，$ f_* $ 是新的输入点的潜在函数值。该积分可以通过数值方法或蒙特卡罗采样近似计算。</p>
<h3>多分类高斯过程分类器</h3>
<p>对于多分类问题，目标变量 $ y $ 取值为 ${1, 2, ..., K}$。多分类高斯过程分类器通过引入 $ K $ 个潜在函数 $ {f_k(x)}_{k=1}^{K} $，然后使用softmax函数将其映射到类别概率。</p>
<h4>模型定义</h4>
<p>类别概率表示为：
$$ p(y=k|x) = \frac{\exp(f_k(x))}{\sum_{j=1}^{K} \exp(f_j(x))} $$</p>
<h4>似然函数</h4>
<p>给定训练数据 ${(x_n, y_n)}<em n="1">{n=1}^{N}$，似然函数表示为：
$$ p(y|f) = \prod</em>^{N} \frac{\exp(f_{y_n}(x_n))}{\sum_{j=1}^{K} \exp(f_j(x_n))} $$</p>
<h3>实例分析</h3>
<p>假设我们有一个二维分类问题，输入变量为 $ x = [x_1, x_2] $，目标变量 $ y $ 取值为 ${0, 1}$。生成数据如下：
$$ x_i \sim \mathcal{U}(0, 1) $$
$$ y_i = \begin{cases}
1, &amp; \text{if } x_1^2 + x_2^2 &gt; 0.5 \
0, &amp; \text{otherwise}
\end{cases} $$</p>
<h4>数据可视化</h4>
<p>绘制输入 $ x $ 和目标 $ y $ 的散点图。</p>
<h4>模型训练</h4>
<ol>
<li><strong>初始参数选择</strong>：选择核函数和初始超参数。</li>
<li><strong>边际似然最大化</strong>：通过优化算法最大化负对数边际似然，学习超参数。</li>
<li><strong>预测</strong>：使用优化后的参数进行预测，并计算预测概率。</li>
</ol>
<h4>结果分析</h4>
<p>通过可视化预测结果，可以看到高斯过程分类器能够准确捕捉数据的非线性边界，并量化预测的不确定性。</p>
<h3>小结</h3>
<p>高斯过程分类器通过引入潜在函数和非线性激活函数，提供了一种灵活且强大的方法来处理分类任务。拉普拉斯近似和变分推断等方法使得高斯过程在实际应用中更为实用。</p>

    <h3>Python 文件</h3>
    <pre><code># 04_6.4.5_Gaussian_processes_for_classification

"""
Lecture: 6_Kernel_Methods/6.4_Gaussian_Processes
Content: 04_6.4.5_Gaussian_processes_for_classification
"""

</code></pre>
  </div>
</body>
</html>
  