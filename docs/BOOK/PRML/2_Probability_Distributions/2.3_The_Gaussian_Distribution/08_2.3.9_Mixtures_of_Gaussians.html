
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>2.3.9 Mixtures of Gaussians</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>08_2.3.9_Mixtures_of_Gaussians</h1>
<pre><code>Lecture: 2_Probability_Distributions/2.3_The_Gaussian_Distribution
Content: 08_2.3.9_Mixtures_of_Gaussians
</code></pre>
<h3>PDF 探索和详细分析</h3>
<h4>高斯混合模型（Mixtures of Gaussians）</h4>
<p>在2.3.9节中，讨论了高斯混合模型（Gaussian Mixture Models, GMMs）的定义、性质及其应用。高斯混合模型是通过线性组合多个高斯分布来表示复杂数据分布的一种方法。它在统计建模中非常重要，因为它可以逼近几乎任何连续的概率密度函数。</p>
<h4>定义与背景</h4>
<ol>
<li>
<p><strong>高斯混合模型的定义</strong>：
高斯混合模型由多个高斯分布组成，每个分布称为一个“分量”。设数据点 $ x $ 的概率分布由 $ K $ 个高斯分布线性组合而成：
$$
p(x) = \sum_{k=1}^{K} \pi_k N(x|\mu_k, \Sigma_k)
$$
其中：</p>
<ul>
<li>$\pi_k$ 是混合系数，满足 $ \sum_{k=1}^{K} \pi_k = 1 $ 且 $ 0 \leq \pi_k \leq 1 $。</li>
<li>$N(x|\mu_k, \Sigma_k)$ 是第 $ k $ 个高斯分布，均值为 $ \mu_k $，协方差矩阵为 $ \Sigma_k $。</li>
</ul>
</li>
<li>
<p><strong>混合系数的性质</strong>：
混合系数 $ \pi_k $ 表示从第 $ k $ 个高斯分布中采样的概率。它们是非负数，并且总和为1。这样确保了 $ p(x) $ 是一个合法的概率分布。</p>
</li>
<li>
<p><strong>高斯混合模型的优点</strong>：</p>
<ul>
<li><strong>灵活性</strong>：通过调整各个分量的均值、协方差矩阵和混合系数，可以逼近几乎任何形状的概率密度函数。</li>
<li><strong>多模态分布</strong>：能够处理多模态数据，即数据集中存在多个峰值的情况。</li>
<li><strong>适用性广</strong>：在模式识别、图像处理、数据挖掘等多个领域都有广泛应用。</li>
</ul>
</li>
</ol>
<h4>高斯混合模型的参数估计</h4>
<p>高斯混合模型的参数估计通常使用最大似然估计法（Maximum Likelihood Estimation, MLE）。由于直接求解MLE较为复杂，常用期望最大化算法（Expectation-Maximization, EM）来进行迭代估计。</p>
<ol>
<li><strong>EM算法</strong>：
<ul>
<li><strong>E步（Expectation step）</strong>：计算每个数据点属于每个高斯分布的后验概率，即“责任” $ \gamma_{nk} $：
$$
\gamma_{nk} = \frac{\pi_k N(x_n|\mu_k, \Sigma_k)}{\sum_{j=1}^{K} \pi_j N(x_n|\mu_j, \Sigma_j)}
$$</li>
<li><strong>M步（Maximization step）</strong>：更新参数（均值、协方差矩阵和混合系数）：
$$
\mu_k = \frac{\sum_{n=1}^{N} \gamma_{nk} x_n}{\sum_{n=1}^{N} \gamma_{nk}}
$$
$$
\Sigma_k = \frac{\sum_{n=1}^{N} \gamma_{nk} (x_n - \mu_k)(x_n - \mu_k)^T}{\sum_{n=1}^{N} \gamma_{nk}}
$$
$$
\pi_k = \frac{1}{N} \sum_{n=1}^{N} \gamma_{nk}
$$</li>
</ul>
</li>
</ol>
<h4>高斯混合模型的应用</h4>
<ol>
<li>
<p><strong>聚类分析</strong>：
高斯混合模型可以用于聚类分析，将数据点划分为不同的簇。相比于K-means聚类，高斯混合模型允许簇具有不同的形状和大小。</p>
</li>
<li>
<p><strong>密度估计</strong>：
GMMs可以用于估计数据的概率密度函数，特别是当数据具有复杂的分布形态时。</p>
</li>
<li>
<p><strong>图像处理</strong>：
在图像分割和图像压缩中，高斯混合模型可以用于建模图像中的像素分布，从而实现图像的有效处理。</p>
</li>
</ol>
<h3>结论</h3>
<p>高斯混合模型通过线性组合多个高斯分布，提供了一种灵活且强大的工具来表示复杂的数据分布。它的参数估计通常通过EM算法实现，并在聚类分析、密度估计和图像处理等多个领域具有广泛应用。高斯混合模型能够处理多模态数据，并通过调整分量参数逼近几乎任何形状的概率密度函数。</p>

    <h3>Python 文件</h3>
    <pre><code># 08_2.3.9_Mixtures_of_Gaussians

"""
Lecture: 2_Probability_Distributions/2.3_The_Gaussian_Distribution
Content: 08_2.3.9_Mixtures_of_Gaussians
"""

import numpy as np
from scipy.stats import multivariate_normal
from typing import Tuple, List

class GaussianMixtureModel:
    def __init__(self, n_components: int, tol: float = 1e-6, max_iter: int = 100):
        """
        初始化高斯混合模型类
        
        参数:
        n_components (int): 混合分量的数量
        tol (float): 收敛阈值
        max_iter (int): 最大迭代次数
        """
        self.n_components = n_components
        self.tol = tol
        self.max_iter = max_iter

    def _initialize_parameters(self, X: np.ndarray) -> None:
        """
        初始化模型参数
        
        参数:
        X (np.ndarray): 输入数据
        """
        n_samples, n_features = X.shape
        self.weights = np.ones(self.n_components) / self.n_components
        self.means = X[np.random.choice(n_samples, self.n_components, replace=False)]
        self.covariances = np.array([np.eye(n_features) for _ in range(self.n_components)])
    
    def _e_step(self, X: np.ndarray) -> np.ndarray:
        """
        E步：计算责任值
        
        参数:
        X (np.ndarray): 输入数据
        
        返回:
        np.ndarray: 责任值矩阵
        """
        n_samples = X.shape[0]
        responsibilities = np.zeros((n_samples, self.n_components))
        for k in range(self.n_components):
            responsibilities[:, k] = self.weights[k] * multivariate_normal.pdf(X, mean=self.means[k], cov=self.covariances[k])
        sum_responsibilities = responsibilities.sum(axis=1, keepdims=True)
        return responsibilities / sum_responsibilities
    
    def _m_step(self, X: np.ndarray, responsibilities: np.ndarray) -> None:
        """
        M步：更新模型参数
        
        参数:
        X (np.ndarray): 输入数据
        responsibilities (np.ndarray): 责任值矩阵
        """
        n_samples, n_features = X.shape
        for k in range(self.n_components):
            responsibility = responsibilities[:, k]
            total_responsibility = responsibility.sum()
            self.weights[k] = total_responsibility / n_samples
            self.means[k] = (X * responsibility[:, np.newaxis]).sum(axis=0) / total_responsibility
            diff = X - self.means[k]
            self.covariances[k] = np.dot((responsibility[:, np.newaxis] * diff).T, diff) / total_responsibility
    
    def fit(self, X: np.ndarray) -> None:
        """
        训练高斯混合模型
        
        参数:
        X (np.ndarray): 输入数据
        """
        self._initialize_parameters(X)
        log_likelihood = []
        for _ in range(self.max_iter):
            responsibilities = self._e_step(X)
            self._m_step(X, responsibilities)
            log_likelihood.append(np.sum(np.log(np.sum(responsibilities, axis=1))))
            if len(log_likelihood) > 1 and abs(log_likelihood[-1] - log_likelihood[-2]) < self.tol:
                break

    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """
        预测每个样本点的责任值
        
        参数:
        X (np.ndarray): 输入数据
        
        返回:
        np.ndarray: 每个样本点的责任值矩阵
        """
        return self._e_step(X)

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        预测每个样本点的簇标签
        
        参数:
        X (np.ndarray): 输入数据
        
        返回:
        np.ndarray: 每个样本点的簇标签
        """
        responsibilities = self._e_step(X)
        return np.argmax(responsibilities, axis=1)

# 示例用法
if __name__ == "__main__":
    np.random.seed(0)
    X = np.vstack([
        np.random.multivariate_normal(mean=[0, 0], cov=[[1, 0.5], [0.5, 1]], size=100),
        np.random.multivariate_normal(mean=[3, 3], cov=[[1, -0.5], [-0.5, 1]], size=100)
    ])
    
    gmm = GaussianMixtureModel(n_components=2)
    gmm.fit(X)
    
    labels = gmm.predict(X)
    print("预测的簇标签:", labels)</code></pre>
  </div>
</body>
</html>
  