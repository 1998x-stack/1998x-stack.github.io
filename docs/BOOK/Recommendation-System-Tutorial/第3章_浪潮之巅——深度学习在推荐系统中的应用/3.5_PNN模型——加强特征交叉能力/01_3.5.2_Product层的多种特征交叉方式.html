
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.5.2 Product层的多种特征交叉方式</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>01_3.5.2 Product层的多种特征交叉方式</h1>
<pre><code>Lecture: 第3章 浪潮之巅——深度学习在推荐系统中的应用/3.5 PNN模型——加强特征交叉能力
Content: 01_3.5.2 Product层的多种特征交叉方式
</code></pre>
<h3>Product层的多种特征交叉方式</h3>
<h4>一、引言</h4>
<p>PNN（Product-based Neural Network）模型通过引入乘积层（Product Layer），显著增强了特征交叉的能力。乘积层在特征交叉中采用了多种方式，包括内积操作和外积操作，使得PNN模型在CTR（Click-Through Rate）预估和推荐系统中表现出色。</p>
<h4>二、Product层的特征交叉方式</h4>
<h5>1. 内积操作（Inner Product）</h5>
<p><strong>1.1 定义：</strong></p>
<ul>
<li>内积操作是经典的向量内积运算。假设输入特征向量分别为$\mathbf{f}_i$和$\mathbf{f}<em>j$，其内积互操作定义为：$$ g</em>{\text{inner}}(\mathbf{f}_i, \mathbf{f}_j) = \mathbf{f}_i \cdot \mathbf{f}_j $$</li>
</ul>
<p><strong>1.2 实现：</strong></p>
<ul>
<li>对特征向量进行内积运算，可以有效捕捉特征间的线性关系。</li>
<li>内积结果生成一个新的特征向量，保留了输入特征之间的交互信息。</li>
</ul>
<p><strong>1.3 优点：</strong></p>
<ul>
<li>计算简单，易于实现。</li>
<li>能有效捕捉线性关系。</li>
</ul>
<p><strong>1.4 局限性：</strong></p>
<ul>
<li>只能捕捉到特征间的线性关系，无法捕捉更复杂的非线性关系。</li>
</ul>
<h5>2. 外积操作（Outer Product）</h5>
<p><strong>2.1 定义：</strong></p>
<ul>
<li>外积操作是对输入特征向量$\mathbf{f}_i$和$\mathbf{f}<em>j$的各维度进行两两交叉，生成特征交叉矩阵。外积互操作定义为：$$ g</em>{\text{outer}}(\mathbf{f}_i, \mathbf{f}_j) = \mathbf{f}_i \otimes \mathbf{f}_j $$</li>
</ul>
<p><strong>2.2 实现：</strong></p>
<ul>
<li>外积操作生成的是特征向量$\mathbf{f}_i$和$\mathbf{f}_j$各维度两两交叉而成的一个$M \times M$的方形矩阵（其中$M$是输入向量的维度）。</li>
</ul>
<p><strong>2.3 优点：</strong></p>
<ul>
<li>能捕捉到更复杂的非线性关系。</li>
<li>提供了丰富的特征交叉信息，有助于提高模型的表达能力。</li>
</ul>
<p><strong>2.4 局限性：</strong></p>
<ul>
<li>计算复杂度高。外积操作将问题的复杂度从原来的$M$提升到$M^2$。</li>
<li>生成的特征矩阵维度较高，增加了计算和存储的负担。</li>
</ul>
<h5>3. 降维处理</h5>
<p><strong>3.1 定义：</strong></p>
<ul>
<li>为了减小外积操作带来的计算复杂度，PNN模型对外积结果进行了降维处理。具体方法是将所有两两特征Embedding向量外积互操作的结果叠加（Superposition），形成一个叠加外积互操作矩阵$\mathbf{p}$。</li>
</ul>
<p><strong>3.2 实现：</strong></p>
<ul>
<li>降维处理将外积互操作的结果叠加成一个新的特征向量，减少了计算和存储的负担，同时保留了特征交叉的信息。</li>
</ul>
<p><strong>3.3 优点：</strong></p>
<ul>
<li>有效减少了计算复杂度，保证了模型的训练效率。</li>
<li>在一定程度上保留了外积操作的特征交叉信息，提高了模型的表达能力。</li>
</ul>
<p><strong>3.4 局限性：</strong></p>
<ul>
<li>降维处理可能会丢失部分特征交叉信息，影响模型的精度。</li>
</ul>
<h4>三、PNN模型中的特征交叉方式应用实例</h4>
<h5>1. CTR预估</h5>
<p><strong>1.1 应用场景：</strong></p>
<ul>
<li>在广告推荐中，PNN模型可以用于预估用户对广告的点击率。通过内积和外积操作捕捉用户和广告特征之间的复杂交互信息，提高点击率预估的准确性。</li>
</ul>
<p><strong>1.2 优势：</strong></p>
<ul>
<li>通过多种特征交叉方式，PNN模型能够捕捉到更多的特征交互信息，提高了模型的表达能力和预测性能。</li>
</ul>
<h5>2. 推荐系统</h5>
<p><strong>2.1 应用场景：</strong></p>
<ul>
<li>在推荐系统中，PNN模型可以用于预测用户对商品的评分或点击概率，提供个性化推荐服务。</li>
</ul>
<p><strong>2.2 优势：</strong></p>
<ul>
<li>通过外积操作和降维处理，PNN模型能够有效捕捉用户和商品特征之间的高阶交互信息，提高推荐结果的准确性和鲁棒性。</li>
</ul>
<h4>四、总结</h4>
<p>PNN模型通过引入内积和外积操作，有效增强了特征交叉的能力。内积操作捕捉线性关系，外积操作捕捉非线性关系，降维处理减少了计算复杂度，保留了特征交叉信息。PNN模型在CTR预估和推荐系统中表现出色，通过多种特征交叉方式提高了模型的表达能力和预测性能。</p>
<hr>
<p>感谢你的指正。这里有些部分需要更正和更详细的解释。下面是修正和详细的讲解。</p>
<h3>极其详细讲解内积操作与外积操作并降维</h3>
<h4>一、内积操作（Inner Product）</h4>
<p><strong>定义</strong>：
内积操作是向量之间的点积运算，用于捕捉特征之间的线性关系。</p>
<p><strong>公式</strong>：
假设有两个特征向量 $\mathbf{f}_u$ 和 $\mathbf{f}<em>i$，它们的内积计算公式为：
$$ g</em>{\text{inner}}(\mathbf{f}_u, \mathbf{f}<em i,k="">i) = \mathbf{f}<em u,k="">u \cdot \mathbf{f}<em k="1">i = \sum</em>^{d} f</em> \cdot f</em> $$
其中，$ \mathbf{f}<em i,k="">u $ 和 $ \mathbf{f}<em u,k="">i $ 是维度为 $ d $ 的向量，$ f</em> $ 和 $ f</em> $ 分别是向量 $ \mathbf{f}_u $ 和 $ \mathbf{f}_i $ 的第 $ k $ 个元素。</p>
<p><strong>实现</strong>：
在代码中，通过 <code>torch.bmm</code> 函数实现内积操作，并使用 <code>view</code> 函数调整输出向量的形状。</p>
<pre><code class="language-python"># 获取用户和物品的Embedding向量
user_emb = self.user_embedding(user)  # [batch_size, embedding_dim]
item_emb = self.item_embedding(item)  # [batch_size, embedding_dim]

# 内积操作
inner_product = torch.sum(user_emb * item_emb, dim=1, keepdim=True)
</code></pre>
<p><strong>步骤解析</strong>：</p>
<ol>
<li><code>user_emb</code> 的形状是 <code>[batch_size, embedding_dim]</code>，<code>item_emb</code> 的形状也是 <code>[batch_size, embedding_dim]</code>。</li>
<li>元素级相乘：<code>user_emb * item_emb</code> 会进行逐元素相乘，结果的形状仍然是 <code>[batch_size, embedding_dim]</code>。</li>
<li><code>torch.sum</code> 函数沿着 <code>embedding_dim</code> 维度求和，得到内积结果，其形状为 <code>[batch_size, 1]</code>。</li>
</ol>
<h4>二、外积操作（Outer Product）并降维</h4>
<p><strong>定义</strong>：
外积操作是向量之间的Kronecker积运算，用于捕捉特征之间的非线性关系。外积会生成一个矩阵，其中每个元素表示两个特征之间的交互。</p>
<p><strong>公式</strong>：
假设有两个特征向量 $\mathbf{f}<em u,1="">u$ 和 $\mathbf{f}<em>i$，它们的外积计算公式为：
$$ g</em>{\text{outer}}(\mathbf{f}<em i,2="">u, \mathbf{f}<em u,1="">i) = \mathbf{f}<em i,1="">u \otimes \mathbf{f}<em u,1="">i = \begin{bmatrix}
f</em> \cdot f</em> &amp; f</em> \cdot f</em> &amp; \cdots &amp; f</em> \cdot f_{i,d} \
f_{u,2} \cdot f_{i,1} &amp; f_{u,2} \cdot f_{i,2} &amp; \cdots &amp; f_{u,2} \cdot f_{i,d} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
f_{u,d} \cdot f_{i,1} &amp; f_{u,d} \cdot f_{i,2} &amp; \cdots &amp; f_{u,d} \cdot f_{i,d}
\end{bmatrix} $$</p>
<p><strong>实现</strong>：
在代码中，通过 <code>torch.bmm</code> 函数实现外积操作，并使用 <code>view</code> 函数和 <code>torch.tril</code> 函数进行降维处理。</p>
<pre><code class="language-python"># 获取用户和物品的Embedding向量
user_emb = self.user_embedding(user)  # [batch_size, embedding_dim]
item_emb = self.item_embedding(item)  # [batch_size, embedding_dim]

# 外积操作并降维
outer_product = torch.bmm(user_emb.unsqueeze(2), item_emb.unsqueeze(1)).view(-1, self.embedding_dim ** 2)
outer_product = outer_product[:, torch.tril(torch.ones(self.embedding_dim, self.embedding_dim)).bool()].view(-1, self.embedding_dim * (self.embedding_dim - 1) // 2)
</code></pre>
<p><strong>步骤解析</strong>：</p>
<ol>
<li><code>unsqueeze</code> 函数用于在指定位置插入一个维度，使得 <code>user_emb</code> 的形状从 <code>[batch_size, embedding_dim]</code> 变为 <code>[batch_size, embedding_dim, 1]</code>，<code>item_emb</code> 的形状从 <code>[batch_size, embedding_dim]</code> 变为 <code>[batch_size, 1, embedding_dim]</code>。</li>
<li><code>torch.bmm</code> 函数用于批量矩阵乘法，将 <code>user_emb</code> 和 <code>item_emb</code> 进行矩阵乘法，得到形状为 <code>[batch_size, embedding_dim, embedding_dim]</code> 的矩阵。</li>
<li><code>torch.tril</code> 函数生成一个下三角矩阵掩码，将其转换为布尔类型并用于选择外积结果中的下三角元素（包括对角线），实现降维处理。注意，这里使用的是下三角掩码，保留了下三角部分的数据。</li>
<li><code>view</code> 函数用于调整降维后的向量形状，使其变为 <code>[batch_size, embedding_dim * (self.embedding_dim - 1) // 2]</code>。</li>
</ol>
<p>通过这种方式，外积操作不仅捕捉了特征之间的非线性关系，而且通过降维处理减少了计算复杂度，使得模型更加高效。</p>

    <h3>Python 文件</h3>
    <pre><code># 01_3.5.2 Product层的多种特征交叉方式

"""
Lecture: 第3章 浪潮之巅——深度学习在推荐系统中的应用/3.5 PNN模型——加强特征交叉能力
Content: 01_3.5.2 Product层的多种特征交叉方式
"""

</code></pre>
  </div>
</body>
</html>
  