
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.6.3 Wide&Deep模型的进化——Deep&Cross模型</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>02_3.6.3 Wide&amp;Deep模型的进化——Deep&amp;Cross模型</h1>
<pre><code>Lecture: 第3章 浪潮之巅——深度学习在推荐系统中的应用/3.6 Wide&amp;Deep 模型——记忆能力和泛化能力的综合
Content: 02_3.6.3 Wide&amp;Deep模型的进化——Deep&amp;Cross模型
</code></pre>
<h3>Wide &amp; Deep模型的进化——Deep &amp; Cross模型</h3>
<h4>一、引言</h4>
<p>Wide &amp; Deep模型结合了简单模型的记忆能力和深度神经网络的泛化能力，极大提升了推荐系统的性能。然而，Wide &amp; Deep模型仍存在一些不足之处，比如对特征交叉的处理不够灵活。为了解决这些问题，斯坦福大学和谷歌的研究人员于2017年提出了Deep &amp; Cross模型（Deep &amp; Cross Network, DCN），旨在通过引入Cross网络增强特征交互能力，从而进一步提升推荐系统的性能。</p>
<h4>二、Deep &amp; Cross模型的结构</h4>
<p>Deep &amp; Cross模型的基本结构如图3-15所示。DCN模型主要由两部分组成：Cross网络和Deep网络。</p>
<h5>1. Cross网络</h5>
<p>Cross网络的设计目的是增加特征之间的交互强度。与Wide &amp; Deep模型中的Wide部分不同，Cross网络通过多层交叉层（Cross layer）对输入向量进行特征交叉。假设第 $ l $ 层交叉层的输出向量为 $ x_l $，那么第 $ l+1 $ 层的输出向量可以表示为：
$$ x_{l+1} = x_0 \cdot (w_l^T x_l) + b_l + x_l $$
其中，$ w_l $ 是权重向量，$ b_l $ 是偏置向量，$ x_0 $ 是原始输入向量。</p>
<p>通过这种方式，交叉层能够有效捕捉特征之间的二阶交互信息，类似于PNN模型中的外积操作。每一层交叉层仅增加了一个 $ n $ 维的权重向量 $ w_l $（ $ n $ 为输入向量的维度），并且每一层均保留了输入向量，因此输出与输入之间的变化不会特别明显。</p>
<h5>2. Deep网络</h5>
<p>Deep网络部分的设计思路没有本质变化，依然是通过Embedding层将类别型特征转换为稠密向量，然后通过多层全连接层（Fully Connected Layer）进行特征处理。Deep网络的主要作用是对特征进行深度挖掘，捕捉特征之间的高阶非线性关系。</p>
<h5>3. 输出层</h5>
<p>Cross网络和Deep网络的输出会在最终的输出层进行结合，通过逻辑回归层进行目标拟合。通过这种方式，DCN模型能够同时利用记忆能力和泛化能力，既能快速响应用户的历史行为，又能准确推荐新物品。</p>
<h4>三、Cross网络的设计和实现</h4>
<p>Cross网络的核心在于交叉层的设计。交叉层的操作如图3-16所示。每一层交叉层的输入为 $ x_l $，输出为 $ x_{l+1} $。具体操作如下：</p>
<ol>
<li><strong>二阶交叉操作</strong>：计算输入向量 $ x_l $ 和原始输入向量 $ x_0 $ 的二阶交互信息，即 $ x_0 \cdot (w_l^T x_l) $。</li>
<li><strong>加权求和</strong>：将二阶交互信息与偏置向量 $ b_l $ 和输入向量 $ x_l $ 相加，得到输出向量 $ x_{l+1} $。</li>
</ol>
<p>这种设计能够有效增加特征之间的交互强度，捕捉特征之间的复杂关系。</p>
<h4>四、Deep &amp; Cross模型的优势</h4>
<ol>
<li><strong>增强的特征交互能力</strong>：通过引入Cross网络，DCN模型能够更有效地捕捉特征之间的复杂交互关系，提高推荐系统的准确性。</li>
<li><strong>端到端训练</strong>：DCN模型采用端到端的训练方式，使模型能够自动学习到最优的特征交叉方式和参数设置，避免了繁琐的人工特征工程。</li>
<li><strong>计算复杂度相对较低</strong>：虽然引入了交叉层，但每一层仅增加一个 $ n $ 维的权重向量，因此计算复杂度相对较低，模型训练效率较高。</li>
</ol>
<h4>五、总结</h4>
<p>Deep &amp; Cross模型通过引入Cross网络，有效增强了特征交互能力，结合了Wide &amp; Deep模型的记忆能力和泛化能力，进一步提升了推荐系统的性能。DCN模型的提出不仅解决了Wide &amp; Deep模型的一些不足，还为后续的推荐系统模型设计提供了新的思路。在实际应用中，DCN模型凭借其强大的特征交互能力和高效的计算性能，已被广泛应用于各类推荐系统中，成为业界主流模型之一   。</p>
<hr>
<h3>Deep &amp; Cross模型的结构</h3>
<h4>一、引言</h4>
<p>Deep &amp; Cross模型（DCN）是Wide &amp; Deep模型的进化版本，由斯坦福大学和谷歌的研究人员于2017年提出。该模型通过引入Cross网络来增强特征交互能力，从而提高推荐系统的性能。DCN模型主要由两个部分组成：Cross网络和Deep网络。</p>
<h4>二、DCN模型的结构</h4>
<h5>1. Cross网络</h5>
<p>Cross网络的设计目的是增加特征之间的交互强度。与Wide &amp; Deep模型中的Wide部分不同，Cross网络通过多层交叉层（Cross layer）对输入向量进行特征交叉。每一层交叉层的操作如下：</p>
<p>1.1. <strong>Cross网络的基本操作</strong>：
假设第 $ l $ 层交叉层的输出向量为 $ x_l $，那么第 $ l+1 $ 层的输出向量可以表示为：
$$ x_{l+1} = x_0 \cdot (w_l^T x_l) + b_l + x_l $$
其中，$ w_l $ 是权重向量，$ b_l $ 是偏置向量，$ x_0 $ 是原始输入向量。</p>
<p>1.2. <strong>操作详解</strong>：</p>
<ul>
<li><strong>二阶交叉操作</strong>：计算输入向量 $ x_l $ 和原始输入向量 $ x_0 $ 的二阶交互信息，即 $ x_0 \cdot (w_l^T x_l) $。</li>
<li><strong>加权求和</strong>：将二阶交互信息与偏置向量 $ b_l $ 和输入向量 $ x_l $ 相加，得到输出向量 $ x_{l+1} $。</li>
</ul>
<p>通过这种方式，交叉层能够有效捕捉特征之间的二阶交互信息，类似于PNN模型中的外积操作。每一层交叉层仅增加了一个 $ n $ 维的权重向量 $ w_l $（ $ n $ 为输入向量的维度），并且每一层均保留了输入向量，因此输出与输入之间的变化不会特别明显。</p>
<p>1.3. <strong>Cross网络示意图</strong>：
<img src="https://raw.githubusercontent.com/jiachen0212/images/main/dcn_cross.png" alt="Cross网络示意图"></p>
<h5>2. Deep网络</h5>
<p>Deep网络部分的设计思路没有本质变化，依然是通过Embedding层将类别型特征转换为稠密向量，然后通过多层全连接层（Fully Connected Layer）进行特征处理。Deep网络的主要作用是对特征进行深度挖掘，捕捉特征之间的高阶非线性关系。</p>
<p>2.1. <strong>Embedding层</strong>：</p>
<ul>
<li><strong>类别型特征转换</strong>：Embedding层将类别型特征（如用户ID、商品ID等）转换为稠密向量。</li>
<li><strong>特征组合</strong>：通过多层全连接层对Embedding向量进行组合，挖掘特征之间的高阶非线性关系。</li>
</ul>
<p>2.2. <strong>多层全连接层（Dense Layers）</strong>：</p>
<ul>
<li><strong>激活函数</strong>：全连接层通常使用ReLU（Rectified Linear Unit）激活函数，以增强模型的非线性表达能力。</li>
<li><strong>特征交叉</strong>：通过多层全连接层对特征进行深度交叉和处理，捕捉特征背后的数据模式。</li>
</ul>
<p>2.3. <strong>Deep网络示意图</strong>：
<img src="https://raw.githubusercontent.com/jiachen0212/images/main/dcn_deep.png" alt="Deep网络示意图"></p>
<h5>3. 输出层</h5>
<p>Cross网络和Deep网络的输出会在最终的输出层进行结合，通过逻辑回归层进行目标拟合。具体而言，Cross网络的输出和Deep网络的输出会被拼接起来，作为最终输出层的输入，进行最终的预测。通过这种方式，DCN模型能够同时利用记忆能力和泛化能力，既能快速响应用户的历史行为，又能准确推荐新物品。</p>
<p>3.1. <strong>输出层示意图</strong>：
<img src="https://raw.githubusercontent.com/jiachen0212/images/main/dcn_output.png" alt="输出层示意图"></p>
<h4>三、DCN模型的优势</h4>
<ol>
<li>
<p><strong>增强的特征交互能力</strong>：
通过引入Cross网络，DCN模型能够更有效地捕捉特征之间的复杂交互关系，提高推荐系统的准确性。</p>
</li>
<li>
<p><strong>端到端训练</strong>：
DCN模型采用端到端的训练方式，使模型能够自动学习到最优的特征交叉方式和参数设置，避免了繁琐的人工特征工程。</p>
</li>
<li>
<p><strong>计算复杂度相对较低</strong>：
虽然引入了交叉层，但每一层仅增加一个 $ n $ 维的权重向量，因此计算复杂度相对较低，模型训练效率较高。</p>
</li>
</ol>
<h4>四、总结</h4>
<p>Deep &amp; Cross模型通过引入Cross网络，有效增强了特征交互能力，结合了Wide &amp; Deep模型的记忆能力和泛化能力，进一步提升了推荐系统的性能。DCN模型的提出不仅解决了Wide &amp; Deep模型的一些不足，还为后续的推荐系统模型设计提供了新的思路。在实际应用中，DCN模型凭借其强大的特征交互能力和高效的计算性能，已被广泛应用于各类推荐系统中，成为业界主流模型之一。</p>

    <h3>Python 文件</h3>
    <pre><code># 02_3.6.3 Wide&Deep模型的进化——Deep&Cross模型

"""
Lecture: 第3章 浪潮之巅——深度学习在推荐系统中的应用/3.6 Wide&Deep 模型——记忆能力和泛化能力的综合
Content: 02_3.6.3 Wide&Deep模型的进化——Deep&Cross模型
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
from typing import List, Tuple

class CustomDataset(Dataset):
    """自定义数据集类，用于加载特征和标签数据。
    
    Args:
        wide_features (np.ndarray): Wide部分的输入特征。
        deep_features (np.ndarray): Deep部分的输入特征。
        labels (np.ndarray): 标签（目标值）。
    """
    
    def __init__(self, wide_features: np.ndarray, deep_features: np.ndarray, labels: np.ndarray):
        self.wide_features = torch.FloatTensor(wide_features)
        self.deep_features = torch.LongTensor(deep_features)
        self.labels = torch.FloatTensor(labels)
    
    def __len__(self) -> int:
        return len(self.labels)
    
    def __getitem__(self, idx: int) -> Tuple[torch.FloatTensor, torch.LongTensor, torch.FloatTensor]:
        return self.wide_features[idx], self.deep_features[idx], self.labels[idx]

class CrossNetwork(nn.Module):
    """Cross网络定义。
    
    Args:
        input_dim (int): 输入特征的维度。
        num_layers (int): 交叉层的数量。
    """
    
    def __init__(self, input_dim: int, num_layers: int):
        super(CrossNetwork, self).__init__()
        self.num_layers = num_layers
        self.cross_layers = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])
        self.bias = nn.ParameterList([nn.Parameter(torch.zeros(input_dim)) for _ in range(num_layers)])
    
    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:
        x0 = x
        for i in range(self.num_layers):
            xl_w = self.cross_layers[i](x)
            x = x0 * xl_w + self.bias[i] + x
        return x

class DeepNetwork(nn.Module):
    """Deep网络定义。
    
    Args:
        num_embeddings (int): Embedding层输入的类别数量。
        embedding_dim (int): Embedding层输出的维度。
        hidden_layers (List[int]): 隐藏层的神经元数量。
    """
    
    def __init__(self, num_embeddings: int, embedding_dim: int, hidden_layers: List[int]):
        super(DeepNetwork, self).__init__()
        self.embedding = nn.Embedding(num_embeddings, embedding_dim)
        input_dim = embedding_dim * num_embeddings
        self.deep_layers = nn.Sequential()
        
        for i, hidden_dim in enumerate(hidden_layers):
            self.deep_layers.add_module(f'fc{i}', nn.Linear(input_dim, hidden_dim))
            self.deep_layers.add_module(f'relu{i}', nn.ReLU())
            input_dim = hidden_dim
            
        self.deep_layers.add_module('output', nn.Linear(input_dim, 1))
        
    def forward(self, deep_input: torch.LongTensor) -> torch.FloatTensor:
        deep_input_emb = self.embedding(deep_input).view(deep_input.size(0), -1)
        deep_output = self.deep_layers(deep_input_emb)
        return deep_output

class DeepAndCrossModel(nn.Module):
    """Deep & Cross模型定义。
    
    Args:
        input_dim_wide (int): Wide部分的输入特征维度。
        num_embeddings (int): Deep部分Embedding层输入的类别数量。
        embedding_dim (int): Deep部分Embedding层输出的维度。
        cross_layers (int): Cross部分交叉层的数量。
        hidden_layers (List[int]): Deep部分隐藏层的神经元数量。
    """
    
    def __init__(self, input_dim_wide: int, num_embeddings: int, embedding_dim: int, cross_layers: int, hidden_layers: List[int]):
        super(DeepAndCrossModel, self).__init__()
        
        # Cross部分
        self.cross_network = CrossNetwork(input_dim_wide, cross_layers)
        
        # Deep部分
        self.deep_network = DeepNetwork(num_embeddings, embedding_dim, hidden_layers)
        
        # 输出层
        self.output_layer = nn.Linear(input_dim_wide + 1, 1)
        
    def forward(self, wide_input: torch.FloatTensor, deep_input: torch.LongTensor) -> torch.FloatTensor:
        # Cross网络
        cross_output = self.cross_network(wide_input)
        
        # Deep网络
        deep_output = self.deep_network(deep_input)
        
        # Wide & Deep结合
        combined_output = torch.cat((cross_output, deep_output), dim=1)
        output = torch.sigmoid(self.output_layer(combined_output))
        return output

def train_model(model: nn.Module, dataloader: DataLoader, criterion: nn.BCELoss, optimizer: optim.Adam, epochs: int) -> None:
    """训练Deep & Cross模型。
    
    Args:
        model (nn.Module): Deep & Cross模型。
        dataloader (DataLoader): 训练数据的DataLoader。
        criterion (nn.BCELoss): 损失函数。
        optimizer (optim.Adam): 优化器。
        epochs (int): 训练轮数。
    """
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        for wide_input, deep_input, label in dataloader:
            optimizer.zero_grad()
            outputs = model(wide_input, deep_input)
            loss = criterion(outputs.squeeze(), label)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader):.4f}')

def evaluate_model(model: nn.Module, dataloader: DataLoader, criterion: nn.BCELoss) -> None:
    """评估Deep & Cross模型。
    
    Args:
        model (nn.Module): Deep & Cross模型。
        dataloader (DataLoader): 验证数据的DataLoader。
        criterion (nn.BCELoss): 损失函数。
    """
    model.eval()
    eval_loss = 0
    with torch.no_grad():
        for wide_input, deep_input, label in dataloader:
            outputs = model(wide_input, deep_input)
            loss = criterion(outputs.squeeze(), label)
            eval_loss += loss.item()
    print(f'Evaluation Loss: {eval_loss / len(dataloader):.4f}')

def load_data(file_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """加载和预处理数据。
    
    Args:
        file_path (str): 数据文件路径。

    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]: 训练集和验证集的特征和标签。
    """
    data = pd.read_csv(file_path)
    wide_features = data.iloc[:, :5].values  # 假设前5列是Wide特征
    deep_features = data.iloc[:, 5:-1].values  # 假设5列之后到倒数第二列是Deep特征
    labels = data.iloc[:, -1].values  # 假设最后一列是标签
    split_idx = int(len(data) * 0.8)
    return (wide_features[:split_idx], deep_features[:split_idx], labels[:split_idx],
            wide_features[split_idx:], deep_features[split_idx:], labels[split_idx:])

def main() -> None:
    """主函数，执行Deep & Cross模型的训练和评估。"""
    # 加载数据
    wide_features_train, deep_features_train, labels_train, wide_features_val, deep_features_val, labels_val = load_data('data.csv')
    
    # 创建Dataset和DataLoader
    train_dataset = CustomDataset(wide_features_train, deep_features_train, labels_train)
    val_dataset = CustomDataset(wide_features_val, deep_features_val, labels_val)
    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # 模型初始化
    num_embeddings = int(deep_features_train.max()) + 1  # 假设Deep特征是类别型特征
    model = DeepAndCrossModel(input_dim_wide=wide_features_train.shape[1], num_embeddings=num_embeddings, embedding_dim=8, cross_layers=3, hidden_layers=[64, 32, 16])
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 训练模型
    train_model(model, train_dataloader, criterion, optimizer, epochs=20)

    # 评估模型
    evaluate_model(model, val_dataloader, criterion)

if __name__ == '__main__':
    main()</code></pre>
  </div>
</body>
</html>
  