
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>2.2.2 用户相似度计算</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>01_2.2.2 用户相似度计算</h1>
<pre><code>Lecture: 第2章 前深度学习时代——推荐系统的进化之路/2.2 协同过滤——经典的推荐算法
Content: 01_2.2.2 用户相似度计算
</code></pre>
<h3>2.2.2 用户相似度计算</h3>
<h4>1. 概述</h4>
<p>在协同过滤推荐系统中，用户相似度的计算是关键步骤。用户相似度用于识别兴趣相似的用户，从而基于这些相似用户的行为数据进行推荐。常用的相似度计算方法包括余弦相似度和皮尔逊相关系数 。</p>
<h4>2. 余弦相似度（Cosine Similarity）</h4>
<p>余弦相似度用于衡量两个向量之间的夹角。其计算公式为：
$$ \text{Sim}_{\text{cos}}(i,j) = \frac{\mathbf{R}_i \cdot \mathbf{R}_j}{|\mathbf{R}_i| |\mathbf{R}_j|} $$
其中，$\mathbf{R}_i$ 和 $\mathbf{R}_j$ 分别表示用户 $i$ 和用户 $j$ 的评分向量，点积 $\mathbf{R}_i \cdot \mathbf{R}_j$ 衡量了两个向量的相似度，$|\mathbf{R}_i|$ 和 $|\mathbf{R}_j|$ 分别表示向量的模。</p>
<h5>优点</h5>
<ol>
<li><strong>直观性</strong>：余弦相似度简单易懂，计算方便。</li>
<li><strong>应用广泛</strong>：在各种推荐系统中被广泛使用。</li>
</ol>
<h5>缺点</h5>
<ol>
<li><strong>忽略评分差异</strong>：余弦相似度未考虑评分的绝对差异，可能导致不同评分尺度的用户被认为是相似的。</li>
</ol>
<h4>3. 皮尔逊相关系数（Pearson Correlation Coefficient）</h4>
<p>皮尔逊相关系数通过调整评分均值来衡量两个向量之间的线性相关性。其计算公式为：
$$ \text{Sim}<em>{\text{pearson}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">i)(R</em> - \bar{R}<em>j)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>i)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}<em i,p="">j)^2}} $$
其中，$R</em>$ 表示用户 $i$ 对物品 $p$ 的评分，$\bar{R}_i$ 表示用户 $i$ 的平均评分，$P$ 表示共同评分的物品集合 。</p>
<h5>优点</h5>
<ol>
<li><strong>考虑评分差异</strong>：皮尔逊相关系数通过减去均值，减小了评分偏置的影响。</li>
<li><strong>更准确</strong>：在用户评分分布不均匀时，皮尔逊相关系数能更准确地反映用户之间的相似度。</li>
</ol>
<h5>缺点</h5>
<ol>
<li><strong>计算复杂</strong>：皮尔逊相关系数计算比余弦相似度复杂，需要更多计算资源。</li>
<li><strong>依赖数据量</strong>：在评分数据稀疏的情况下，皮尔逊相关系数可能不稳定。</li>
</ol>
<h4>4. 修正余弦相似度（Adjusted Cosine Similarity）</h4>
<p>修正余弦相似度通过考虑物品的平均评分来调整用户评分，从而更准确地衡量相似度。其计算公式为：
$$ \text{Sim}<em>{\text{adjusted cos}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">p)(R</em> - \bar{R}<em>p)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>p)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}_p)^2}} $$
其中，$\bar{R}_p$ 表示物品 $p$ 的平均评分 。</p>
<h5>优点</h5>
<ol>
<li><strong>减小物品评分偏置</strong>：修正余弦相似度通过调整物品平均评分，减少了物品评分偏置的影响。</li>
<li><strong>更准确</strong>：在用户对不同物品评分差异较大时，修正余弦相似度能更准确地反映用户之间的相似度。</li>
</ol>
<h5>缺点</h5>
<ol>
<li><strong>计算复杂</strong>：需要计算物品的平均评分，增加了计算复杂度。</li>
<li><strong>依赖数据量</strong>：在物品评分数据稀疏时，修正余弦相似度可能不稳定。</li>
</ol>
<h4>5. 用户相似度的应用</h4>
<p>在推荐系统中，用户相似度计算用于识别与目标用户兴趣相似的其他用户，从而基于这些相似用户的行为数据进行推荐。具体应用步骤如下：</p>
<ol>
<li><strong>计算相似度矩阵</strong>：根据用户评分数据，计算所有用户之间的相似度矩阵。</li>
<li><strong>选择相似用户</strong>：为目标用户选择Top n个最相似的用户。</li>
<li><strong>生成推荐列表</strong>：根据相似用户的评分数据，生成目标用户的推荐列表  。</li>
</ol>
<h4>6. 优缺点分析</h4>
<h5>优点</h5>
<ol>
<li><strong>简洁性</strong>：用户相似度计算方法简单易懂，便于实现。</li>
<li><strong>高效性</strong>：在数据量不大的情况下，计算相似度和生成推荐列表的效率较高。</li>
</ol>
<h5>缺点</h5>
<ol>
<li><strong>数据稀疏性问题</strong>：在实际应用中，用户评分数据往往非常稀疏，导致相似度计算不准确。</li>
<li><strong>扩展性差</strong>：随着用户数量和物品数量的增加，计算相似度矩阵的存储和计算开销迅速增加。</li>
<li><strong>冷启动问题</strong>：对于新用户或新物品，由于缺乏足够的评分数据，难以准确计算相似度并生成推荐 。</li>
</ol>
<h3>结论</h3>
<p>用户相似度计算在协同过滤推荐系统中起着关键作用。余弦相似度、皮尔逊相关系数和修正余弦相似度是常用的相似度计算方法，各有优缺点。尽管用户相似度计算面临数据稀疏性、扩展性和冷启动问题，但其直观性和高效性使其在推荐系统中得到了广泛应用。通过不断改进算法和优化计算方法，可以在一定程度上克服这些问题，提高推荐系统的性能和用户体验。</p>
<hr>
<h3>用户相似度计算方法详细对比表</h3>
<table>
<thead>
<tr>
<th><strong>特征</strong></th>
<th><strong>余弦相似度（Cosine Similarity）</strong></th>
<th><strong>皮尔逊相关系数（Pearson Correlation Coefficient）</strong></th>
<th><strong>修正余弦相似度（Adjusted Cosine Similarity）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>计算公式</strong></td>
<td>$\text{Sim}_{\text{cos}}(i,j) = \frac{\mathbf{R}_i \cdot \mathbf{R}_j}{|\mathbf{R}_i| |\mathbf{R}_j|}$</td>
<td>$\text{Sim}<em>{\text{pearson}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">i)(R</em> - \bar{R}<em>j)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>i)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}_j)^2}}$</td>
<td>$\text{Sim}<em>{\text{adjusted cos}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">p)(R</em> - \bar{R}<em>p)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>p)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}_p)^2}}$</td>
</tr>
<tr>
<td><strong>计算内容</strong></td>
<td>衡量两个向量的夹角</td>
<td>衡量两个向量之间的线性相关性</td>
<td>调整评分后衡量两个向量的相似度</td>
</tr>
<tr>
<td><strong>优点</strong></td>
<td>1. 简单易懂，计算方便&lt;br&gt;2. 应用广泛</td>
<td>1. 考虑评分差异，减小评分偏置影响&lt;br&gt;2. 准确反映用户相似度</td>
<td>1. 减小物品评分偏置&lt;br&gt;2. 更准确反映用户之间的相似度</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>1. 忽略评分的绝对差异</td>
<td>1. 计算复杂，资源消耗高&lt;br&gt;2. 数据稀疏时不稳定</td>
<td>1. 计算复杂度高&lt;br&gt;2. 数据稀疏时不稳定</td>
</tr>
<tr>
<td><strong>计算复杂度</strong></td>
<td>低</td>
<td>中</td>
<td>高</td>
</tr>
<tr>
<td><strong>评分偏置处理</strong></td>
<td>无</td>
<td>通过减去均值处理</td>
<td>通过减去物品平均评分处理</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>适用于评分标准一致、评分数据较多的情况</td>
<td>适用于评分分布不均匀的情况</td>
<td>适用于评分差异较大的情况</td>
</tr>
<tr>
<td><strong>对稀疏数据的敏感度</strong></td>
<td>高</td>
<td>中</td>
<td>中</td>
</tr>
<tr>
<td><strong>公式解释</strong></td>
<td>$$1$$ 计算两个用户的评分向量点积，除以两个向量的模</td>
<td>$$2$$ 计算两个用户对共同物品评分与其平均值的差，求和后再归一化</td>
<td>$$3$$ 计算两个用户对共同物品评分与物品平均评分的差，求和后再归一化</td>
</tr>
</tbody>
</table>
<h3>详细解释</h3>
<h4>余弦相似度</h4>
<ul>
<li><strong>计算公式</strong>:
$$
\text{Sim}_{\text{cos}}(i,j) = \frac{\mathbf{R}_i \cdot \mathbf{R}_j}{|\mathbf{R}_i| |\mathbf{R}_j|}
$$</li>
<li><strong>解释</strong>: 计算两个用户评分向量的夹角余弦值。点积衡量了两个向量的相似度，向量模表示了向量的长度。</li>
<li><strong>优点</strong>: 简单直观，计算方便。广泛应用于各种推荐系统。</li>
<li><strong>缺点</strong>: 忽略了评分的绝对差异，可能导致不同评分尺度的用户被认为是相似的。</li>
</ul>
<h4>皮尔逊相关系数</h4>
<ul>
<li><strong>计算公式</strong>:
$$
\text{Sim}<em>{\text{pearson}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">i)(R</em> - \bar{R}<em>j)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>i)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}_j)^2}}
$$</li>
<li><strong>解释</strong>: 通过减去均值，计算两个用户评分向量之间的线性相关性。通过考虑评分的均值，减小了评分偏置的影响。</li>
<li><strong>优点</strong>: 更准确地反映用户之间的相似度，特别是在用户评分分布不均匀的情况下。</li>
<li><strong>缺点</strong>: 计算复杂度高，依赖于评分数据量。在数据稀疏的情况下可能不稳定。</li>
</ul>
<h4>修正余弦相似度</h4>
<ul>
<li><strong>计算公式</strong>:
$$
\text{Sim}<em>{\text{adjusted cos}}(i,j) = \frac{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em j,p="">p)(R</em> - \bar{R}<em>p)}{\sqrt{\sum</em>{p \in P} (R_{i,p} - \bar{R}<em>p)^2} \sqrt{\sum</em>{p \in P} (R_{j,p} - \bar{R}_p)^2}}
$$</li>
<li><strong>解释</strong>: 通过减去物品的平均评分，调整用户评分后计算相似度。这减少了物品评分偏置的影响，使相似度计算更加准确。</li>
<li><strong>优点</strong>: 减小了物品评分偏置的影响，更准确地反映用户之间的相似度，特别是在用户对不同物品评分差异较大的情况下。</li>
<li><strong>缺点</strong>: 计算复杂度高，需要计算物品的平均评分。在数据稀疏的情况下可能不稳定。</li>
</ul>
<h3>总结</h3>
<p>通过比较三种常用的用户相似度计算方法，我们可以看到它们各有优缺点，适用于不同的场景和数据情况。余弦相似度简单直观，适用于评分标准一致、评分数据较多的情况；皮尔逊相关系数考虑评分差异，适用于评分分布不均匀的情况；修正余弦相似度通过调整物品平均评分，适用于评分差异较大的情况。在实际应用中，可以根据具体的数据特点和需求选择合适的相似度计算方法，或者结合多种方法进行综合评估，以提高推荐系统的性能和用户体验。</p>

    <h3>Python 文件</h3>
    <pre><code># 01_2.2.2 用户相似度计算

"""
Lecture: 第2章 前深度学习时代——推荐系统的进化之路/2.2 协同过滤——经典的推荐算法
Content: 01_2.2.2 用户相似度计算
"""

import numpy as np
from typing import Dict, List, Tuple

class CollaborativeFiltering:
    def __init__(self, user_item_matrix: np.ndarray):
        """
        初始化协同过滤类

        Args:
            user_item_matrix (np.ndarray): 用户-物品评分矩阵
        """
        self.user_item_matrix = user_item_matrix

    def cosine_similarity(self, user1: int, user2: int) -> float:
        """
        计算两个用户之间的余弦相似度

        Args:
            user1 (int): 用户1的索引
            user2 (int): 用户2的索引

        Returns:
            float: 余弦相似度
        """
        vec1 = self.user_item_matrix[user1]
        vec2 = self.user_item_matrix[user2]
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)

    def pearson_correlation(self, user1: int, user2: int) -> float:
        """
        计算两个用户之间的皮尔逊相关系数

        Args:
            user1 (int): 用户1的索引
            user2 (int): 用户2的索引

        Returns:
            float: 皮尔逊相关系数
        """
        vec1 = self.user_item_matrix[user1]
        vec2 = self.user_item_matrix[user2]
        mean1 = np.mean(vec1[vec1 > 0])
        mean2 = np.mean(vec2[vec2 > 0])
        centered_vec1 = vec1 - mean1
        centered_vec2 = vec2 - mean2
        mask = (vec1 > 0) & (vec2 > 0)
        if not np.any(mask):
            return 0.0
        centered_vec1 = centered_vec1[mask]
        centered_vec2 = centered_vec2[mask]
        dot_product = np.dot(centered_vec1, centered_vec2)
        norm1 = np.linalg.norm(centered_vec1)
        norm2 = np.linalg.norm(centered_vec2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)

    def adjusted_cosine_similarity(self, user1: int, user2: int) -> float:
        """
        计算两个用户之间的修正余弦相似度

        Args:
            user1 (int): 用户1的索引
            user2 (int): 用户2的索引

        Returns:
            float: 修正余弦相似度
        """
        vec1 = self.user_item_matrix[user1]
        vec2 = self.user_item_matrix[user2]
        item_means = np.mean(self.user_item_matrix, axis=0)
        adjusted_vec1 = vec1 - item_means
        adjusted_vec2 = vec2 - item_means
        mask = (vec1 > 0) & (vec2 > 0)
        if not np.any(mask):
            return 0.0
        adjusted_vec1 = adjusted_vec1[mask]
        adjusted_vec2 = adjusted_vec2[mask]
        dot_product = np.dot(adjusted_vec1, adjusted_vec2)
        norm1 = np.linalg.norm(adjusted_vec1)
        norm2 = np.linalg.norm(adjusted_vec2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)

    def compute_similarities(self, method: str = 'cosine') -> Dict[Tuple[int, int], float]:
        """
        计算所有用户之间的相似度

        Args:
            method (str): 相似度计算方法（'cosine', 'pearson', 'adjusted_cosine'）

        Returns:
            Dict[Tuple[int, int], float]: 用户对之间的相似度字典
        """
        num_users = self.user_item_matrix.shape[0]
        similarities = {}
        for user1 in range(num_users):
            for user2 in range(user1 + 1, num_users):
                if method == 'cosine':
                    similarity = self.cosine_similarity(user1, user2)
                elif method == 'pearson':
                    similarity = self.pearson_correlation(user1, user2)
                elif method == 'adjusted_cosine':
                    similarity = self.adjusted_cosine_similarity(user1, user2)
                else:
                    raise ValueError("Invalid method: choose from 'cosine', 'pearson', 'adjusted_cosine'")
                similarities[(user1, user2)] = similarity
                similarities[(user2, user1)] = similarity
        return similarities

    def predict_rating(self, user: int, item: int, similarities: Dict[Tuple[int, int], float], top_n: int = 10) -> float:
        """
        预测用户对物品的评分

        Args:
            user (int): 用户索引
            item (int): 物品索引
            similarities (Dict[Tuple[int, int], float]): 用户对之间的相似度字典
            top_n (int): 使用相似用户的数量

        Returns:
            float: 预测评分
        """
        similar_users = sorted(similarities.keys(), key=lambda x: similarities[x], reverse=True)
        top_similar_users = [u for u in similar_users if u[0] == user or u[1] == user][:top_n]
        numerator = sum(similarities[(u, user)] * self.user_item_matrix[u, item] for u in top_similar_users)
        denominator = sum(abs(similarities[(u, user)]) for u in top_similar_users)
        if denominator == 0:
            return 0.0
        return numerator / denominator

def main():
    # 示例用户-物品评分矩阵
    user_item_matrix = np.array([
        [5, 3, 0, 1],
        [4, 0, 0, 1],
        [1, 1, 0, 5],
        [1, 0, 0, 4],
        [0, 1, 5, 4],
    ])

    # 初始化协同过滤模型
    cf = CollaborativeFiltering(user_item_matrix)

    # 计算所有用户之间的余弦相似度
    cosine_similarities = cf.compute_similarities(method='cosine')
    print("Cosine Similarities:")
    for pair, similarity in cosine_similarities.items():
        print(f"User {pair[0]} - User {pair[1]}: {similarity}")

    # 计算所有用户之间的皮尔逊相关系数
    pearson_similarities = cf.compute_similarities(method='pearson')
    print("\nPearson Correlation Coefficients:")
    for pair, similarity in pearson_similarities.items():
        print(f"User {pair[0]} - User {pair[1]}: {similarity}")

    # 计算所有用户之间的修正余弦相似度
    adjusted_cosine_similarities = cf.compute_similarities(method='adjusted_cosine')
    print("\nAdjusted Cosine Similarities:")
    for pair, similarity in adjusted_cosine_similarities.items():
        print(f"User {pair[0]} - User {pair[1]}: {similarity}")

    # 预测用户0对物品2的评分
    predicted_rating = cf.predict_rating(user=0, item=2, similarities=cosine_similarities, top_n=2)
    print(f"\nPredicted Rating for User 0 on Item 2: {predicted_rating}")

if __name__ == "__main__":
    main()
</code></pre>
  </div>
</body>
</html>
  