
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>2.3.3 消除用户和物品打分的偏差</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>02_2.3.3 消除用户和物品打分的偏差</h1>
<pre><code>Lecture: 第2章 前深度学习时代——推荐系统的进化之路/2.3 矩阵分解算法——协同过滤的进化
Content: 02_2.3.3 消除用户和物品打分的偏差
</code></pre>
<h3>2.3.3 消除用户和物品打分的偏差</h3>
<h4>概述</h4>
<p>在推荐系统中，由于不同用户和物品的评分标准不同，常会出现评分偏差（Bias）。例如，有些用户习惯给高分，而另一些用户则倾向于给低分；不同类型的物品也可能有不同的平均评分水平。为了提高推荐系统的准确性和公平性，我们需要在矩阵分解过程中消除这些偏差。</p>
<h4>偏差的来源</h4>
<ol>
<li><strong>用户偏差（User Bias）</strong>：不同用户的评分习惯不同，有些用户习惯性打高分，有些用户则习惯性打低分。</li>
<li><strong>物品偏差（Item Bias）</strong>：不同物品的评分标准不同，例如电子产品的平均评分可能高于日用品。</li>
</ol>
<h4>消除偏差的方法</h4>
<p>在矩阵分解的过程中，我们可以通过引入偏差向量来消除用户和物品的评分偏差。具体方法如下：</p>
<h5>1. 引入偏差向量</h5>
<p>在传统的矩阵分解模型中，评分矩阵 $R$ 被分解为用户特征矩阵 $P$ 和物品特征矩阵 $Q$ 的乘积：
$$ R \approx P \times Q^T $$</p>
<p>为了消除评分偏差，我们引入全局偏差 $\mu$、用户偏差向量 $b_u$ 和物品偏差向量 $b_i$，使得评分矩阵的估计值为：
$$ R_{ij} \approx \mu + b_u[i] + b_i[j] + P[i, :] \cdot Q[j, :]^T $$</p>
<p>其中：</p>
<ul>
<li>$\mu$ 是全局平均评分。</li>
<li>$b_u[i]$ 是用户 $i$ 的偏差。</li>
<li>$b_i[j]$ 是物品 $j$ 的偏差。</li>
</ul>
<h5>2. 目标函数的修改</h5>
<p>在引入偏差向量后，我们需要修改矩阵分解的目标函数。新的目标函数如下：
$$ \min_{P, Q, b_u, b_i} \sum_{(i,j) \in K} (R_{ij} - (\mu + b_u[i] + b_i[j] + P[i, :] \cdot Q[j, :]^T))^2 + \lambda (|P|^2 + |Q|^2 + |b_u|^2 + |b_i|^2) $$</p>
<p>其中：</p>
<ul>
<li>$K$ 是已知评分的集合。</li>
<li>$\lambda$ 是正则化参数，用于防止过拟合。</li>
</ul>
<h5>3. 梯度下降优化</h5>
<p>为了最小化目标函数，我们可以使用梯度下降法更新参数。更新规则如下：
$$ b_u[i] := b_u[i] + \alpha \left( e_{ij} - \lambda b_u[i] \right) $$
$$ b_i[j] := b_i[j] + \alpha \left( e_{ij} - \lambda b_i[j] \right) $$
$$ P[i, :] := P[i, :] + \alpha \left( e_{ij} Q[j, :] - \lambda P[i, :] \right) $$
$$ Q[j, :] := Q[j, :] + \alpha \left( e_{ij} P[i, :] - \lambda Q[j, :] \right) $$</p>
<p>其中：</p>
<ul>
<li>$e_{ij} = R_{ij} - (\mu + b_u[i] + b_i[j] + P[i, :] \cdot Q[j, :]^T)$ 是误差。</li>
<li>$\alpha$ 是学习率。</li>
</ul>
<h4>实例分析</h4>
<p>通过引入用户和物品的偏差项，矩阵分解能够更准确地反映用户对物品的真实态度，从而提高推荐结果的准确性。例如：</p>
<ul>
<li>对于一个习惯性打低分的用户，即使其对某个物品的评分低，系统也能通过其偏差项调整预测评分，避免误判。</li>
<li>对于一个评分较高的物品，即使其被部分用户打低分，系统也能通过物品的偏差项调整预测评分，保持推荐的准确性。</li>
</ul>
<h4>结论</h4>
<p>消除用户和物品打分的偏差是提高推荐系统准确性的重要手段。通过在矩阵分解过程中引入偏差向量，并修改目标函数，我们可以有效地消除评分偏差，提高推荐结果的公平性和准确性。这一方法在实际应用中得到了广泛的验证和应用。</p>
<hr>

    <h3>Python 文件</h3>
    <pre><code># 02_2.3.3 消除用户和物品打分的偏差

"""
Lecture: 第2章 前深度学习时代——推荐系统的进化之路/2.3 矩阵分解算法——协同过滤的进化
Content: 02_2.3.3 消除用户和物品打分的偏差
"""

import numpy as np
from typing import Tuple

class MatrixFactorizationWithBias:
    def __init__(self, R: np.ndarray, K: int, alpha: float, beta: float, iterations: int):
        """
        初始化矩阵分解类，考虑用户和物品偏差

        Args:
            R (np.ndarray): 用户-物品评分矩阵
            K (int): 潜在特征的数量
            alpha (float): 学习率
            beta (float): 正则化参数
            iterations (int): 迭代次数
        """
        self.R = R
        self.num_users, self.num_items = R.shape
        self.K = K
        self.alpha = alpha
        self.beta = beta
        self.iterations = iterations
        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))
        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))
        self.b_u = np.zeros(self.num_users)
        self.b_i = np.zeros(self.num_items)
        self.b = np.mean(self.R[np.where(self.R != 0)])
        self.samples = [
            (i, j, self.R[i, j])
            for i in range(self.num_users)
            for j in range(self.num_items)
            if self.R[i, j] > 0
        ]

    def train(self) -> Tuple[np.ndarray, np.ndarray, float]:
        """
        训练矩阵分解模型

        Returns:
            Tuple[np.ndarray, np.ndarray, float]: 分别为用户特征矩阵、物品特征矩阵及训练误差
        """
        training_process = []
        for i in range(self.iterations):
            np.random.shuffle(self.samples)
            self.sgd()
            mse = self.mse()
            training_process.append((i, mse))
            if (i+1) % 10 == 0:
                print(f"Iteration: {i+1}; error = {mse:.4f}")

        return self.P, self.Q, training_process

    def mse(self) -> float:
        """
        计算均方误差

        Returns:
            float: 均方误差
        """
        xs, ys = self.R.nonzero()
        predicted = self.full_matrix()
        error = 0
        for x, y in zip(xs, ys):
            error += (self.R[x, y] - predicted[x, y])**2
        return np.sqrt(error)

    def sgd(self):
        """
        随机梯度下降优化
        """
        for i, j, r in self.samples:
            prediction = self.get_prediction(i, j)
            e = (r - prediction)

            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])
            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])

            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])
            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])

    def get_prediction(self, i: int, j: int) -> float:
        """
        获取对用户i对物品j的评分预测

        Args:
            i (int): 用户索引
            j (int): 物品索引

        Returns:
            float: 预测评分
        """
        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)
        return prediction

    def full_matrix(self) -> np.ndarray:
        """
        重建完整的用户-物品评分矩阵

        Returns:
            np.ndarray: 完整评分矩阵
        """
        return self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis:, ] + self.P.dot(self.Q.T)

def main():
    # 示例用户-物品评分矩阵
    R = np.array([
        [5, 3, 0, 1],
        [4, 0, 0, 1],
        [1, 1, 0, 5],
        [1, 0, 0, 4],
        [0, 1, 5, 4],
    ])

    # 初始化矩阵分解模型
    mf = MatrixFactorizationWithBias(R, K=2, alpha=0.01, beta=0.01, iterations=100)

    # 训练模型
    P, Q, training_process = mf.train()

    print("\nP matrix:\n", P)
    print("\nQ matrix:\n", Q)
    print("\nPredicted Ratings:\n", mf.full_matrix())

if __name__ == "__main__":
    main()
</code></pre>
  </div>
</body>
</html>
  