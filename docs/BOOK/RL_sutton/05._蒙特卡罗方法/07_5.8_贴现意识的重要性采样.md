# 07_5.8_贴现意识的重要性采样

"""
Lecture: /05._蒙特卡罗方法
Content: 07_5.8_贴现意识的重要性采样
"""

### 07_5.8 贴现意识的重要性采样

#### 贴现意识的重要性采样简介

贴现意识的重要性采样（Discounting-aware Importance Sampling）是一种先进的研究方法，用于减少离策略估计器的方差。在之前讨论的离策略方法中，返回值被视为整体进行重要性采样，而没有考虑返回值作为贴现奖励和的内部结构。贴现意识的重要性采样则利用这一结构，通过部分终止的思想，显著减少了方差。

#### 关键概念

1. **重要性采样比率**：
   - 在传统的重要性采样中，返回值被整个比例缩放，这可能导致非常高的方差，尤其是在序列较长时。例如，假设一个序列有100步，且贴现因子 $\gamma = 0$，返回值 $G_0 = R_1$ 的重要性采样比率将是100个比率的乘积：
     $$
     \prod_{t=0}^{99} \frac{\pi(A_t|S_t)}{b(A_t|S_t)}
     $$
     而实际上，只需对第一个因子进行缩放，因为后续的因子独立于返回值，并且期望值为1。

2. **部分终止和平坦部分返回值**：
   - 贴现意识的重要性采样通过将贴现视为部分终止的概率，从而重新定义返回值。例如，对于任意 $\gamma \in [0, 1)$，可以将返回值 $G_0$ 视为部分终止于一步、两步或更多步。部分返回值被定义为：
     $$
     \bar{G}_{t:h} = R_{t+1} + R_{t+2} + \cdots + R_h
     $$
     其中“平坦”表示没有贴现，“部分”表示返回值并未延续到终止，而是止于某个时间点 $h$。

3. **平坦返回值的和**：
   - 传统的完整返回值 $G_t$ 可以视为平坦部分返回值的和：
     $$
     G_t = (1 - \gamma)R_{t+1} + (1 - \gamma)\gamma (R_{t+1} + R_{t+2}) + \cdots
     $$
     这种方法将返回值拆分成多个部分，每个部分对应一个不同的终止概率，从而减少了每一步的方差。

#### 算法步骤

1. **初始化**：
   - 初始化动作值函数 $Q(s, a)$ 和累计权重 $C(s, a)$。
   - 初始策略为贪心策略，根据 $Q(s, a)$ 选择动作。

2. **生成序列**：
   - 使用行为策略生成一个完整的序列，记录状态、动作和相应的奖励。

3. **计算重要性采样比率**：
   - 对于每个状态-动作对，计算重要性采样比率 $W$，用于调整回报。

4. **更新动作值函数**：
   - 根据重要性采样比率和回报，使用加权重要性采样的方法更新动作值函数。

5. **策略改进**：
   - 根据当前的动作值函数 $Q(s, a)$ 更新策略，使其贪心于 $Q$。

6. **重复**：
   - 反复进行生成序列、计算比率、更新值函数和策略改进，直到策略收敛。

#### 优缺点分析

**优点**：
1. **降低方差**：通过部分终止的思想，贴现意识的重要性采样显著减少了方差，使得估计更加稳定。
2. **提高效率**：减少不必要的比率计算，提高了算法的效率。

**缺点**：
1. **复杂性增加**：需要重新定义返回值和终止概率，增加了算法的复杂性。
2. **适用范围有限**：这种方法可能不适用于所有的强化学习问题，尤其是那些不易定义平坦部分返回值的问题。

#### 应用实例

在实际应用中，贴现意识的重要性采样可以用于各种离策略强化学习任务。例如，在金融市场中，可以使用行为策略生成交易数据，同时评估和改进目标策略，以优化投资回报。

### 结论

贴现意识的重要性采样通过重新定义返回值和终止概率，显著减少了离策略估计的方差，提高了算法的效率和稳定性。尽管增加了算法的复杂性，但其在特定应用中的优势是显而易见的，特别是在需要高效估计和低方差的情况下。