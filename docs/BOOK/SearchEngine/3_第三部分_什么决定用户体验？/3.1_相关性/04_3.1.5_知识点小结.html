
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.1.5 知识点小结</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>04_3.1.5_知识点小结</h1>
<pre><code>Lecture: 3_第三部分_什么决定用户体验？/3.1_相关性
Content: 04_3.1.5_知识点小结
</code></pre>
<h2>知识点小结：相关性模型训练</h2>
<h3>一、简介</h3>
<p>相关性模型的训练是搜索引擎优化中的关键步骤，通过训练高精度的相关性模型，可以提升用户体验和业务指标。本小结将详细总结相关性模型的训练方法、评价指标和优化策略。</p>
<h3>二、训练步骤</h3>
<p>相关性模型的训练包括预训练、后预训练、微调和蒸馏四个主要步骤。</p>
<h4>1. 预训练（Pre-training）</h4>
<p>预训练通过大规模无标注的文本数据进行自监督学习，使模型掌握丰富的语言知识和上下文理解能力。主要任务包括掩码语言模型（MLM）和下一句预测（NSP）。</p>
<ul>
<li><strong>MLM</strong>：随机掩码输入文本中的部分词，让模型预测这些词。</li>
<li><strong>NSP</strong>：判断两段文本是否相邻。</li>
</ul>
<h4>2. 后预训练（Post Pre-training）</h4>
<p>后预训练通过挖掘搜索日志数据，构建大规模的相关性数据集，并进一步训练模型。利用小模型（如GBDT）将用户行为统计量映射到相关性分数上，用这些分数来训练大模型。</p>
<h4>3. 微调（Fine-tuning）</h4>
<p>微调在人工标注的数据集上进行，通过数十万、数百万条样本，进一步优化模型在特定任务上的表现。高质量的标注数据至关重要，需要制定详细的标注规则并进行严格的质量控制。</p>
<h4>4. 蒸馏（Distillation）</h4>
<p>蒸馏通过大模型指导小模型的训练，使小模型也能获得大模型的高性能。蒸馏需要大量数据，通常为数亿对（q, d）二元组，通过大模型的输出作为小模型的训练目标。</p>
<h3>三、模型评价与优化</h3>
<h4>1. 评价指标</h4>
<p>评价指标包括AUC和正逆序比，用于衡量模型的预测和排序效果。</p>
<ul>
<li><strong>AUC</strong>：衡量模型预测的相关性分数与实际标签的一致性，数值越高，模型越准确。</li>
<li><strong>正逆序比</strong>：考察模型对文档排序的准确性，通过比较文档对的正序与逆序数量进行评估。</li>
</ul>
<h4>2. 损失函数</h4>
<p>损失函数包括Pointwise、Pairwise和预训练损失函数，用于不同阶段的训练优化。</p>
<ul>
<li><strong>Pointwise 损失函数</strong>：如均方误差（MSE）和交叉熵，用于提升AUC指标。</li>
<li><strong>Pairwise 损失函数</strong>：如对比损失和pairwise logistic损失，用于提升正逆序比。</li>
<li><strong>预训练损失函数</strong>：如MLM损失和NSP损失，确保预训练成果在后续训练中被保留。</li>
</ul>
<h3>四、后预训练阶段的数据构建</h3>
<h4>1. 数据来源</h4>
<p>数据来源于搜索引擎的日志数据，记录了用户的搜索行为，包括查询词（query）、点击的文档（document）、停留时间（dwell time）、点击率（CTR）、交互率等。</p>
<h4>2. 数据抽取</h4>
<p>从搜索日志中抽取数亿对（q, d）二元组，并计算这些二元组的用户行为统计量（如点击率、交互率等）。这些统计量作为特征向量，结合文档文本作为模型输入。</p>
<h4>3. 数据标注</h4>
<p>利用用户行为数据进行自动标注，通过用户的点击行为和交互行为，为（q, d）对打上相关性标签。点击次数和交互次数越多，相关性越高。</p>
<h4>4. 数据清洗</h4>
<p>对抽取的数据进行清洗，去除噪声数据和无关数据，保证数据质量。去除重复的查询词和文档对，过滤掉停留时间过短的点击记录，并对查询词和文档文本进行分词、去停用词、词干提取等预处理。</p>
<h4>5. 特征工程</h4>
<p>对构建的数据集进行特征工程，提取有用的特征向量。常见的特征包括文本特征（如TF-IDF、词向量）、行为特征（如点击率、交互率、停留时间）和上下文特征（如位置、时间等）。</p>
<h3>五、总结</h3>
<p>相关性模型的训练通过预训练、后预训练、微调和蒸馏四个步骤，结合大规模数据和高质量标注数据，显著提升搜索引擎的相关性判断能力。通过合理的训练和优化策略，可以提升用户体验和业务指标。</p>

    <h3>Python 文件</h3>
    <pre><code># 04_3.1.5_知识点小结

"""
Lecture: 3_第三部分_什么决定用户体验？/3.1_相关性
Content: 04_3.1.5_知识点小结
"""

</code></pre>
  </div>
</body>
</html>
  