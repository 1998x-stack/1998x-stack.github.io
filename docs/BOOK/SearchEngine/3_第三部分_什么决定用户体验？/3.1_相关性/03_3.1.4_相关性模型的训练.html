
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>3.1.4 相关性模型的训练</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=STIX+Two+Math&display=swap">
  <link rel="stylesheet" href="../../markdown.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="../../markdown.js"></script>
</head>
<body>
  <div class="container">
    <h1>03_3.1.4_相关性模型的训练</h1>
<pre><code>Lecture: 3_第三部分_什么决定用户体验？/3.1_相关性
Content: 03_3.1.4_相关性模型的训练
</code></pre>
<h2>相关性模型的训练</h2>
<h3>一、简介</h3>
<p>在搜索引擎优化中，相关性模型的训练至关重要。BERT（Bidirectional Encoder Representations from Transformers）模型在自然语言处理（NLP）领域取得了显著的成功，被广泛应用于相关性计算。训练高精度的相关性模型需要经过预训练、后预训练、微调和蒸馏四个步骤。</p>
<h3>二、训练步骤</h3>
<h4>1. 预训练（Pre-training）</h4>
<p>预训练是在大规模语料上进行的，使模型能够掌握丰富的语言知识和上下文理解能力。预训练任务包括：</p>
<ul>
<li><strong>掩码语言模型（Masked Language Model, MLM）</strong>：随机掩码输入文本中的一些词，并让模型预测这些被掩码的词。</li>
<li><strong>下一句预测（Next Sentence Prediction, NSP）</strong>：判断两段文本是否相邻。</li>
</ul>
<h4>2. 后预训练（Post Pre-training）</h4>
<p>后预训练通过挖掘搜索引擎日志，构建大规模的相关性数据集，并进一步训练模型。这一阶段的目标是使模型更加适应搜索相关性任务。</p>
<ul>
<li><strong>数据构建</strong>：从搜索日志中抽取数亿对（q, d）二元组，并计算这些二元组的用户行为统计量（如点击率、交互率等）。</li>
<li><strong>教师模型</strong>：使用小模型（如GBDT）将用户行为统计量映射到相关性分数，并用这些分数来训练大模型。</li>
</ul>
<h4>3. 微调（Fine-tuning）</h4>
<p>微调是在人工标注的数据集上进行的。通过人工标注的数十万、数百万条样本，模型能够学到更高精度的相关性判断。</p>
<ul>
<li><strong>高质量标注</strong>：数据标注需要产品团队、算法团队和标注团队的紧密合作，制定详细的标注规则并进行严格的质量控制。</li>
</ul>
<h4>4. 蒸馏（Distillation）</h4>
<p>蒸馏是通过大模型来指导小模型的训练，使小模型也能获得大模型的高性能。</p>
<ul>
<li><strong>数据量要求</strong>：蒸馏用的数据量应尽可能大，通常需要数亿对（q, d）二元组。</li>
<li><strong>蒸馏策略</strong>：常用的方法是直接用大模型的输出作为小模型的训练目标，通过调整输出层的方式进行蒸馏。</li>
</ul>
<h3>三、模型评价与优化</h3>
<h4>1. 评价指标</h4>
<ul>
<li><strong>AUC（Area Under Curve）</strong>：衡量模型预测的相关性分数与实际标签之间的一致性，数值越高，模型越准确。</li>
<li><strong>正逆序比</strong>：比较文档对的正序与逆序数量，评估模型的排序效果。</li>
</ul>
<h4>2. 损失函数</h4>
<ul>
<li><strong>Pointwise 损失函数</strong>：如均方误差（MSE）和交叉熵，用于“保值”。</li>
<li><strong>Pairwise 损失函数</strong>：用于“保序”，如对比损失函数。</li>
<li><strong>预训练损失函数</strong>：如MLM损失，确保预训练的成果不会在后续训练中被“清洗掉”。</li>
</ul>
<h3>四、实际应用中的挑战与策略</h3>
<h4>1. 数据标注</h4>
<ul>
<li><strong>挑战</strong>：数据标注的质量直接影响模型的性能，标注规则的制定和实施是关键。</li>
<li><strong>策略</strong>：参考行业领先企业的经验，制定详细且可执行的标注规则，确保标注数据的高质量。</li>
</ul>
<h4>2. 模型优化</h4>
<ul>
<li><strong>挑战</strong>：模型的训练和推理成本高，需要平衡计算资源和模型性能。</li>
<li><strong>策略</strong>：通过蒸馏和缓存机制（如Redis）等方式优化模型的计算效率，降低线上推理成本。</li>
</ul>
<h3>五、总结</h3>
<p>训练高精度的相关性模型需要经过预训练、后预训练、微调和蒸馏四个步骤，每一步都至关重要。通过大规模数据集和高质量的标注数据，结合先进的深度学习技术，可以显著提升搜索引擎的相关性判断能力，最终提升用户体验和业务指标。</p>
<hr>
<h3>训练步骤详解</h3>
<h4>1. 预训练（Pre-training）</h4>
<p>预训练是BERT模型训练的第一步，旨在让模型掌握丰富的语言知识和上下文理解能力。主要任务包括掩码语言模型（MLM）和下一句预测（NSP）。</p>
<ul>
<li>
<p><strong>掩码语言模型（MLM）</strong>：随机掩码输入文本中的一些词，让模型预测这些被掩码的词。具体做法是将输入句子中的一部分词随机替换为特殊标记[MASK]，然后让模型根据上下文预测这些被替换的词。例如，输入句子“我爱[MASK]，它非常美味”，模型需要预测出[MASK]应该是“苹果”或“蛋糕”等词 。</p>
</li>
<li>
<p><strong>下一句预测（NSP）</strong>：判断两段文本是否相邻。具体做法是将两段文本拼接在一起，输入模型，模型需要判断这两段文本是否在原始文档中相邻。例如，“我爱吃苹果。[SEP]苹果非常美味。”是正样本，而“我爱吃苹果。[SEP]明天要下雨。”是负样本  。</p>
</li>
</ul>
<p>预训练阶段利用大量无标注的文本数据，通过自监督学习让模型掌握语言结构和语义关系，为后续任务打下基础。</p>
<h4>2. 后预训练（Post Pre-training）</h4>
<p>后预训练通过挖掘搜索引擎日志，构建大规模的相关性数据集，并进一步训练模型，使其更适应搜索相关性任务。</p>
<ul>
<li>
<p><strong>数据构建</strong>：从搜索日志中抽取数亿对（q, d）二元组，并计算这些二元组的用户行为统计量（如点击率、交互率等）。这些统计量作为特征向量，结合文档文本作为模型输入  。</p>
</li>
<li>
<p><strong>教师模型</strong>：使用小模型（如GBDT）将用户行为统计量映射到相关性分数，并用这些分数来训练大模型。具体做法是先用少量人工标注的数据训练教师模型，然后用教师模型生成大规模的训练数据，供BERT模型进一步学习  。</p>
</li>
</ul>
<p>后预训练阶段结合了监督学习和自监督学习的优势，通过大量实际数据增强模型对特定任务的理解和适应能力。</p>
<h4>3. 微调（Fine-tuning）</h4>
<p>微调是在人工标注的数据集上进行的，通过人工标注的数十万、数百万条样本，模型能够学到更高精度的相关性判断。</p>
<ul>
<li><strong>高质量标注</strong>：数据标注需要产品团队、算法团队和标注团队的紧密合作，制定详细的标注规则并进行严格的质量控制。标注规则应参考行业领先企业的经验，以保证标注数据的高质量和一致性 。</li>
</ul>
<p>微调阶段利用高质量的标注数据，进一步优化模型在特定任务上的表现，使其在实际应用中达到最佳效果。</p>
<h4>4. 蒸馏（Distillation）</h4>
<p>蒸馏是通过大模型来指导小模型的训练，使小模型也能获得大模型的高性能。</p>
<ul>
<li>
<p><strong>数据量要求</strong>：蒸馏用的数据量应尽可能大，通常需要数亿对（q, d）二元组。数据量越大，蒸馏效果越好  。</p>
</li>
<li>
<p><strong>蒸馏策略</strong>：用大模型的输出作为小模型的训练目标，通过调整输出层的方式进行蒸馏。常用的方法是直接用大模型的输出作为小模型的训练目标，通过调整输出层的方式进行蒸馏 。</p>
</li>
</ul>
<p>蒸馏阶段通过大模型的知识传递，使小模型在保留高效推理能力的同时，也能具备较高的准确性。</p>
<h3>结论</h3>
<h2>BERT模型的训练步骤包括预训练、后预训练、微调和蒸馏。每个步骤都至关重要，通过结合大规模数据和高质量标注数据，模型能够在搜索相关性任务中达到最佳表现。通过合理的训练和优化策略，可以显著提升搜索引擎的用户体验和业务指标    。</h2>
<h2>模型评价与优化</h2>
<h3>一、评价指标</h3>
<h4>1. AUC（Area Under Curve）</h4>
<p>AUC 是一种 pointwise 指标，用于衡量模型预测的相关性分数与实际标签之间的一致性。具体定义如下：</p>
<ul>
<li><strong>定义</strong>：AUC 是 ROC 曲线下的面积。ROC 曲线表示假阳性率（FPR）和真阳性率（TPR）之间的关系。FPR 是将负样本误判为正样本的比率，而 TPR 是将正样本正确判定的比率。AUC 的值介于 0 和 1 之间，AUC 越大，模型的预测越准确。</li>
<li><strong>优点</strong>：AUC 在处理不平衡数据集时表现良好，能够综合考虑模型的整体表现。</li>
<li><strong>计算</strong>：通过比较所有正负样本对的得分，计算这些对中模型正确排序的比例。</li>
</ul>
<h4>2. 正逆序比（Positive-Negative Ratio, PNR）</h4>
<p>正逆序比是一种 pairwise 指标，用于考察模型对文档的排序与真实标签的排序的一致性。具体定义如下：</p>
<ul>
<li><strong>定义</strong>：给定查询词 q 和 k 篇文档，设 y1, …, yk 为真实相关性档位，p1, …, pk 为模型打分。k 篇文档可以组成 $\binom{k}{2}$ 个文档对，正序对满足 $pi ≥ pj$ 且 $yi ≥ yj$，逆序对满足 $pi &lt; pj$ 且 $yi ≥ yj$。正逆序比定义为正序对与逆序对数量之比。</li>
<li><strong>优点</strong>：正逆序比直接反映了模型排序的效果，适用于排序任务。</li>
<li><strong>计算</strong>：通过比较所有文档对的得分，计算正序对和逆序对的数量。</li>
</ul>
<h3>二、损失函数</h3>
<h4>1. Pointwise 损失函数</h4>
<p>Pointwise 损失函数用于“保值”，即让模型预测的相关性分数接近真实标签，有利于提升 AUC 指标。常用的 Pointwise 损失函数包括均方误差（MSE）和交叉熵（Cross-Entropy）。</p>
<ul>
<li>
<p><strong>均方误差（MSE）</strong>：衡量预测值与真实值之间的差异。公式如下：
$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
其中，$y_i$ 为真实值，$\hat{y}_i$ 为预测值。</p>
</li>
<li>
<p><strong>交叉熵（Cross-Entropy）</strong>：用于衡量分类问题中预测概率分布与真实分布之间的差异。公式如下：
$$
\text{Cross-Entropy} = - \frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i)]
$$
其中，$y_i$ 为真实标签（0 或 1），$\hat{p}_i$ 为预测概率。</p>
</li>
</ul>
<h4>2. Pairwise 损失函数</h4>
<p>Pairwise 损失函数用于“保序”，即让模型预测的相关性顺序接近真实顺序，有利于提升正逆序比。常用的 Pairwise 损失函数包括对比损失（Contrastive Loss）和 pairwise logistic 损失。</p>
<ul>
<li>
<p><strong>对比损失（Contrastive Loss）</strong>：用于衡量成对样本之间的相似性差异。公式如下：
$$
\text{Contrastive Loss} = \frac{1}{2N} \sum_{i=1}^{N} [y_i D_i^2 + (1 - y_i) \max(0, m - D_i)^2]
$$
其中，$y_i$ 为标签（相似为 1，不相似为 0），$D_i$ 为样本对之间的距离，$m$ 为边界。</p>
</li>
<li>
<p><strong>pairwise logistic 损失</strong>：用于排序任务，鼓励正序对得分尽量大，逆序对得分尽量小。公式如下：
$$
\text{Pairwise Logistic Loss} = \frac{1}{N} \sum_{i,j} \log(1 + \exp(-\gamma (p_i - p_j)))
$$
其中，$p_i$ 和 $p_j$ 为样本对的得分，$\gamma$ 为超参数。</p>
</li>
</ul>
<h4>3. 预训练损失函数</h4>
<p>预训练损失函数用于确保预训练的成果在后续训练中不会被“清洗掉”。常用的预训练损失函数包括掩码语言模型（MLM）损失和下一句预测（NSP）损失。</p>
<ul>
<li>
<p><strong>掩码语言模型（MLM）损失</strong>：在预训练阶段，通过掩码部分输入词汇，让模型预测这些词汇，从而学习上下文信息。公式如下：
$$
\text{MLM Loss} = - \frac{1}{N} \sum_{i=1}^{N} \log P(w_i | w_{mask})
$$
其中，$w_i$ 为被掩码的词，$w_{mask}$ 为上下文词汇。</p>
</li>
<li>
<p><strong>下一句预测（NSP）损失</strong>：在预训练阶段，通过预测两段文本是否相邻，让模型学习上下文关系。公式如下：
$$
\text{NSP Loss} = - \frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i)]
$$
其中，$y_i$ 为标签（相邻为 1，不相邻为 0），$\hat{p}_i$ 为预测概率。</p>
</li>
</ul>
<h3>三、总结</h3>
<p>模型的评价与优化是提升搜索引擎相关性的重要环节。通过合理选择评价指标和损失函数，可以更准确地衡量和优化模型的性能。AUC 和正逆序比作为主要的评价指标，能够全面反映模型的预测和排序效果。Pointwise、Pairwise 和预训练损失函数在不同训练阶段各有侧重，共同保证模型的高效学习和优化。</p>
<hr>
<h2>后预训练阶段的数据构建</h2>
<h3>一、简介</h3>
<p>后预训练阶段是增强 BERT 模型在搜索相关性任务中的表现，通过挖掘搜索引擎日志，构建大规模的相关性数据集，并进一步训练模型。这一阶段的目标是使模型更适应搜索相关性任务。</p>
<h3>二、数据构建</h3>
<h4>1. 数据来源</h4>
<p>数据主要来源于搜索引擎的日志数据。搜索引擎日志记录了用户的搜索行为，包括查询词（query）、点击的文档（document）、停留时间（dwell time）、点击率（CTR）、交互率等。</p>
<h4>2. 数据抽取</h4>
<p>从搜索日志中抽取数亿对（q, d）二元组，并计算这些二元组的用户行为统计量（如点击率、交互率等）。这些统计量作为特征向量，结合文档文本作为模型输入。</p>
<ul>
<li><strong>查询词（query）</strong>：用户输入的搜索词。</li>
<li><strong>文档（document）</strong>：用户点击的文档，通常由标题和摘要组成。</li>
<li><strong>点击率（CTR）</strong>：某个查询词下某个文档被点击的次数与该文档展示次数的比值。</li>
<li><strong>交互率</strong>：用户在点击文档后的各种交互行为（如点赞、评论、收藏等）的比率。</li>
</ul>
<h4>3. 数据标注</h4>
<p>利用用户行为数据进行自动标注。通过用户的点击行为和交互行为，可以为（q, d）对打上相关性标签。具体方法如下：</p>
<ul>
<li><strong>点击行为</strong>：假设用户点击的文档是相关的，根据点击率对文档打分。点击次数越多，相关性越高。</li>
<li><strong>交互行为</strong>：假设用户进行交互的文档是高度相关的，根据交互率对文档打分。交互次数越多，相关性越高。</li>
<li><strong>停留时间</strong>：假设用户在文档上的停留时间越长，文档的相关性越高。</li>
</ul>
<h4>4. 数据清洗</h4>
<p>对抽取的数据进行清洗，去除噪声数据和无关数据，保证数据质量。例如：</p>
<ul>
<li><strong>去重</strong>：去除重复的查询词和文档对。</li>
<li><strong>过滤</strong>：过滤掉停留时间过短的点击记录，避免引入噪声。</li>
<li><strong>规范化</strong>：对查询词和文档文本进行分词、去停用词、词干提取等预处理。</li>
</ul>
<h4>5. 特征工程</h4>
<p>对构建的数据集进行特征工程，提取有用的特征向量。常见的特征包括：</p>
<ul>
<li><strong>文本特征</strong>：查询词和文档的 TF-IDF、词向量（Word2Vec、GloVe 等）。</li>
<li><strong>行为特征</strong>：点击率、交互率、停留时间等。</li>
<li><strong>上下文特征</strong>：查询词和文档的上下文关系，如位置、时间等。</li>
</ul>
<h3>三、训练数据生成</h3>
<p>使用小模型（如GBDT）将用户行为统计量映射到相关性分数，并用这些分数来训练大模型。具体步骤如下：</p>
<ul>
<li><strong>小模型训练</strong>：使用少量人工标注的数据训练小模型，让其学会将用户行为映射到相关性分数。</li>
<li><strong>大规模生成</strong>：用训练好的小模型在大规模数据集上生成相关性分数，构建训练数据。</li>
</ul>
<h3>四、总结</h3>
<p>后预训练阶段的数据构建通过挖掘和处理搜索引擎日志数据，生成大规模的相关性数据集，并利用小模型进行自动标注，进一步增强 BERT 模型在搜索相关性任务中的表现。这一阶段结合了监督学习和自监督学习的优势，通过大量实际数据增强模型对特定任务的理解和适应能力。</p>

    <h3>Python 文件</h3>
    <pre><code># 03_3.1.4_相关性模型的训练

"""
Lecture: 3_第三部分_什么决定用户体验？/3.1_相关性
Content: 03_3.1.4_相关性模型的训练
"""

</code></pre>
  </div>
</body>
</html>
  