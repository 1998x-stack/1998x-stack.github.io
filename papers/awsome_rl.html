<!DOCTYPE html>
<html lang="en">

<head>
  <title>Recommendation</title>
  <style>
    body {
      font-family: 'Open Sans', sans-serif;
      color: #333;
      line-height: 1.6;
    }

    h1,
    h2 {
      font-family: 'Lora', serif;
    }

    h1 {
      font-size: 2rem;
      text-align: center;
    }

    h2 {
      font-size: 1.5rem;
      margin: 2rem 0 1rem;
    }

    a {
      color: #0077cc;
      font-weight: bold;
      text-decoration: none;
      padding: 0.2rem 0.5rem;
      border-radius: 4px;
      transition: background 0.2s;
    }

    a:hover {
      background: #0077cc;
      color: #fff;
    }

    ul {
      list-style-type: none;
      padding: 0;
    }

    li {
      margin: 1rem 0;
    }

    @media (min-width: 600px) {
      body {
        max-width: 600px;
        margin: 0 auto;
      }

      h1 {
        text-align: left;
      }
    }
  </style>

<body>

  <section>


    <h1
      id="awesome-reinforcement-learning-awesome-https-cdn-rawgit-com-sindresorhus-awesome-d7305f38d29fed78fa85652e3a63e154dd8e8829-media-badge-svg-https-github-com-sindresorhus-awesome-">
      Awesome Reinforcement Learning <a href="https://github.com/sindresorhus/awesome"><img
          src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg"
          alt="Awesome"></a></h1>
    <p>This page is no longer maintained. </p>
    <p>A curated list of resources dedicated to reinforcement learning.</p>
    <p>We have pages for other topics: <a href="https://github.com/kjw0612/awesome-rnn">awesome-rnn</a>, <a
        href="https://github.com/kjw0612/awesome-deep-vision">awesome-deep-vision</a>, <a
        href="https://github.com/kjw0612/awesome-random-forest">awesome-random-forest</a></p>
    <p>Maintainers: <a href="http://sites.duke.edu/hyunsookim/">Hyunsoo Kim</a>, <a
        href="http://github.com/kjw0612">Jiwon Kim</a></p>
    <h2 id="contributing">Contributing</h2>
    <p>Please feel free to <a href="https://github.com/aikorea/awesome-rl/pulls">pull requests</a></p>
    <h2 id="table-of-contents">Table of Contents</h2>
    <ul>
      <li><a href="#theory">Theory</a>
        <ul>
          <li><a href="#lectures">Lectures</a></li>
          <li><a href="#books">Books</a></li>
          <li><a href="#surveys">Surveys</a></li>
          <li><a href="#papers--thesis">Papers / Thesis</a></li>
        </ul>
      </li>
      <li><a href="#applications">Applications</a>
        <ul>
          <li><a href="#game-playing">Game Playing</a></li>
          <li><a href="#robotics">Robotics</a></li>
          <li><a href="#control">Control</a></li>
          <li><a href="#operations-research">Operations Research</a></li>
          <li><a href="#human-computer-interaction">Human Computer Interaction</a></li>
        </ul>
      </li>
      <li><a href="#codes">Codes</a></li>
      <li><a href="#tutorials--websites">Tutorials / Websites</a></li>
      <li><a href="#online-demos">Online Demos</a></li>
      <li><a href="#open-source-reinforcement-learning-platforms">Open Source Reinforcement Learning Platforms</a></li>
    </ul>
    <h2 id="codes">Codes</h2>
    <ul>
      <li>Codes for examples and exercises in Richard Sutton and Andrew Barto&#39;s Reinforcement Learning: An
        Introduction<ul>
          <li><a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">Python Code</a></li>
          <li><a href="http://waxworksmath.com/Authors/N_Z/Sutton/sutton.html">MATLAB Code (BROKEN LINK)</a></li>
          <li><a href="http://incompleteideas.net/book/code/code2nd.html">C/Lisp Code</a></li>
          <li><a href="https://github.com/Ju-jl/ReinforcementLearningAnIntroduction.jl">Julia Code</a></li>
          <li><a href="http://incompleteideas.net/book/RLbook2018.pdf">Book</a></li>
          <li><a
              href="https://github.com/LyWangPX/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions">Exercise
              Solutions</a></li>
        </ul>
      </li>
      <li>Simulation code for Reinforcement Learning Control Problems<ul>
          <li><a href="http://pages.cs.wisc.edu/~finton/poledriver.html">Pole-Cart Problem</a></li>
          <li><a href="http://pages.cs.wisc.edu/~finton/qcontroller.html">Q-learning Controller</a></li>
        </ul>
      </li>
      <li><a href="http://www.cs.colostate.edu/~anderson/res/rl/matlabpaper/rl.html">MATLAB Environment and GUI for
          Reinforcement Learning</a></li>
      <li><a href="http://www-anw.cs.umass.edu/rlr/">Reinforcement Learning Repository - University of Massachusetts,
          Amherst</a></li>
      <li><a href="http://burlap.cs.brown.edu/">Brown-UMBC Reinforcement Learning and Planning Library (Java)</a></li>
      <li><a
          href="http://www.moneyscience.com/pg/blog/StatAlgo/read/635759/reinforcement-learning-in-r-markov-decision-process-mdp-and-value-iteration">Reinforcement
          Learning in R (MDP, Value Iteration)</a></li>
      <li><a href="https://jamh-web.appspot.com/download.htm">Reinforcement Learning Environment in Python and
          MATLAB</a></li>
      <li><a href="http://glue.rl-community.org/wiki/Main_Page">RL-Glue</a> (standard interface for RL) and <a
          href="http://library.rl-community.org/wiki/Main_Page">RL-Glue Library</a></li>
      <li><a href="http://www.pybrain.org/">PyBrain Library</a> - Python-Based Reinforcement learning, Artificial
        intelligence, and Neural network</li>
      <li><a href="http://rlpy.readthedocs.org/en/latest/">RLPy Framework</a> - Value-Function-Based Reinforcement
        Learning Framework for Education and Research</li>
      <li><a href="http://mmlf.sourceforge.net/">Maja</a> - Machine learning framework for problems in Reinforcement
        Learning in python</li>
      <li><a href="http://servicerobotik.hs-weingarten.de/en/teachingbox.php">TeachingBox</a> - Java based Reinforcement
        Learning framework</li>
      <li><a href="http://www.ias.informatik.tu-darmstadt.de/Research/PolicyGradientToolbox">Policy Gradient
          Reinforcement Learning Toolbox for MATLAB</a></li>
      <li><a href="http://sourceforge.net/projects/piqle/">PIQLE</a> - Platform Implementing Q-Learning and other RL
        algorithms</li>
      <li><a href="https://code.google.com/p/beliefbox/">BeliefBox</a> - Bayesian reinforcement learning library and
        toolkit</li>
      <li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Deep Q-Learning with TensorFlow</a> - A deep Q
        learning demonstration using Google Tensorflow</li>
      <li><a href="https://github.com/Kaixhin/Atari">Atari</a> - Deep Q-networks and asynchronous agents in Torch</li>
      <li><a href="https://github.com/yandexdataschool/AgentNet">AgentNet</a> - A python library for deep reinforcement
        learning and custom recurrent networks using Theano+Lasagne.</li>
      <li><a href="https://github.com/rlcode/reinforcement-learning">Reinforcement Learning Examples by RLCode</a> - A
        Collection of minimal and clean reinforcement learning examples</li>
      <li><a href="https://github.com/openai/baselines">OpenAI Baselines</a> - Well tested implementations (<a
          href="https://github.com/openai/baselines-results">and results</a>) of reinforcement learning algorithms from
        OpenAI </li>
      <li><a href="https://github.com/ShangtongZhang/DeepRL">PyTorch Deep RL</a> - Popular deep RL algorithm
        implementations with PyTorch</li>
      <li><a href="https://github.com/chainer/chainerrl">ChainerRL</a> - Popular deep RL algorithm implementations with
        Chainer</li>
      <li><a href="https://github.com/resibots/blackdrops">Black-DROPS</a> - Modular and generic code for the
        model-based policy search Black-DROPS algorithm (IROS 2017 paper) and easy integration with the <a
          href="http://dartsim.github.io/">DART</a> simulator</li>
      <li><a href="https://github.com/aunum/gold">Gold</a> - A reinforcement learning library for Golang.</li>
      <li><a href="https://github.com/instadeepai/jumanji">Jumanji</a> - A Suite of Industry-Driven Hardware-Accelerated
        RL Environments written in JAX.</li>
    </ul>
    <h2 id="theory">Theory</h2>
    <h3 id="lectures">Lectures</h3>
    <ul>
      <li>[DeepMind x UCL] <a
          href="https://deepmind.com/learning-resources/reinforcement-learning-series-2021">Reinforcement Learning
          Lecture Series 2021</a>
        <ul>
          <li>[UCL] <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">COMPM050/COMPGI13 Reinforcement
              Learning</a> by David Silver</li>
          <li>[UCL] <a
              href="https://github.com/enggen/DeepMind-Advanced-Deep-Learning-and-Reinforcement-Learning">COMPMI22/COMPGI22
              - Advanced Deep Learning and Reinforcement Learning</a></li>
          <li>[UC Berkeley] CS188 Artificial Intelligence by Pieter Abbeel<ul>
              <li><a href="https://www.youtube.com/watch?v=i0o-ui1N35U">Lecture 8: Markov Decision Processes 1</a></li>
              <li><a href="https://www.youtube.com/watch?v=Csiiv6WGzKM">Lecture 9: Markov Decision Processes 2</a></li>
              <li><a href="https://www.youtube.com/watch?v=ifma8G7LegE">Lecture 10: Reinforcement Learning 1</a></li>
              <li><a href="https://www.youtube.com/watch?v=Si1_YTw960c">Lecture 11: Reinforcement Learning 2</a></li>
            </ul>
          </li>
          <li>[Udacity (Georgia Tech.)] <a href="https://classroom.udacity.com/courses/ud600">CS7642 Reinforcement
              Learning</a></li>
          <li>[Stanford] <a href="https://www.youtube.com/watch?v=RtxI449ZjSc&amp;feature=relmfu">CS229 Machine Learning
              - Lecture 16: Reinforcement Learning</a> by Andrew Ng</li>
          <li>[UC Berkeley] <a href="https://sites.google.com/view/deep-rl-bootcamp/lectures">Deep RL Bootcamp</a></li>
          <li>[UC Berkeley] <a href="http://rll.berkeley.edu/deeprlcourse/">CS294 Deep Reinforcement Learning</a> by
            John Schulman and Pieter Abbeel</li>
          <li>[CMU] <a href="https://katefvision.github.io/">10703: Deep Reinforcement Learning and Control, Spring
              2017</a></li>
          <li>[MIT] <a href="http://selfdrivingcars.mit.edu/">6.S094: Deep Learning for Self-Driving Cars</a>
            <ul>
              <li><a
                  href="https://www.youtube.com/watch?v=QDzM8r3WgBw&amp;list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf">Lecture
                  2: Deep Reinforcement Learning for Motion Planning</a></li>
            </ul>
          </li>
          <li>[Siraj Raval]: Introduction to AI for Video Games (Reinforcement Learning Video Series)<ul>
              <li><a href="https://youtu.be/i_McNBDP9Qs">Introduction to AI for video games</a></li>
              <li><a href="https://youtu.be/-YpalutQCKw">Monte Carlo Prediction</a></li>
              <li><a href="https://youtu.be/aCEvtRtNO-M">Q learning explained</a></li>
              <li><a href="https://youtu.be/pN7ETkOizGM">Solving the basic game of Pong</a></li>
              <li><a href="https://youtu.be/w_3mmm0P0j8">Actor Critic Algorithms</a></li>
              <li><a href="https://youtu.be/tm5kQmjfZN8">War Robots</a></li>
            </ul>
          </li>
          <li>[Mutual Information] <a
              href="https://www.youtube.com/playlist?list=PLzvYlJMoZ02Dxtwe-MmH4nOB5jYlMGBjr">Reinforcement Learning
              Fundamentals</a>
            <ul>
              <li><a href="https://youtu.be/NFo9v_yKQXA">Reinforcement Learning: A Six Part Series</a></li>
              <li><a href="https://youtu.be/_j6pvGEchWU">The Bellman Equations, Dynamic Programming, and Generalized
                  Policy Iteration</a></li>
              <li><a href="https://youtu.be/bpUszPiWM7o">Monte Carlo And Off-Policy Methods</a></li>
              <li><a href="https://youtu.be/AJiG3ykOxmY">TD Learning, Sarsa, and Q-Learning</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
    <h3 id="books">Books</h3>
    <ul>
      <li>Richard Sutton and Andrew Barto, Reinforcement Learning: An Introduction (1st Edition, 1998) <a
          href="http://incompleteideas.net/book/ebook/the-book.html">[Book]</a> <a
          href="http://incompleteideas.net/book/code/code.html">[Code]</a></li>
      <li>Richard Sutton and Andrew Barto, Reinforcement Learning: An Introduction (2nd Edition, in progress, 2018) <a
          href="http://incompleteideas.net/book/RLbook2020.pdf">[Book]</a> <a
          href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">[Code]</a></li>
      <li>Csaba Szepesvari, Algorithms for Reinforcement Learning <a
          href="http://www.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf">[Book]</a></li>
      <li>David Poole and Alan Mackworth, Artificial Intelligence: Foundations of Computational Agents <a
          href="http://artint.info/html/ArtInt_262.html">[Book Chapter]</a></li>
      <li>Dimitri P. Bertsekas and John N. Tsitsiklis, Neuro-Dynamic Programming <a
          href="http://www.amazon.com/Neuro-Dynamic-Programming-Optimization-Neural-Computation/dp/1886529108/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1442461075&amp;sr=1-3&amp;refinements=p_27%3AJohn+N.+Tsitsiklis+Dimitri+P.+Bertsekas">[Book
          (Amazon)]</a> <a href="http://www.mit.edu/~dimitrib/NDP_Encycl.pdf">[Summary]</a></li>
      <li>Mykel J. Kochenderfer, Decision Making Under Uncertainty: Theory and Application <a
          href="http://www.amazon.com/Decision-Making-Under-Uncertainty-Application/dp/0262029251/ref=sr_1_1?ie=UTF8&amp;qid=1441126550&amp;sr=8-1&amp;keywords=kochenderfer&amp;pebp=1441126551594&amp;perid=1Y6RG2EGRD26659CJHH9">[Book
          (Amazon)]</a></li>
      <li>Deep Reinforcement Learning in Action <a
          href="https://www.manning.com/books/deep-reinforcement-learning-in-action">[Book(Manning)]</a></li>
      <li>REINFORCEMENT LEARNING AND OPTIMAL CONTROL Dimitri P. Bertsekas <a
          href="http://web.mit.edu/dimitrib/www/RLbook.html">BOOK, VIDEOLECTURES, AND COURSE MATERIAL, 2019</a></li>
    </ul>
    <h3 id="surveys">Surveys</h3>
    <ul>
      <li>Leslie Pack Kaelbling, Michael L. Littman, Andrew W. Moore, Reinforcement Learning: A Survey (JAIR 1996) <a
          href="https://www.jair.org/index.php/jair/article/download/10166/24110/">[Paper]</a></li>
      <li>S. S. Keerthi and B. Ravindran, A Tutorial Survey of Reinforcement Learning (Sadhana 1994) <a
          href="http://www.cse.iitm.ac.in/~ravi/papers/keerthi.rl-survey.pdf">[Paper]</a></li>
      <li>Matthew E. Taylor, Peter Stone, Transfer Learning for Reinforcement Learning Domains: A Survey (JMLR 2009) <a
          href="http://www.jmlr.org/papers/volume10/taylor09a/taylor09a.pdf">[Paper]</a></li>
      <li>Jens Kober, J. Andrew Bagnell, Jan Peters, Reinforcement Learning in Robotics, A Survey (IJRR 2013) <a
          href="http://www.ias.tu-darmstadt.de/uploads/Publications/Kober_IJRR_2013.pdf">[Paper]</a></li>
      <li>Michael L. Littman, Reinforcement learning improves behaviour from evaluative feedback (Nature 2015) <a
          href="http://www.nature.com/nature/journal/v521/n7553/full/nature14540.html">[Paper]</a></li>
      <li>Marc P. Deisenroth, Gerhard Neumann, Jan Peter, A Survey on Policy Search for Robotics, Foundations and Trends
        in Robotics (2014) <a
          href="https://spiral.imperial.ac.uk:8443/bitstream/10044/1/12051/7/fnt_corrected_2014-8-22.pdf">[Book]</a>
      </li>
      <li>Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, Anil Anthony Bharath, A Brief Survey of Deep
        Reinforcement Learning (IEEE Signal Processing Magazine 2017) <a
          href="https://dx.doi.org/10.1109/MSP.2017.2743240">[DOI]</a> <a
          href="https://arxiv.org/pdf/1708.05866.pdf">[Paper]</a></li>
      <li>Benjamin Recht, A Tour of Reinforcement Learning: The View from Continuous Control (Annu. Rev. Control Robot.
        Auton. Syst. 2019) <a href="https://dx.doi.org/10.1146/annurev-control-053018-023825">[DOI]</a></li>
    </ul>
    <h3 id="papers-thesis">Papers / Thesis</h3>
    <p>Foundational Papers</p>
    <ul>
      <li>Marvin Minsky, Steps toward Artificial Intelligence, Proceedings of the IRE, 1961. <a
          href="https://dx.doi.org/10.1109/JRPROC.1961.287775">[DOI]</a> <a
          href="http://staffweb.worc.ac.uk/DrC/Courses%202010-11/Comp%203104/Tutor%20Inputs/Session%209%20Prep/Reading%20material/Minsky60steps.pdf">[Paper]</a>
        (discusses issues in RL such as the &quot;credit assignment problem&quot;)</li>
      <li>Ian H. Witten, An Adaptive Optimal Controller for Discrete-Time Markov Environments, Information and Control,
        1977. <a href="https://doi.org/10.1016/S0019-9958(77">[DOI]</a>90354-0) <a
          href="http://www.cs.waikato.ac.nz/~ihw/papers/77-IHW-AdaptiveController.pdf">[Paper]</a> (earliest publication
        on temporal-difference (TD) learning rule)</li>
    </ul>
    <p>Methods</p>
    <ul>
      <li>Dynamic Programming (DP):<ul>
          <li>Christopher J. C. H. Watkins, Learning from Delayed Rewards, Ph.D. Thesis, Cambridge University, 1989. <a
              href="https://www.cs.rhul.ac.uk/home/chrisw/new_thesis.pdf">[Thesis]</a></li>
        </ul>
      </li>
      <li>Monte Carlo:<ul>
          <li>Andrew Barto, Michael Duff, Monte Carlo Inversion and Reinforcement Learning, NIPS, 1994. <a
              href="http://papers.nips.cc/paper/865-monte-carlo-matrix-inversion-and-reinforcement-learning.pdf">[Paper]</a>
          </li>
          <li>Satinder P. Singh, Richard S. Sutton, Reinforcement Learning with Replacing Eligibility Traces, Machine
            Learning, 1996. <a href="http://www-all.cs.umass.edu/pubs/1995_96/singh_s_ML96.pdf">[Paper]</a></li>
        </ul>
      </li>
      <li>Temporal-Difference:<ul>
          <li>Richard S. Sutton, Learning to predict by the methods of temporal differences. Machine Learning 3: 9-44,
            1988. <a href="http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-88-with-erratum.pdf">[Paper]</a></li>
        </ul>
      </li>
      <li>Q-Learning (Off-policy TD algorithm):<ul>
          <li>Chris Watkins, Learning from Delayed Rewards, Cambridge, 1989. <a
              href="http://www.cs.rhul.ac.uk/home/chrisw/thesis.html">[Thesis]</a></li>
        </ul>
      </li>
      <li>Sarsa (On-policy TD algorithm):<ul>
          <li>G.A. Rummery, M. Niranjan, On-line Q-learning using connectionist systems, Technical Report, Cambridge
            Univ., 1994. <a
              href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;ved=0CDIQFjACahUKEwj2lMm5wZDIAhUHkg0KHa6kAVM&amp;url=ftp%3A%2F%2Fmi.eng.cam.ac.uk%2Fpub%2Freports%2Fauto-pdf%2Frummery_tr166.pdf&amp;usg=AFQjCNHz6IrgcaaO5lzC7t8oEIBY9epozg&amp;sig2=sa-emPme1m5Jav7YmaXsNQ&amp;cad=rja">[Report]</a>
          </li>
          <li>Richard S. Sutton, Generalization in Reinforcement Learning: Successful examples using sparse coding,
            NIPS, 1996. <a href="http://webdocs.cs.ualberta.ca/~sutton/papers/sutton-96.pdf">[Paper]</a></li>
        </ul>
      </li>
      <li>R-Learning (learning of relative values)<ul>
          <li>Andrew Schwartz, A Reinforcement Learning Method for Maximizing Undiscounted Rewards, ICML, 1993. <a
              href="https://scholar.google.com/scholar?q=reinforcement+learning+method+for+maximizing+undiscounted+rewards&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart&amp;sa=X&amp;ved=0CBsQgQMwAGoVChMIho6p_MOQyAIVwh0eCh3XWAwM">[Paper-Google
              Scholar]</a></li>
        </ul>
      </li>
      <li>Function Approximation methods (Least-Square Temporal Difference, Least-Square Policy Iteration)<ul>
          <li>Steven J. Bradtke, Andrew G. Barto, Linear Least-Squares Algorithms for Temporal Difference Learning,
            Machine Learning, 1996. <a href="http://www-anw.cs.umass.edu/pubs/1995_96/bradtke_b_ML96.pdf">[Paper]</a>
          </li>
          <li>Michail G. Lagoudakis, Ronald Parr, Model-Free Least Squares Policy Iteration, NIPS, 2001. <a
              href="http://www.cs.duke.edu/research/AI/LSPI/nips01.pdf">[Paper]</a> <a
              href="http://www.cs.duke.edu/research/AI/LSPI/">[Code]</a></li>
        </ul>
      </li>
      <li>Policy Search / Policy Gradient<ul>
          <li>Richard Sutton, David McAllester, Satinder Singh, Yishay Mansour, Policy Gradient Methods for
            Reinforcement Learning with Function Approximation, NIPS, 1999. <a
              href="http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf">[Paper]</a>
          </li>
          <li>Jan Peters, Sethu Vijayakumar, Stefan Schaal, Natural Actor-Critic, ECML, 2005. <a
              href="https://homes.cs.washington.edu/~todorov/courses/amath579/reading/NaturalActorCritic.pdf">[Paper]</a>
          </li>
          <li>Jens Kober, Jan Peters, Policy Search for Motor Primitives in Robotics, NIPS, 2009. <a
              href="http://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics.pdf">[Paper]</a>
          </li>
          <li>Jan Peters, Katharina Mulling, Yasemin Altun, Relative Entropy Policy Search, AAAI, 2010. <a
              href="http://www.kyb.tue.mpg.de/fileadmin/user_upload/files/publications/attachments/AAAI-2010-Peters_6439%5b0%5d.pdf">[Paper]</a>
          </li>
          <li>Freek Stulp, Olivier Sigaud, Path Integral Policy Improvement with Covariance Matrix Adaptation, ICML,
            2012. <a href="http://arxiv.org/pdf/1206.4621v1.pdf">[Paper]</a></li>
          <li>Nate Kohl, Peter Stone, Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion, ICRA,
            2004. <a href="http://www.cs.utexas.edu/~pstone/Papers/bib2html-links/icra04.pdf">[Paper]</a></li>
          <li>Marc Deisenroth, Carl Rasmussen, PILCO: A Model-Based and Data-Efficient Approach to Policy Search, ICML,
            2011. <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf">[Paper]</a></li>
          <li>Scott Kuindersma, Roderic Grupen, Andrew Barto, Learning Dynamic Arm Motions for Postural Recovery,
            Humanoids, 2011. <a href="http://www-all.cs.umass.edu/pubs/2011/kuindersma_g_b_11.pdf">[Paper]</a></li>
          <li>Konstantinos Chatzilygeroudis, Roberto Rama, Rituraj Kaushik, Dorian Goepp, Vassilis Vassiliades,
            Jean-Baptiste Mouret, Black-Box Data-efficient Policy Search for Robotics, IROS, 2017. [<a
              href="https://arxiv.org/pdf/1703.07261.pdf">Paper</a>]</li>
        </ul>
      </li>
      <li>Hierarchical RL<ul>
          <li>Richard Sutton, Doina Precup, Satinder Singh, Between MDPs and Semi-MDPs: A Framework for Temporal
            Abstraction in Reinforcement Learning, Artificial Intelligence, 1999. <a
              href="https://webdocs.cs.ualberta.ca/~sutton/papers/SPS-aij.pdf">[Paper]</a></li>
          <li>George Konidaris, Andrew Barto, Building Portable Options: Skill Transfer in Reinforcement Learning,
            IJCAI, 2007. <a href="http://www-anw.cs.umass.edu/pubs/2007/konidaris_b_IJCAI07.pdf">[Paper]</a></li>
        </ul>
      </li>
      <li>Deep Learning + Reinforcement Learning (A sample of recent works on DL+RL)<ul>
          <li>V. Mnih, et. al., Human-level Control through Deep Reinforcement Learning, Nature, 2015. <a
              href="http://www.readcube.com/articles/10.1038%2Fnature14236?shared_access_token=Lo_2hFdW4MuqEcF3CVBZm9RgN0jAjWel9jnR3ZoTv0P5kedCCNjz3FJ2FhQCgXkApOr3ZSsJAldp-tw3IWgTseRnLpAc9xQq-vTA2Z5Ji9lg16_WvCy4SaOgpK5XXA6ecqo8d8J7l4EJsdjwai53GqKt-7JuioG0r3iV67MQIro74l6IxvmcVNKBgOwiMGi8U0izJStLpmQp6Vmi_8Lw_A%3D%3D">[Paper]</a>
          </li>
          <li>Xiaoxiao Guo, Satinder Singh, Honglak Lee, Richard Lewis, Xiaoshi Wang, Deep Learning for Real-Time Atari
            Game Play Using Offline Monte-Carlo Tree Search Planning, NIPS, 2014. <a
              href="http://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf">[Paper]</a>
          </li>
          <li>Sergey Levine, Chelsea Finn, Trevor Darrel, Pieter Abbeel, End-to-End Training of Deep Visuomotor
            Policies. ArXiv, 16 Oct 2015. <a href="http://arxiv.org/pdf/1504.00702v3.pdf">[ArXiv]</a></li>
          <li>Tom Schaul, John Quan, Ioannis Antonoglou, David Silver, Prioritized Experience Replay, ArXiv, 18 Nov
            2015. <a href="http://arxiv.org/pdf/1511.05952v2.pdf">[ArXiv]</a></li>
          <li>Hado van Hasselt, Arthur Guez, David Silver, Deep Reinforcement Learning with Double Q-Learning, ArXiv, 22
            Sep 2015. <a href="http://arxiv.org/abs/1509.06461">[ArXiv]</a></li>
          <li>Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley,
            David Silver, Koray Kavukcuoglu, Asynchronous Methods for Deep Reinforcement Learning, ArXiv, 4 Feb 2016. <a
              href="https://arxiv.org/pdf/1602.01783.pdf">[ArXiv]</a></li>
        </ul>
      </li>
    </ul>
    <h2 id="applications">Applications</h2>
    <h3 id="game-playing">Game Playing</h3>
    <p>Traditional Games</p>
    <ul>
      <li>Backgammon - Gerald Tesauro, &quot;TD-Gammon&quot; game play using TD(λ) (ACM 1995) <a
          href="http://www.bkgm.com/articles/tesauro/tdl.html">[Paper]</a></li>
      <li>Chess - Jonathan Baxter, Andrew Tridgell and Lex Weaver, &quot;KnightCap&quot; program using TD(λ) (1999) <a
          href="http://arxiv.org/pdf/cs/9901002v1.pdf">[arXiv]</a></li>
      <li>Chess - Matthew Lai, Giraffe: Using deep reinforcement learning to play chess (2015) <a
          href="http://arxiv.org/pdf/1509.01549v2.pdf">[arXiv]</a></li>
    </ul>
    <p>Computer Games</p>
    <ul>
      <li>Atari 2600 Games - Volodymyr Mnih, Koray Kavukcuoglu, David Silver et al., Human-level Control through Deep
        Reinforcement Learning (Nature 2015) <a href="https://dx.doi.org/doi:10.1038/nature14236">[DOI]</a> <a
          href="http://www.readcube.com/articles/10.1038%2Fnature14236?shared_access_token=Lo_2hFdW4MuqEcF3CVBZm9RgN0jAjWel9jnR3ZoTv0P5kedCCNjz3FJ2FhQCgXkApOr3ZSsJAldp-tw3IWgTseRnLpAc9xQq-vTA2Z5Ji9lg16_WvCy4SaOgpK5XXA6ecqo8d8J7l4EJsdjwai53GqKt-7JuioG0r3iV67MQIro74l6IxvmcVNKBgOwiMGi8U0izJStLpmQp6Vmi_8Lw_A%3D%3D">[Paper]</a>
        <a href="https://sites.google.com/a/deepmind.com/dqn/">[Code]</a> <a
          href="https://www.youtube.com/watch?v=iqXKQf2BOSE">[Video]</a></li>
      <li>Flappy Bird - Sarvagya Vaish, <a href="https://github.com/SarvagyaVaish/FlappyBirdRL">Flappy Bird
          Reinforcement Learning</a> <a href="https://www.youtube.com/watch?v=xM62SpKAZHU">[Video]</a></li>
      <li>Mario - Kenneth O. Stanley and Risto Miikkulainen, MarI/O - learning to play Mario with evolutionary
        reinforcement learning using artificial neural networks (Evolutionary Computation 2002) <a
          href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=qv6UVOQ0F44">[Video]</a></li>
      <li>StarCraft II - Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki et al., Grandmaster level in StarCraft II
        using multi-agent reinforcement learning (Nature 2019) <a
          href="https://doi.org/10.1038/s41586-019-1724-z">[DOI]</a> <a
          href="https://www.nature.com/articles/s41586-019-1724-z.epdf">[Paper]</a> <a
          href="https://deepmind.com/research/open-source/alphastar-resources">[Video]</a></li>
    </ul>
    <h3 id="robotics">Robotics</h3>
    <ul>
      <li>Nate Kohl and Peter Stone, Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion (ICRA 2004)
        <a href="http://www.cs.utexas.edu/~pstone/Papers/bib2html-links/icra04.pdf">[Paper]</a></li>
      <li>Petar Kormushev, Sylvain Calinon and Darwin G. Caldwel, Robot Motor SKill Coordination with EM-based
        Reinforcement Learning (IROS 2010) <a href="http://kormushev.com/papers/Kormushev-IROS2010.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=W_gxLKSsSIE">[Video]</a></li>
      <li>Todd Hester, Michael Quinlan, and Peter Stone, Generalized Model Learning for Reinforcement Learning on a
        Humanoid Robot (ICRA 2010) <a href="https://ccc.inaoep.mx/~mdprl/documentos/Hester_2010.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=mRpX9DFCdwI&amp;list=PL5nBAYUyJTrM48dViibyi68urttMlUv7e&amp;index=12">[Video]</a>
      </li>
      <li>George Konidaris, Scott Kuindersma, Roderic Grupen and Andrew Barto, Autonomous Skill Acquisition on a Mobile
        Manipulator (AAAI 2011) <a href="http://lis.csail.mit.edu/pubs/konidaris-aaai11b.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=yUICAkSQTZY">[Video]</a></li>
      <li>Marc Peter Deisenroth and Carl Edward Rasmussen,PILCO: A Model-Based and Data-Efficient Approach to Policy
        Search (ICML 2011) <a href="http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf">[Paper]</a></li>
      <li>Scott Niekum, Sachin Chitta, Bhaskara Marthi, et al., Incremental Semantically Grounded Learning from
        Demonstration (RSS 2013) <a
          href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.310.87&amp;rep=rep1&amp;type=pdf">[Paper]</a>
      </li>
      <li>Mark Cutler and Jonathan P. How, Efficient Reinforcement Learning for Robots using Informative Simulated
        Priors (ICRA 2015) <a href="http://markjcutler.com/papers/Cutler15_ICRA.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=kKClFx6l1HY">[Video]</a></li>
      <li>Antoine Cully, Jeff Clune, Danesh Tarapore and Jean-Baptiste Mouret, Robots that can adapt like animals
        (Nature 2015) [<a href="https://arxiv.org/pdf/1407.3501.pdf">ArXiv</a>] [<a
          href="https://www.youtube.com/watch?v=T-c17RKh3uE">Video</a>] [<a
          href="https://github.com/resibots/cully_2015_nature">Code</a>]</li>
      <li>Konstantinos Chatzilygeroudis, Roberto Rama, Rituraj Kaushik et al, Black-Box Data-efficient Policy Search for
        Robotics (IROS 2017) [<a href="https://arxiv.org/pdf/1703.07261.pdf">ArXiv</a>] [<a
          href="https://www.youtube.com/watch?v=kTEyYiIFGPM">Video</a>] [<a
          href="https://github.com/resibots/blackdrops">Code</a>]</li>
      <li>P. Travis Jardine, Michael Kogan, Sidney N. Givigi and Shahram Yousefi, Adaptive predictive control of a
        differential drive robot tuned with reinforcement learning (Int J Adapt Control Signal Process 2019) <a
          href="https://dx.doi.org/10.1002/acs.2882">[DOI]</a></li>
    </ul>
    <h3 id="control">Control</h3>
    <ul>
      <li>Pieter Abbeel, Adam Coates, et al., An Application of Reinforcement Learning to Aerobatic Helicopter Flight
        (NIPS 2006) <a href="http://heli.stanford.edu/papers/nips06-aerobatichelicopter.pdf">[Paper]</a> <a
          href="https://www.youtube.com/watch?v=VCdxqn0fcnE">[Video]</a></li>
      <li>J. Andrew Bagnell and Jeff G. Schneider, Autonomous helicopter control using Reinforcement Learning Policy
        Search Methods (ICRA 2001) <a
          href="https://kilthub.cmu.edu/articles/Autonomous_Helicopter_Control_Using_Reinforcement_Learning_Policy_Search_Methods/6552119/files/12033380.pdf">[Paper]</a>
      </li>
    </ul>
    <h3 id="operations-research">Operations Research</h3>
    <ul>
      <li>Scott Proper and Prasad Tadepalli, Scaling Average-reward Reinforcement Learning for Product Delivery (AAAI
        2004) <a
          href="https://s3.amazonaws.com/academia.edu.documents/44453946/Scaling_Average-reward_Reinforcement_Lea20160405-20758-1wxkm8y.pdf">[Paper]</a>
      </li>
      <li>Naoki Abe, Naval Verma et al., Cross Channel Optimized Marketing by Reinforcement Learning (KDD 2004) <a
          href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.375.151&amp;rep=rep1&amp;type=pdf">[Paper]</a>
      </li>
      <li>Bernd Waschneck, Andre Reichstaller, Lenz Belzner et al., Deep reinforcement learning for semiconductor
        production scheduling (ASMC 2018) <a href="https://dx.doi.org/10.1109/ASMC.2018.8373191">[DOI]</a> <a
          href="https://www.researchgate.net/profile/Lenz_Belzner/publication/325713164_Deep_reinforcement_learning_for_semiconductor_production_scheduling/links/5be537caa6fdcc3a8dc89fb3/Deep-reinforcement-learning-for-semiconductor-production-scheduling.pdf">[Paper]</a>
      </li>
    </ul>
    <h3 id="human-computer-interaction">Human Computer Interaction</h3>
    <ul>
      <li>Satinder Singh, Diane Litman et al., Optimizing Dialogue Management with Reinforcement Learning: Experiments
        with the NJFun System (JAIR 2002) <a href="http://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf">[Paper]</a>
      </li>
    </ul>
    <h2 id="codes">Codes</h2>
    <ul>
      <li>Codes for examples and exercises in Richard Sutton and Andrew Barto&#39;s <a href="#books">Book</a>
        Reinforcement Learning: An Introduction<ul>
          <li><a href="https://github.com/ShangtongZhang/reinforcement-learning-an-introduction">Python Code</a> (2nd
            Edition)</li>
          <li><a href="https://waxworksmath.com/Authors/N_Z/Sutton/RLAI_1st_Edition/sutton.html">MATLAB Code</a> (1st
            Edition)</li>
        </ul>
      </li>
      <li>Simulation code for Reinforcement Learning Control Problems<ul>
          <li><a href="http://pages.cs.wisc.edu/~finton/poledriver.html">Pole-Cart Problem</a></li>
          <li><a href="http://pages.cs.wisc.edu/~finton/qcontroller.html">Q-learning Controller</a></li>
        </ul>
      </li>
      <li><a href="http://www.cs.colostate.edu/~anderson/res/rl/matlabpaper/rl.html">MATLAB Environment and GUI for
          Reinforcement Learning</a></li>
      <li><a href="http://www-anw.cs.umass.edu/rlr/">Reinforcement Learning Repository - University of Massachusetts,
          Amherst</a></li>
      <li><a href="http://burlap.cs.brown.edu/">Brown-UMBC Reinforcement Learning and Planning Library (Java)</a></li>
      <li><a
          href="http://www.moneyscience.com/pg/blog/StatAlgo/read/635759/reinforcement-learning-in-r-markov-decision-process-mdp-and-value-iteration">Reinforcement
          Learning in R (MDP, Value Iteration)</a></li>
      <li><a href="https://jamh-web.appspot.com/download.htm">Reinforcement Learning Environment in Python and
          MATLAB</a></li>
      <li><a href="http://glue.rl-community.org/wiki/Main_Page">RL-Glue</a> (standard interface for RL) and <a
          href="http://library.rl-community.org/wiki/Main_Page">RL-Glue Library</a></li>
      <li><a href="http://www.pybrain.org/">PyBrain Library</a> - Python-Based Reinforcement learning, Artificial
        intelligence, and Neural network</li>
      <li><a href="http://rlpy.readthedocs.org/en/latest/">RLPy Framework</a> - Value-Function-Based Reinforcement
        Learning Framework for Education and Research</li>
      <li><a href="http://mmlf.sourceforge.net/">Maja</a> - Machine learning framework for problems in Reinforcement
        Learning in python</li>
      <li><a href="http://servicerobotik.hs-weingarten.de/en/teachingbox.php">TeachingBox</a> - Java based Reinforcement
        Learning framework</li>
      <li><a href="http://www.ias.informatik.tu-darmstadt.de/Research/PolicyGradientToolbox">Policy Gradient
          Reinforcement Learning Toolbox for MATLAB</a></li>
      <li><a href="http://sourceforge.net/projects/piqle/">PIQLE</a> - Platform Implementing Q-Learning and other RL
        algorithms</li>
      <li><a href="https://code.google.com/p/beliefbox/">BeliefBox</a> - Bayesian reinforcement learning library and
        toolkit</li>
      <li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Deep Q-Learning with TensorFlow</a> - A deep Q
        learning demonstration using Google Tensorflow</li>
      <li><a href="https://github.com/Kaixhin/Atari">Atari</a> - Deep Q-networks and asynchronous agents in Torch</li>
      <li><a href="https://github.com/yandexdataschool/AgentNet">AgentNet</a> - A python library for deep reinforcement
        learning and custom recurrent networks using Theano+Lasagne.</li>
      <li><a href="https://github.com/rlcode/reinforcement-learning">Reinforcement Learning Examples by RLCode</a> - A
        Collection of minimal and clean reinforcement learning examples</li>
      <li><a href="https://github.com/openai/baselines">OpenAI Baselines</a> - Well tested implementations (<a
          href="https://github.com/openai/baselines-results">and results</a>) of reinforcement learning algorithms from
        OpenAI </li>
      <li><a href="https://github.com/ShangtongZhang/DeepRL">PyTorch Deep RL</a> - Popular deep RL algorithm
        implementations with PyTorch</li>
      <li><a href="https://github.com/chainer/chainerrl">ChainerRL</a> - Popular deep RL algorithm implementations with
        Chainer</li>
      <li><a href="https://github.com/resibots/blackdrops">Black-DROPS</a> - Modular and generic code for the
        model-based policy search Black-DROPS algorithm (IROS 2017 paper) and easy integration with the <a
          href="http://dartsim.github.io/">DART</a> simulator</li>
      <li><a href="https://github.com/instadeepai/jumanji">Jumanji</a> - A Suite of Industry-Driven Hardware-Accelerated
        RL Environments written in JAX.</li>
    </ul>
    <h2 id="tutorials-websites">Tutorials / Websites</h2>
    <ul>
      <li>Mance Harmon and Stephanie Harmon, <a
          href="http://old.nbu.bg/cogs/events/2000/Readings/Petrov/rltutorial.pdf">Reinforcement Learning: A
          Tutorial</a></li>
      <li>C. Igel, M.A. Riedmiller, et al., Reinforcement Learning in a Nutshell, ESANN, 2007. <a
          href="http://image.diku.dk/igel/paper/RLiaN.pdf">[Paper]</a></li>
      <li>UNSW - <a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html">Reinforcement Learning</a>
        <ul>
          <li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/introduction.html">Introduction</a></li>
          <li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/tdlearning.html">TD-Learning</a></li>
          <li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/algorithms.html">Q-Learning and SARSA</a></li>
          <li><a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/applet.html">Applet for &quot;Cat and Mouse&quot;
              Game</a></li>
        </ul>
      </li>
      <li><a href="http://wiki.ros.org/reinforcement_learning/Tutorials/Reinforcement%20Learning%20Tutorial">ROS
          Reinforcement Learning Tutorial</a></li>
      <li><a href="http://cs.brown.edu/research/ai/pomdp/tutorial/index.html">POMDP for Dummies</a></li>
      <li>Scholarpedia articles on:<ul>
          <li><a href="http://www.scholarpedia.org/article/Reinforcement_learning">Reinforcement Learning</a></li>
          <li><a href="http://www.scholarpedia.org/article/Temporal_difference_learning">Temporal Difference
              Learning</a></li>
        </ul>
      </li>
      <li>Repository with useful <a href="http://busoniu.net/repository.php">MATLAB Software, presentations, and demo
          videos</a></li>
      <li><a href="http://liinwww.ira.uka.de/bibliography/Neural/reinforcement.learning.html">Bibliography on
          Reinforcement Learning</a></li>
      <li>UC Berkeley - CS 294: Deep Reinforcement Learning, Fall 2015 (John Schulman, Pieter Abbeel) <a
          href="http://rll.berkeley.edu/deeprlcourse/">[Class Website]</a></li>
      <li><a href="https://studywolf.wordpress.com/2012/11/25/reinforcement-learning-q-learning-and-exploration/">Blog
          posts on Reinforcement Learning, Parts 1-4</a> by Travis DeWolf</li>
      <li><a href="http://www.arcadelearningenvironment.org/">The Arcade Learning Environment</a> - Atari 2600 games
        environment for developing AI agents</li>
      <li><a href="http://karpathy.github.io/2016/05/31/rl/">Deep Reinforcement Learning: Pong from Pixels</a> by Andrej
        Karpathy</li>
      <li><a href="https://www.nervanasys.com/demystifying-deep-reinforcement-learning/">Demystifying Deep Reinforcement
          Learning</a> </li>
      <li><a href="https://jaromiru.com/2016/09/27/lets-make-a-dqn-theory/">Let’s make a DQN</a> </li>
      <li><a
          href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.78km20i8r">Simple
          Reinforcement Learning with Tensorflow, Parts 0-8</a> by Arthur Juliani</li>
      <li><a href="https://github.com/yandexdataschool/Practical_RL">Practical_RL</a> - github-based course in
        reinforcement learning in the wild (lectures, coding labs, projects)</li>
      <li><a href="https://rlenv.directory/">RLenv.directory: Explore and find new reinforcement learning
          environments.</a></li>
      <li>Katja Hofmann&#39;s talk at NeurIPS &#39;19 - <a
          href="https://slideslive.com/38922817/reinforcement-learning-past-present-and-future-perspectives">RL: Past,
          Present and Future Perspectives</a></li>
      <li><a
          href="https://neptune.ai/blog/how-to-structure-organize-track-and-manage-reinforcement-learning-rl-projects">How
          to Structure, Organize, Track and Manage Reinforcement Learning (RL) Projects</a></li>
      <li><a href="https://alxthm.com/assets/pdf/rl-cheatsheet.pdf">Reinforcement Learning Cheat Sheet</a> - A summary
        of some important concepts and algorithms in RL</li>
    </ul>
    <h2 id="online-demos">Online Demos</h2>
    <ul>
      <li><a href="http://www.dcsc.tudelft.nl/~robotics/media.html">Real-world demonstrations of Reinforcement
          Learning</a></li>
      <li><a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html">Deep Q-Learning Demo</a> - A deep
        Q learning demonstration using ConvNetJS</li>
      <li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Deep Q-Learning with Tensor Flow</a> - A deep Q
        learning demonstration using Google Tensorflow</li>
      <li><a href="http://cs.stanford.edu/people/karpathy/reinforcejs/">Reinforcement Learning Demo</a> - A
        reinforcement learning demo using reinforcejs by Andrej Karpathy</li>
    </ul>
    <h2 id="open-source-reinforcement-learning-platforms">Open Source Reinforcement Learning Platforms</h2>
    <ul>
      <li><a href="https://github.com/openai/gym">OpenAI gym</a> - A toolkit for developing and comparing reinforcement
        learning algorithms</li>
      <li><a href="https://github.com/openai/universe">OpenAI universe</a> - A software platform for measuring and
        training an AI&#39;s general intelligence across the world&#39;s supply of games, websites and other
        applications</li>
      <li><a href="https://github.com/deepmind/lab">DeepMind Lab</a> - A customisable 3D platform for agent-based AI
        research</li>
      <li><a href="https://github.com/Microsoft/malmo">Project Malmo</a> - A platform for Artificial Intelligence
        experimentation and research built on top of Minecraft by Microsoft</li>
      <li><a href="https://github.com/Marqt/ViZDoom">ViZDoom</a> - Doom-based AI research platform for reinforcement
        learning from raw visual information</li>
      <li><a href="https://github.com/nadavbh12/Retro-Learning-Environment">Retro Learning Environment</a> - An AI
        platform for reinforcement learning based on video game emulators. Currently supports SNES and Sega Genesis.
        Compatible with OpenAI gym.</li>
      <li><a href="https://github.com/twitter/torch-twrl">torch-twrl</a> - A package that enables reinforcement learning
        in Torch by Twitter</li>
      <li><a href="https://github.com/facebook/UETorch">UETorch</a> - A Torch plugin for Unreal Engine 4 by Facebook
      </li>
      <li><a href="https://github.com/TorchCraft/TorchCraft">TorchCraft</a> - Connecting Torch to StarCraft</li>
      <li><a href="https://github.com/rlworkgroup/garage">garage</a> - A framework for reproducible reinformcement
        learning research, fully compatible with OpenAI Gym and DeepMind Control Suite (successor to rllab)</li>
      <li><a href="https://github.com/reinforceio/tensorforce">TensorForce</a> - Practical deep reinforcement learning
        on TensorFlow with Gitter support and OpenAI Gym/Universe/DeepMind Lab integration.</li>
      <li><a href="https://github.com/deepmind/trfl/">tf-TRFL</a> - A library built on top of TensorFlow that exposes
        several useful building blocks for implementing Reinforcement Learning agents.</li>
      <li><a href="https://github.com/kengz/openai_lab">OpenAI lab</a> - An experimentation system for Reinforcement
        Learning using OpenAI Gym, Tensorflow, and Keras.</li>
      <li><a href="https://github.com/matthiasplappert/keras-rl">keras-rl</a> - State-of-the art deep reinforcement
        learning algorithms in Keras designed for compatibility with OpenAI.</li>
      <li><a href="http://burlap.cs.brown.edu">BURLAP</a> - Brown-UMBC Reinforcement Learning and Planning, a library
        written in Java</li>
      <li><a href="https://github.com/geek-ai/MAgent">MAgent</a> - A Platform for Many-agent Reinforcement Learning.
      </li>
      <li><a href="http://ray.readthedocs.io/en/latest/rllib.html">Ray RLlib</a> - Ray RLlib is a reinforcement learning
        library that aims to provide both performance and composability.</li>
      <li><a href="https://github.com/kengz/SLM-Lab">SLM Lab</a> - A research framework for Deep Reinforcement Learning
        using Unity, OpenAI Gym, PyTorch, Tensorflow.</li>
      <li><a href="https://github.com/Unity-Technologies/ml-agents">Unity ML Agents</a> - Create reinforcement learning
        environments using the Unity Editor</li>
      <li><a href="https://github.com/NervanaSystems/coach">Intel Coach</a> - Coach is a python reinforcement learning
        research framework containing implementation of many state-of-the-art algorithms.</li>
      <li><a href="https://microsoft.github.io/AirSim/reinforcement_learning/">Microsoft AirSim</a> - Open source
        simulator based on Unreal Engine for autonomous vehicles from Microsoft AI &amp; Research.</li>
      <li><a href="https://github.com/opendilab/DI-engine">DI-engine</a> - DI-engine is a generalized Decision
        Intelligence engine. It supports most basic deep reinforcement learning (DRL) algorithms, such as DQN, PPO, SAC,
        and domain-specific algorithms like QMIX in multi-agent RL, GAIL in inverse RL, and RND in exploration problems.
      </li>
      <li><a href="https://github.com/instadeepai/jumanji">Jumanji</a> - A Suite of Industry-Driven Hardware-Accelerated
        RL Environments written in JAX.</li>
    </ul>
    <h2 id="valuable-contributors-">valuable Contributors👩‍💻👨‍💻 :</h2>
    <p align="center"><a href="https://github.com/aikorea/awesome-rl">
        <img src="https://contributors-img.web.app/image?repo=aikorea/awesome-rl" />
      </a></p>








    <h1 id="awesome-rl-papers">awesome-rl-papers</h1>
    <ul>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#Block-MDP">Block MDP</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#Lifelong-Learning-Continual-Learning">Lifelong Learning,
          Continual Learning</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#Generalization">Generalization</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#abstraction-logical">Abstraction, Logical</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#symbolic">Symbolic</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#auto-rl">Auto RL</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#evolutionary-rl">Evolutionary RL</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#graph">Graph</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#auxiliary-task-representation-learning">Auxiliary task,
          Representation learning</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#tutorials">Tutorials</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#misc">Misc</a></li>
      <li><a href="https://github.com/dyabel/awesome-rl-arxivs#resources">Resources</a>
        <h2 id="block-mdp">Block MDP</h2>
      </li>
      <li>Provable RL with Exogenous Distractors via Multistep Inverse Dynamics (ICLR2022 oral) <a
          href="https://arxiv.org/pdf/2110.08847.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Provably efficient RL with Rich Observations via Latent State Decoding (ICML2019) <a
          href="https://arxiv.org/pdf/1901.09018.pdf">arxiv</a> <a
          href="https://github.com/Microsoft/StateDecoding">code</a></li>
      <li>Provable Rich Observation Reinforcement Learning with Combinatorial Latent States (ICLR2021) <a
          href="https://openreview.net/forum?id=hx1IXFHAw7R">arxiv</a> <a href="">[no code]</a></li>
      <li>Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning (ICML2020) <a
          href="https://arxiv.org/pdf/1911.05815.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Efficient Reinforcement Learning in Block MDPs: A Model-free Representation Learning Approach (arxiv) <a
          href="https://arxiv.org/pdf/2202.00063.pdf">arxiv</a> <a href="https://github.com/yudasong/briee">code</a>
      </li>
      <li>Exploiting Action Impact Regularity and Exogenous State Variables for Offline
        Reinforcement Learning <a href="https://arxiv.org/pdf/2111.08066.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>On Reinforcement Learning with Adversarial Corruption and Its Application to Block MDP <a
          href="http://proceedings.mlr.press/v139/wu21g.html">arxiv</a></li>
      <li>Block Contextual MDPs for Continual Learning (ICLR2022 withdraw) <a
          href="https://openreview.net/forum?id=ys-bh0Eer_">openreview</a></li>
      <li>Learning Domain Invariant Representations in Goal-conditioned Block MDPs <a
          href="https://arxiv.org/pdf/2110.14248.pdf?msclkid=243ef4f5ae9f11ec9324a68f4b48c4f0">arxiv</a> <a
          href="https://github.com/facebookresearch/icp-block-mdp">code</a></li>
      <li>On Reinforcement Learning with Adversarial Corruption and Its Application to Block MDP (ICML2021) <a
          href="http://proceedings.mlr.press/v139/wu21g/wu21g.pdf">pdf</a>
        <h2 id="lifelong-learning-continual-learning">Lifelong Learning, Continual Learning</h2>
      </li>
      <li>Modular Lifelong Reinforcement Learning via Neural Composition (ICLR2022) <a
          href="https://openreview.net/forum?id=5XmLzdslFNN">arxiv</a> <a href="">[no code]</a></li>
      <li>Generalisation in Lifelong Reinforcement Learning through Logical Composition (ICLR2022) <a
          href="https://openreview.net/forum?id=ZOcX-eybqoL">arxiv</a> <a href="">[code bug]</a></li>
      <li><strong>Continual Learning via Local Module Composition</strong> (NIPS2021) <a
          href="https://arxiv.org/pdf/2111.07736.pdf">arxiv</a> <a href="https://github.com/oleksost/lmc">code</a></li>
      <li>Gradient Projection Memory for Continual Learning (ICLR2021 oral) <a
          href="https://openreview.net/forum?id=3AOj0RCNC2">arxiv</a> <a
          href="https://github.com/sahagobinda/GPM">code</a></li>
      <li>Policy and value transfer in lifelong reinforcement learning. (ICML2018) <a
          href="https://proceedings.mlr.press/v80/abel18b.html">arxiv</a> <a href="">[no code]</a></li>
      <li>Lipschitz Lifelong Reinforcement Learning (AAAI2021) <a href="https://arxiv.org/pdf/2001.05411.pdf">arxiv</a>
        <a href="https://github.com/SuReLI/llrl">code</a></li>
      <li>Towards Continual Reinforcement Learning: A Review and Perspectives <a
          href="https://arxiv.org/pdf/2012.13490.pdf">arxiv</a></li>
      <li>Fast reinforcement learning with generalized policy updates (PNAS) <a
          href="https://www.pnas.org/doi/10.1073/pnas.1907370117">arxiv</a> </li>
      <li>Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement (ICML2018)
        <a href="https://arxiv.org/pdf/1901.10964.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting (NIPS2020) <a
          href="https://arxiv.org/pdf/2007.07011.pdf?msclkid=f032622cae9b11eca1208cbc4573adfd">arxiv</a></li>
      <li>Policy Consolidation for Continual Reinforcement Learning (ICML2019) <a
          href="https://arxiv.org/pdf/1902.00255.pdf">arxiv</a> <a
          href="https://github.com/ChristosKap/policy_consolidation">code</a></li>
      <li><strong>Continual Reinforcement Learning with Complex Synapses</strong> <a
          href="https://arxiv.org/pdf/1802.07239.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Continuous Coordination As a Realistic Scenario for Lifelong Learning <a
          href="https://arxiv.org/pdf/2103.03216.pdf">arxiv</a> <a href="https://arxiv.org/pdf/2103.03216.pdf">code1</a>
        <a href="https://github.com/chandar-lab/CMAL_Hanabi">code2</a></li>
      <li>Lifelong Incremental Reinforcement Learning with Online Bayesian Inference (TNNLS) <a
          href="https://arxiv.org/pdf/2007.14196.pdf">pdf</a> <a href="https://github.com/HeyuanMingong/llirl">code</a>
      </li>
      <li>Is Model-Free Learning Nearly Optimal for Non-Stationary RL? [ICML2021] <a
          href="https://arxiv.org/pdf/2010.03161.pdfv2">arxiv</a> <a href="">[no code]</a>
        <h2 id="generalization">Generalization</h2>
      </li>
      <li>Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL (ICLR2022) <a
          href="https://arxiv.org/pdf/2106.02193.pdf">arxiv</a> <a
          href="https://github.com/bmazoure/ctrl_public">code</a></li>
      <li>Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability (NIPS2021) <a
          href="https://arxiv.org/pdf/2107.06277.pdf">arxiv</a></li>
      <li>Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates (ICLR2022) <a
          href="https://arxiv.org/pdf/2112.15025.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Environment Generation for Zero-Shot Compositional Reinforcement Learning (NIPS2021) <a
          href="https://arxiv.org/pdf/2201.08896.pdf">arxiv</a> <a
          href="https://github.com/google-research/google-research">code?</a></li>
      <li>Reinforcement Learning with Prototypical Representations (ICML2021) <a
          href="https://arxiv.org/pdf/2102.11271.pdf">arxiv</a> <a href="https://github.com/denisyarats/proto">code</a>
      </li>
      <li>Deep Reinforcement Learning amidst Continual Structured Non-Stationarity (ICML2021) <a
          href="http://proceedings.mlr.press/v139/xie21c/xie21c.pdf">arxiv</a></li>
      <li>K-level Reasoning for Zero-Shot Coordination in Hanabi (NIPS2021) <a
          href="https://proceedings.neurips.cc/arxiv/2021/hash/4547dff5fd7604f18c8ee32cf3da41d7-Abstract.html">arxiv</a>
      </li>
      <li>Source tasks selection for transfer deep reinforcement learning: a case of study on Atari games</li>
      <li>The Distracting Control Suite -- A Challenging Benchmark for Reinforcement Learning from Pixels <a
          href="https://arxiv.org/pdf/2101.02722.pdf">pdf</a> <a
          href="https://github.com/google-research/google-research/tree/master/distracting_control">code</a></li>
      <li>AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2107.02729.pdf?msclkid=20563870ae9511ec9aee6806961083d2">arxiv</a> <a
          href="https://github.com/adaptive-rl/adarl-code">code</a></li>
      <li>Improving zero-shot generalization in offline reinforcement learning using generalized similarity functions
        (ICLR2022 reject) <a href="https://openreview.net/forum?id=pC00NfsvnSK">openreview</a> <a href="">code</a></li>
      <li>DARLA: Improving Zero-Shot Transfer in Reinforcement Learning (ICML2017) <a
          href="https://arxiv.org/pdf/1707.08475.pdf">arxiv</a> <a href="https://github.com/BCHoagland/DARLA">code</a>
      </li>
      <li>Case-based reasoning for better generalization in textual reinforcement learning (ICLR2022 poster) <a
          href="https://arxiv.org/pdf/2110.08470.pdf">arxiv</a> [[no code]]</li>
      <li>Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks (ICML2021) <a
          href="https://arxiv.org/pdf/2101.07393.pdf">arxiv</a> <a
          href="https://github.com/ahjwang/messenger-emma">code</a></li>
      <li>Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning (ICML2021) <a
          href="https://arxiv.org/pdf/2101.07393.pdf">arxiv</a> <a
          href="https://github.com/ahjwang/messenger-emma">code</a></li>
      <li><strong>On the Generalization of Representations in Reinforcement Learning</strong> (AISTATS22) <a
          href="https://arxiv.org/pdf/2203.00543.pdf">arxiv</a> <a
          href="https://github.com/google-research/google-research/tree/master/generalization_representations_rl_aistats22">code</a>
      </li>
      <li><strong>Policy Architectures for Compositional Generalization in Control</strong> <a
          href="https://arxiv.org/pdf/2203.05960.pdf">arxiv</a> <a
          href="https://github.com/facebookresearch/entity-factored-rl">code</a></li>
      <li>Leveraging procedural generation to benchmark reinforcement learning</li>
      <li>Quantifying generalization in reinforcement learning</li>
      <li>Decoupling value and policy for generalization in reinforcement learning <a
          href="https://github.com/rraileanu/idaac">code</a></li>
      <li>On overfitting and asymptotic bias in batch reinforcement learning with partial observability</li>
      <li>Improving generalization in reinforcement learning with mixture regularization (NIPS2020) <a
          href="https://github.com/kaixin96/mixreg">code</a></li>
      <li>Observational overfitting in reinforcement learning</li>
      <li>Assessing generalization in deep reinforcement learning.</li>
      <li>Neuro-algorithmic Policies enable Fast Combinatorial Generalization (ICML2021) <a href="">[no code]</a></li>
      <li>Self-supervised Visual Reinforcement Learning with Object-centric Representations (ICLR2021 spotlight) <a
          href="https://github.com/martius-lab/SMORL">code</a></li>
      <li>Transient Non-stationarity and Generalisation in Deep Reinforcement Learning (ICLR2021)</li>
      <li>Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals (NIPS2020) (GNN)
      </li>
      <li><strong>SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies (ICML2021)</strong> <a
          href="https://github.com/LinxiFan/SECANT">code</a></li>
      <li><strong>Visual Transfer for Reinforcement Learning via Wasserstein Domain Confusion</strong> (AAAI2021) <a
          href="https://github.com/ku2482/wappo.pytorch">code</a></li>
      <li>Planning to Explore via Self-Supervised World Models (ICML2020) <a
          href="https://arxiv.org/pdf/2005.05960.pdf">arxiv</a> <a
          href="https://github.com/ramanans1/plan2explore">code</a></li>
    </ul>
    <h2 id="transfer-learnning">Transfer learnning</h2>
    <ul>
      <li>Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers (ICLR2021) <a
          href="https://arxiv.org/pdf/2006.13916.pdf">arxiv</a> <a
          href="https://github.com/shreyasc-13/off_domain_rlkit">code</a></li>
      <li>REPAINT: Knowledge Transfer in Deep Reinforcement Learning (ICML2021)<h2 id="multi-task">Multi-Task</h2>
      </li>
      <li>Multi-Task Reinforcement Learning with Context-based Representations (ICML2021) <a
          href="https://arxiv.org/pdf/2102.06177.pdf">arxiv</a> <a
          href="https://github.com/facebookresearch/mtrl">code</a>
        <h2 id="abstraction-logical">Abstraction, Logical</h2>
      </li>
      <li>Compositional Reinforcement Learning from Logical Specifications (NIPS2021) <a
          href="https://arxiv.org/pdf/2106.13906.pdf">arxiv</a> <a href="https://github.com/keyshor/dirl">code</a></li>
      <li>Learning Markov State Abstractions for Deep Reinforcement Learning (NIPS2021) <a
          href="https://arxiv.org/pdf/2106.04379.pdf">arxiv</a> <a
          href="https://github.com/camall3n/markov-state-abstractions">code</a></li>
      <li>R5: RULE DISCOVERY WITH REINFORCED AND RECURRENT RELATIONAL REASONING (ICLR2022) <a
          href="https://openreview.net/forum?id=2eXhNpHeW6E">arxiv</a></li>
      <li>A Theory of Abstraction in Reinforcement Learning <a href="https://arxiv.org/pdf/2203.00397.pdf">pdf
          thesis</a></li>
      <li><strong>Model-Invariant State Abstractions for Model-Based Reinforcement Learning</strong> <a
          href="https://arxiv.org/pdf/2102.09850.pdf">arxiv</a> <a href="">[no code]</a>
        <h2 id="symbolic">Symbolic</h2>
      </li>
      <li><strong>EMERGENT SYMBOLS THROUGH BINDING IN EXTERNAL MEMORY</strong> (ICLR2021) <a
          href="https://arxiv.org/pdf/2012.14601.pdf">arxiv</a> <a
          href="https://github.com/taylorwwebb/emergent_symbols">code</a></li>
      <li>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients
        (ICLR2021) <a href="https://arxiv.org/pdf/1912.04871.pdf">arxiv</a> <a
          href="https://github.com/brendenpetersen/deep-symbolic-regression">code</a></li>
      <li>Discovering symbolic policies with deep reinforcement learning (ICML2021) <a
          href="http://proceedings.mlr.press/v139/landajuela21a.html">arxiv</a></li>
      <li>Iterated learning for emergent systematicity in VQA (ICLR2021 oral) <a
          href="https://openreview.net/forum?id=Pd_oMxH8IlF">arxiv</a>
        <h2 id="auto-rl">Auto RL</h2>
      </li>
      <li>Evolving Reinforcement Learning Algorithms (ICLR2021 oral) <a
          href="https://arxiv.org/pdf/2101.03958.pdf">arxiv</a></li>
      <li>Discovering Reinforcement Learning Algorithms (NIPS2020) <a
          href="https://arxiv.org/pdf/2007.08794.pdf">arxiv</a></li>
      <li>CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning (NIPS2021w) <a
          href="https://arxiv.org/pdf/2110.02102.pdf">arxiv</a>
        <h2 id="evolutionary-rl">Evolutionary RL</h2>
      </li>
      <li>Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design (ICLR2022 oral) <a
          href="https://arxiv.org/pdf/2110.03659.pdf">arxiv</a> <a
          href="https://github.com/Khrylx/Transform2Act">code</a>
        <h2 id="graph">Graph</h2>
      </li>
      <li>Graph Convolutional Reinforcement Learning (ICLR2020) <a href="https://arxiv.org/pdf/1810.09202.pdf">arxiv</a>
        <a href="https://github.com/jiechuanjiang/pytorch_DGN">pytorch</a> <a
          href="https://github.com/PKU-AI-Edge/DGN/">tf</a></li>
      <li>Graph Policy Gradients for Large Scale Robot Control (CoRL2019 oral) <a
          href="https://arxiv.org/pdf/1907.03822.pdf">arxiv</a> <a
          href="https://github.com/arbaazkhan2/gpg_labeled">code</a></li>
      <li><strong>Actor-Attention-Critic for Multi-Agent Reinforcement Learning</strong> (ICML2019) <a
          href="https://arxiv.org/pdf/1810.02912.pdf">arxiv</a> <a
          href="https://github.com/shariqiqbal2810/MAAC">code</a></li>
      <li>Symbolic Relational Deep Reinforcement Learning based on Graph Neural Networks</li>
      <li>Efficient and Interpretable Robot Manipulation with Graph Neural Networks</li>
      <li>Towards practical multi-object manipulation using relational reinforcement learning.</li>
      <li>Neural task graphs:Generalizing to unseen tasks from a single video demonstration. (CVPR2019)<h2 id="marl">
          MARL</h2>
      </li>
      <li>Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations and Alternative Solution <a
          href="https://arxiv.org/pdf/2109.01178.pdf">arxiv</a></li>
      <li>Multi-Agent Generative Adversarial Imitation Learning (NIPS2018) <a
          href="https://arxiv.org/pdf/1807.09936.pdf">arxiv</a></li>
      <li>Social Neuro AI: Social Interaction as the &quot;dark matter&quot; of AI <a
          href="https://arxiv.org/pdf/2112.15459.pdf">arxiv</a></li>
      <li>Emergent Social Learning via Multi-agent Reinforcement Learning (ICML2021) <a
          href="https://arxiv.org/pdf/2010.00581.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li>Meta-brain Models: biologically-inspired cognitive agents <a
          href="https://arxiv.org/pdf/2109.11938.pdf">arxiv</a></li>
      <li>Learning Meta Representations for Agents in Multi-Agent Reinforcement Learning <a
          href="https://arxiv.org/pdf/2108.12988.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li><strong>An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning</strong> (NIPS2021) <a
          href="https://arxiv.org/pdf/2002.08030.pdf">arxiv</a> <a
          href="https://github.com/tianpeiyang/maptf_code">code</a></li>
      <li><strong>Option-Critic in Cooperative Multi-agent Systems</strong> <a
          href="https://arxiv.org/pdf/1911.12825.pdf">arxiv</a> <a
          href="https://github.com/Jhelum-Ch/On-policy-Distributed-Option-Critic">code</a></li>
      <li>Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning (ICML2019) <a
          href="https://arxiv.org/pdf/1811.01458.pdf">arxiv</a> <a
          href="https://github.com/facebookresearch/jps">code</a></li>
      <li>Joint Policy Search for Collaborative Multi-agent Imperfect Information Games (NIPS2020) <a
          href="https://arxiv.org/pdf/2008.06495.pdf">arxiv</a> <a
          href="https://github.com/facebookresearch/jps">code</a></li>
      <li>Hierarchical Deep Multiagent Reinforcement Learning with Temporal Abstraction <a
          href="https://arxiv.org/pdf/1809.09332.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li><strong>Cooperative Exploration for Multi-Agent Deep Reinforcement Learning</strong> (ICML2021) <a
          href="https://arxiv.org/pdf/2107.11444.pdfv1">arxiv</a> <a
          href="https://github.com/IouJenLiu/CMAE/tree/main">code</a></li>
      <li><strong>A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning</strong>
        (ICML2021) <a href="https://arxiv.org/pdf/2011.00382.pdf">arxiv</a> <a
          href="https://github.com/dkkim93/meta-mapg">code</a></li>
      <li>Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition (ICML)</li>
      <li>Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning (ICML2021)</li>
      <li><strong>Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and
          Theory</strong> (ICLR2022)</li>
      <li>Tensor Decomposition for Multi-agent Predictive State Representation</li>
      <li><strong>Learning with Opponent-Learning Awarenes</strong>s (AAMAS2018) <a
          href="https://arxiv.org/pdf/1709.04326.pdf">arxiv</a> <a href="https://github.com/alshedivat/lola">code</a>
      </li>
      <li><strong>Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts</strong> (IJCAI2021)
        <a href="https://arxiv.org/pdf/2105.03363.pdf">arxiv</a> <a href="https://github.com/apexrl/AORPO">code</a></li>
      <li>Communication in multi-agent reinforcement learning: Intention sharing (ICLR2021)</li>
      <li><strong>Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium
          Computation</strong> <a href="https://arxiv.org/pdf/2203.07322.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li><strong>Agent Modelling under Partial Observability for Deep Reinforcement Learning</strong> (NIPS2021) <a
          href="https://github.com/uoe-agents/LIAM">code</a></li>
    </ul>
    <h2 id="auxiliary-task-representation-learning">Auxiliary task, Representation learning</h2>
    <ul>
      <li>state-representaton-learning-rl <a
          href="https://tech.preferred.jp/en/blog/state-representation-learning-rl/">blog</a></li>
      <li><strong>Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning</strong>
        (ICLR2021 oral) <a href="https://arxiv.org/pdf/2101.05265.pdf">arxiv</a> <a
          href="https://github.com/google-research/google-research/tree/master/pse">code</a></li>
      <li><strong>Learning Invariant Representations for Reinforcement Learning without Reconstruction</strong> <a
          href="https://arxiv.org/pdf/2006.10742.pdf">arxiv</a> <a
          href="https://github.com/facebookresearch/deep_bisim4control">code</a></li>
      <li><strong>Decoupling Representation Learning from Reinforcement Learning</strong> (ICML2021) <a
          href="https://arxiv.org/pdf/2009.08319.pdf">arxiv</a> <a href="https://github.com/astooke/rlpyt">code</a></li>
      <li>Dealing with Non-Stationarity in MARL via Trust-Region Decomposition (ICLR2022) <a
          href="https://arxiv.org/pdf/2102.10616.pdf">arxiv</a> <a href="">[no code]</a>
        <h2 id="exploration">Exploration</h2>
      </li>
      <li>A Tutorial on Thompson Sampling <a href="https://arxiv.org/pdf/1707.02038.pdf">pdf</a></li>
      <li><strong>When should agents explore?</strong> (ICLR2021 spotlight) <a
          href="https://arxiv.org/pdf/2108.11811.pdf">arxiv</a></li>
      <li>Principled Exploration via Optimistic Bootstrapping and Backward Induction (ICML2021)<h2 id="offline">Offline
        </h2>
      </li>
      <li>NeoRL: A Near Real-World Benchmark for Offline Reinforcement Learning <a
          href="https://arxiv.org/pdf/2102.00714.pdf">arxiv</a> <a href="https://github.com/polixir/NeoRL">code</a>
        <h2 id="low-rank-mdp">Low Rank MDP</h2>
      </li>
      <li>Representation Learning for Online and Offline RL in Low-rank MDPs (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2110.04652.pdf">arxiv</a></li>
      <li>A Free Lunch from the Noise: Provable and Practical Exploration for Representation Learning (ICLR2022 reject)
        <a href="https://openreview.net/forum?id=f6CQliwyra">openreview</a></li>
      <li>Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations (NIPS2021) <a
          href="https://arxiv.org/pdf/2106.11519.pdf?msclkid=2a754eb2ae9f11ecb5df19982b137626">arxiv</a>
        <h2 id="sample-efficiency">Sample Efficiency</h2>
      </li>
      <li>Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2201.01666.pdf">arxiv</a>
        <h2 id="interpretability">Interpretability</h2>
      </li>
      <li>Programmatic Reinforcement Learning without Oracles (ICLR2022 spotlight) <a
          href="https://openreview.net/forum?id=6Tk2noBdvxt">openreview</a> <a href="">[no code]</a>
        <h2 id="sim2real">Sim2Real</h2>
      </li>
      <li>Understanding Domain Randomization for Sim-to-real Transfer (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2110.03239.pdf">arxiv</a>
        <h2 id="hierarchical">Hierarchical</h2>
      </li>
      <li>Possibility Before Utility: Learning And Using Hierarchical Affordances (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2203.12686.pdfv1?msclkid=83020b9cae9711ecaafdee45eee7f46a">arxiv</a> <a
          href="https://github.com/robbycostales/hal">code</a></li>
      <li>Hierarchical Reinforcement Learning: A Comprehensive Survey <a
          href="https://dl.acm.org/doi/10.1145/3453160">pdf</a></li>
      <li>Hierarchical Multi-Agent Reinforcement Learning <a
          href="https://mohammadghavamzadeh.github.io/PUBLICATIONS/jaamas06.pdf">pdf</a></li>
      <li>Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill Discovery (AAMAS2020) <a
          href="https://arxiv.org/pdf/1912.03558.pdf">arxiv</a> <a
          href="https://github.com/011235813/hierarchical-marl">code</a></li>
      <li>Graph-Based Skill Acquisition For Reinforcement Learning <a
          href="https://dl.acm.org/doi/pdf/10.1145/3291045">pdf</a></li>
      <li>Compositional Reinforcement Learning from Logical Specifications (NIPS2021) <a
          href="https://github.com/keyshor/dirl">code</a> (Dijkstra)<h2 id="pomdp">POMDP</h2>
      </li>
      <li><strong>Deep Variational Reinforcement Learning for POMDPs</strong> (ICLR2018) <a
          href="https://arxiv.org/pdf/1806.02426.pdf">arxiv</a> <a href="https://github.com/maximilianigl/DVRL">code</a>
      </li>
      <li><strong>Structured World Belief for Reinforcement Learning in POMDP</strong> (ICML2021) <a
          href="https://arxiv.org/pdf/2107.08577.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li><strong>An Efficient, Expressive and Local Minima-free Method for Learning Controlled Dynamical
          Systems</strong> (AAAI2018) <a href="https://arxiv.org/pdf/1702.03537.pdf">arxiv</a> <a
          href="https://github.com/ahefnycmu/rffpsr">code</a></li>
      <li><strong>Learning Latent Dynamics for Planning from Pixels</strong> (ICML2019) <a
          href="https://arxiv.org/pdf/1811.04551.pdf">arxiv</a> <a
          href="https://github.com/google-research/planet">code</a></li>
      <li>Recurrent Model-Free RL is a Strong Baseline for Many POMDPs</li>
      <li>Reinforcement Learning in Rich-Observation MDPs using Spectral Methods</li>
      <li>On Improving Deep Reinforcement Learning for POMDPs <a href="https://github.com/bit1029public/ADRQN">code</a>
      </li>
      <li>Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model (NIPS2020)</li>
      <li>Planning from Pixels using Inverse Dynamics Models (ICLR2021) <a href="">[no code]</a></li>
    </ul>
    <h2 id="contrained-rl">Contrained rl</h2>
    <ul>
      <li>Density Constrained Reinforcement Learning (ICML2021) <a href="https://arxiv.org/pdf/2106.12764.pdf">arxiv</a>
        <h2 id="evolution">Evolution</h2>
      </li>
      <li>Trust Region Evolution Strategies (AAAI2019) <a
          href="https://www.microsoft.com/en-us/research/uploads/prod/2018/11/trust-region-evolution-strategies.pdf">pdf</a>
        <h2 id="model-based">Model based</h2>
      </li>
      <li>Model-Based Reinforcement Learning via Latent-Space Collocation (ICML2021)<h2 id="binding">Binding</h2>
      </li>
      <li>Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding (ICLR2021 oral) <a
          href="https://github.com/bethgelab/slow_disentanglement">code</a>
        <h2 id="review">Review</h2>
      </li>
      <li>Deep Reinforcement Learning: Opportunities and Challenges <a
          href="https://arxiv.org/pdf/2202.11296.pdf">pdf</a></li>
      <li>Reinforcement Learning in Robotics: A Survey <a
          href="https://www.ri.cmu.edu/pub_files/2013/7/Kober_IJRR_2013.pdf">pdf</a></li>
      <li><strong>Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects</strong> <a
          href="https://arxiv.org/pdf/2203.10603.pdf">arxiv</a></li>
      <li>A Survey of Generalisation in Deep Reinforcement Learning <a
          href="https://arxiv.org/pdf/2111.09794.pdf">arxiv</a></li>
      <li>Approximation Methods for Partially Observed Markov Decision Processes (POMDPs)<h2 id="tutorials">Tutorials
        </h2>
      </li>
      <li>Notes on Theoretical Foundations of Reinforcement Learning <a
          href="https://people.eecs.berkeley.edu/~krishna/files/focs2020.pdf">pdf</a></li>
      <li>Exploration <a href="https://lilianweng.github.io/posts/2020-06-07-exploration-drl/">blog</a></li>
      <li><a href="https://github.com/yangyutu/EssentialMath/">https://github.com/yangyutu/EssentialMath/</a>
        <h2 id="misc">Misc</h2>
      </li>
      <li>Contextual Decision Processes with Low Bellman Rank are PAC-Learnable (ICML2017) <a
          href="https://arxiv.org/pdf/1610.09512.pdf">arxiv</a></li>
      <li>Is the Policy Gradient a Gradient? <a href="https://arxiv.org/pdf/1906.07073.pdf">pdf</a></li>
      <li>Bayesian Reinforcement Learning: A Survey <a href="https://arxiv.org/pdf/1609.04436.pdf">arxiv</a></li>
      <li>Learning Good State and Action Representations via Tensor Decomposition <a
          href="https://arxiv.org/pdf/2105.01136.pdf">arxiv</a></li>
      <li>On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning (ICLR2022 spotlight) <a
          href="https://arxiv.org/pdf/2105.01648.pdf?msclkid=eebce6cfae9511eca1c40739b9d0cfa1">arxiv</a></li>
      <li>Constrained Policy Optimization via Bayesian World Models <a
          href="https://openreview.net/forum?id=PRZoSmCinhf">openreview</a></li>
      <li>Improving Stochastic Policy Gradients in Continuous Control with Deep
        Reinforcement Learning using the Beta Distribution (ICML2017) <a
          href="http://proceedings.mlr.press/v70/chou17a.html">pdf</a></li>
      <li>A bayesian approach to problems in stochastic estimation and control <a
          href="https://ieeexplore.ieee.org/document/1105763">pdf</a></li>
      <li>On Proximal Policy Optimization&#39;s Heavy-tailed Gradients (ICML2021) <a
          href="https://arxiv.org/pdf/2102.10264.pdfv1">arxiv</a></li>
      <li>Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning
        (ICML2021) <a href="https://arxiv.org/pdf/2103.12726.pdf">arxiv</a> <a
          href="https://github.com/frt03/pic">code</a></li>
      <li>Muesli: Combining Improvements in Policy Optimization (ICML2021) <a
          href="https://arxiv.org/pdf/2104.06159.pdfv1">arxiv</a> <a
          href="https://github.com/YuriCat/MuesliJupyterExample">code</a></li>
      <li>Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half Precision (ICML2021) <a
          href="https://arxiv.org/pdf/2102.13565.pdf">arxiv</a> <a href="">[no code]</a></li>
      <li><strong>Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks</strong> (ICML2021)
        <a href="https://arxiv.org/pdf/2010.05313.pdfv3">arxiv</a> <a href="">[no code]</a></li>
      <li>Spectral Normalisation for Deep Reinforcement Learning: An Optimisation Perspective (ICML2021)</li>
      <li>Temporal Predictive Coding For Model-Based Planning In Latent Space (ICML2021)</li>
      <li>Neural codes: Firing rates and beyond. (beta distribution and spike coding)</li>
      <li>Analysis and Improvement of Policy Gradient Estimation (NIPS2011) (variance of policy gradient estimator is
        inversely proportional to $\sigma^2$)</li>
      <li>Recurrent predictive state policy networks</li>
      <li>A recurrent latent variable model for sequential data.</li>
    </ul>
    <h2 id="resourses">Resourses</h2>
    <ul>
      <li><a href="https://github.com/kaixin96/rl-generalization-arxiv">rl generalization arxiv</a></li>
      <li><a href="https://github.com/ContinualAI/continual-learning-arxivs">Continual AI</a></li>
      <li><a href="https://github.com/xialeiliu/Awesome-Incremental-Learning">Awesome Incremental Learning</a></li>
    </ul>
  </section>
</body>

</html>