<!DOCTYPE html>
<html lang="en">

<head>
  <title>Recommendation</title>
  <style>
    body {
      font-family: 'Open Sans', sans-serif;
      color: #333;
      line-height: 1.6;
    }

    h1,
    h2 {
      font-family: 'Lora', serif;
    }

    h1 {
      font-size: 2rem;
      text-align: center;
    }

    h2 {
      font-size: 1.5rem;
      margin: 2rem 0 1rem;
    }

    a {
      color: #0077cc;
      font-weight: bold;
      text-decoration: none;
      padding: 0.2rem 0.5rem;
      border-radius: 4px;
      transition: background 0.2s;
    }

    a:hover {
      background: #0077cc;
      color: #fff;
    }

    ul {
      list-style-type: none;
      padding: 0;
    }

    li {
      margin: 1rem 0;
    }

    @media (min-width: 600px) {
      body {
        max-width: 600px;
        margin: 0 auto;
      }

      h1 {
        text-align: left;
      }
    }
  </style>

<body>

  <section>
    <h1>
      深度学习论文精读
    </h1>
    <h2>
      录制完成的论文
    </h2>
    <p>
      | 日期 | 标题 | 封面 | 时长 | 视频（播放数） |
      | --: | -- | -- | --: | -- |
      | 3/30/23 |
      <a href="https://openai.com/research/gpt-4">
        GPT-4
      </a>
      |
      <img src="imgs/gpt4.jpg" width="200px" />
      | 1:20:38 |
      <a href="https://www.bilibili.com/video/BV1vM4y1U7b5">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1vM4y1U7b5" />
      </a>
      <br />
      <a href="https://youtu.be/K0SZ9mdygTw">
        <img alt="" src="https://img.shields.io/youtube/views/K0SZ9mdygTw?style=social" />
      </a>
      |
      | 3/23/23 | 大模型时代下做科研的四个思路 |
      <img src="imgs/limited-resources.jpg" width="200px" />
      | 1:06:29 |
      <a href="https://www.bilibili.com/video/BV1oX4y1d7X6">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1oX4y1d7X6" />
      </a>
      <br />
      <a href="https://youtu.be/sh79Z8i15PI">
        <img alt="" src="https://img.shields.io/youtube/views/sh79Z8i15PI?style=social" />
      </a>
      |
      | 3/10/23 |
      <a href="https://arxiv.org/pdf/2204.05862.pdf">
        Anthropic LLM
      </a>
      |
      <img src="imgs/anthropic_lm.jpg" width="200px" />
      | 1:01:51 |
      <a href="https://www.bilibili.com/video/BV1XY411B7nM">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1XY411B7nM" />
      </a>
      <br />
      <a href="https://youtu.be/iqX0pgNDon0">
        <img alt="" src="https://img.shields.io/youtube/views/iqX0pgNDon0?style=social" />
      </a>
      |
      | 1/20/23 |
      <a href="https://arxiv.org/pdf/2211.09110.pdf">
        Helm
      </a>
      全面语言模型评测 |
      <img src="imgs/helm.jpg" width="200px" />
      | 1:23:37 |
      <a href="https://www.bilibili.com/video/BV1z24y1B7uX">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1z24y1B7uX" />
      </a>
      <br />
      <a href="https://youtu.be/WgFEw9U3BXA">
        <img alt="" src="https://img.shields.io/youtube/views/WgFEw9U3BXA?style=social" />
      </a>
      |
      | 1/11/23 | 多模态论文串讲·下 |
      <img src="imgs/multimodal-2.jpg" width="200px" />
      | 1:03:29 |
      <a href="https://www.bilibili.com/video/BV1fA411Z772">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1fA411Z772" />
      </a>
      <br />
      <a href="https://youtu.be/S1le41J76lQ">
        <img alt="" src="https://img.shields.io/youtube/views/S1le41J76lQ?style=social" />
      </a>
      |
      | 12/29/22 |
      <a href="https://arxiv.org/pdf/2203.02155.pdf">
        Instruct GPT
      </a>
      |
      <img src="imgs/instruct-gpt.jpg" width="200px" />
      | 1:07:10 |
      <a href="https://www.bilibili.com/video/BV1hd4y187CR">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1hd4y187CR" />
      </a>
      <br />
      <a href="https://youtu.be/zfIGAwD1jOQ">
        <img alt="" src="https://img.shields.io/youtube/views/zfIGAwD1jOQ?style=social" />
      </a>
      |
      | 12/19/22 |
      <a href="https://arxiv.org/pdf/2206.02743.pdf">
        Neural Corpus Indexer
      </a>
      文档检索 |
      <img src="imgs/nci.jpg" width="200px" />
      | 55:47 |
      <a href="https://www.bilibili.com/video/BV1Se411w7Sn">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Se411w7Sn" />
      </a>
      <br />
      <a href="https://youtu.be/QRffZMSGJyU">
        <img alt="" src="https://img.shields.io/youtube/views/QRffZMSGJyU?style=social" />
      </a>
      |
      | 12/12/22 | 多模态论文串讲·上 |
      <img src="imgs/multimodal-1.jpg" width="200px" />
      | 1:12:27 |
      <a href="https://www.bilibili.com/video/BV1Vd4y1v77v">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Vd4y1v77v" />
      </a>
      <br />
      <a href="https://youtu.be/6pzBOQAXUB8">
        <img alt="" src="https://img.shields.io/youtube/views/6pzBOQAXUB8?style=social" />
      </a>
      |
      | 11/14/22 |
      <a href="https://cdn.openai.com/papers/whisper.pdf">
        OpenAI Whisper
      </a>
      精读 |
      <img src="imgs/whisper.jpg" width="200px" />
      | 1:12:16 |
      <a href="https://www.bilibili.com/video/BV1VG4y1t74x">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1VG4y1t74x" />
      </a>
      <br />
      <a href="https://youtu.be/3eXCJd32UnM">
        <img alt="" src="https://img.shields.io/youtube/views/3eXCJd32UnM?style=social" />
      </a>
      |
      | 11/07/22 | 在讲 OpenAI Whisper 前先做了一个剪视频小工具 |
      <img src="imgs/autocut.jpg" width="200px" />
      | 23:39 |
      <a href="https://www.bilibili.com/video/BV1Pe4y1t7de">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Pe4y1t7de" />
      </a>
      <br />
      <a href="https://youtu.be/PwVlvCPDnrI">
        <img alt="" src="https://img.shields.io/youtube/views/PwVlvCPDnrI?style=social" />
      </a>
      |
      | 10/23/22 |
      <a href="https://arxiv.org/pdf/2201.11903.pdf">
        Chain of Thought
      </a>
      论文、代码和资源 |
      <img src="imgs/cot.jpg" width="200px" />
      | 33:21 |
      <a href="https://www.bilibili.com/video/BV1t8411e7Ug">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1t8411e7Ug" />
      </a>
      <br />
      <a href="https://youtu.be/H4J59iG3t5o">
        <img alt="" src="https://img.shields.io/youtube/views/H4J59iG3t5o?style=social" />
      </a>
      |
      | 9/17/22 | CLIP 改进工作串讲（下） |
      <img src="imgs/clipx-part2.jpg" width="200px" />
      | 1:04:26 |
      <a href="https://www.bilibili.com/video/BV1gg411U7n4">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1gg411U7n4" />
      </a>
      <br />
      <a href="https://youtu.be/ugJeBivv65s">
        <img alt="" src="https://img.shields.io/youtube/views/ugJeBivv65s?style=social" />
      </a>
      |
      | 9/2/22 | CLIP 改进工作串讲（上） |
      <img src="imgs/clipx-part1.jpg" width="200px" />
      | 1:14:43 |
      <a href="https://www.bilibili.com/video/BV1FV4y1p7Lm">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1FV4y1p7Lm" />
      </a>
      <br />
      <a href="https://youtu.be/x4CDhZz_Dvg">
        <img alt="" src="https://img.shields.io/youtube/views/x4CDhZz_Dvg?style=social" />
      </a>
      |
      | 7/29/22 |
      <a href="https://arxiv.org/pdf/2102.03334.pdf">
        ViLT
      </a>
      论文精读 |
      <img src="imgs/vilt.jpg" width="200px" />
      | 1:03:26 |
      <a href="https://www.bilibili.com/video/BV14r4y1j74y">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV14r4y1j74y" />
      </a>
      <br />
      <a href="https://youtu.be/ug8YvZOjOCE">
        <img alt="" src="https://img.shields.io/youtube/views/ug8YvZOjOCE?style=social" />
      </a>
      |
      | 7/22/22 | 理由、论据和担保【
      <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo23521678.html">
        研究的艺术
      </a>
      ·四】 |
      <img src="imgs/craft_research_p4.jpg" width="200px" />
      | 44:14 |
      <a href="https://www.bilibili.com/video/BV1SB4y1a75c">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1SB4y1a75c" />
      </a>
      |
      | 7/15/22 | 如何讲好故事、故事里的论点【
      <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo23521678.html">
        研究的艺术
      </a>
      ·三】|
      <img src="imgs/craft_research_p3.jpg" width="200px" />
      | 43:56 |
      <a href="https://www.bilibili.com/video/BV1WB4y1v7ST">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1WB4y1v7ST" />
      </a>
      |
      | 7/8/22 |
      <a href="https://arxiv.org/pdf/2204.06125.pdf">
        DALL·E 2
      </a>
      逐段精读 |
      <img src="imgs/dalle2.jpg" width="200px" />
      | 1:27:54 |
      <a href="https://www.bilibili.com/video/BV17r4y1u77B">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV17r4y1u77B" />
      </a>
      <br />
      <a href="https://youtu.be/hO57mntSMl0">
        <img alt="" src="https://img.shields.io/youtube/views/hO57mntSMl0?style=social" />
      </a>
      |
      | 7/1/22 | 明白问题的重要性【
      <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo23521678.html">
        研究的艺术
      </a>
      ·二】|
      <img src="imgs/craft_research_p2.jpg" width="200px" />
      | 1:03:40 |
      <a href="https://www.bilibili.com/video/BV11S4y1v7S2/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV11S4y1v7S2" />
      </a>
      |
      | 6/24/22 | 跟读者建立联系【
      <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo23521678.html">
        研究的艺术
      </a>
      ·一】 |
      <img src="imgs/craft_research_p1.jpg" width="200px" />
      | 45:01 |
      <a href="https://www.bilibili.com/video/BV1hY411T7vy/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1hY411T7vy" />
      </a>
      |
      | 6/17/22 |
      <a href="https://arxiv.org/pdf/1910.02054.pdf">
        Zero
      </a>
      逐段精读 |
      <img src="imgs/zero.jpg" width="200px" />
      | 52:21 |
      <a href="https://www.bilibili.com/video/BV1tY411g7ZT/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1tY411g7ZT" />
      </a>
      |
      | 6/10/22 |
      <a href="https://arxiv.org/pdf/2005.12872.pdf">
        DETR
      </a>
      逐段精读 |
      <img src="imgs/detr.jpg" width="200px" />
      | 54:22 |
      <a href="https://www.bilibili.com/video/BV1GB4y1X72R/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GB4y1X72R" />
      </a>
      |
      | 6/3/22 |
      <a href="https://arxiv.org/pdf/1909.08053.pdf">
        Megatron LM
      </a>
      逐段精读 |
      <img src="imgs/megatron_lm.jpg" width="200px" />
      | 56:07 |
      <a href="https://www.bilibili.com/video/BV1nB4y1R7Yz/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1nB4y1R7Yz" />
      </a>
      |
      | 5/27/22 |
      <a href="https://proceedings.neurips.cc/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf">
        GPipe
      </a>
      逐段精读 |
      <img src="imgs/gpipe.jpg" width="200px" />
      | 58:47 |
      <a href="https://www.bilibili.com/video/BV1v34y1E7zu/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1v34y1E7zu" />
      </a>
      <br />
      <a href="https://youtu.be/eXjRpS_BTbs">
        <img alt="" src="https://img.shields.io/youtube/views/eXjRpS_BTbs?style=social" />
      </a>
      |
      | 5/5/22 |
      <a href="https://arxiv.org/pdf/2203.12533.pdf">
        Pathways
      </a>
      逐段精读 |
      <img src="imgs/pathways.jpg" width="200px" />
      | 1:02:13 |
      <a href="https://www.bilibili.com/video/BV1xB4y1m7Xi/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1xB4y1m7Xi" />
      </a>
      <br />
      <a href="https://youtu.be/8hS1ZtgG0wU">
        <img alt="" src="https://img.shields.io/youtube/views/8hS1ZtgG0wU?style=social" />
      </a>
      |
      | 4/28/22 |
      <a href="https://arxiv.org/pdf/2012.06567.pdf">
        视频理解论文串讲
      </a>
      （下） |
      <img src="imgs/video-survey-p2.jpg" width="200px" />
      | 1:08:32 |
      <a href="https://www.bilibili.com/video/BV11Y411P7ep/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV11Y411P7ep" />
      </a>
      <br />
      <a href="https://youtu.be/J2YC0-k57NM">
        <img alt="" src="https://img.shields.io/youtube/views/J2YC0-k57NM?style=social" />
      </a>
      |
      | 4/21/22 |
      <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">
        参数服务器（Parameter Server）
      </a>
      逐段精读 |
      <img src="imgs/ps.jpg" width="200px" />
      | 1:37:40 |
      <a href="https://www.bilibili.com/video/BV1YA4y197G8/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1YA4y197G8" />
      </a>
      <br />
      <a href="https://youtu.be/xt-AwUrDxQk">
        <img alt="" src="https://img.shields.io/youtube/views/xt-AwUrDxQk?style=social" />
      </a>
      |
      | 4/14/22 |
      <a href="https://arxiv.org/pdf/2012.06567.pdf">
        视频理解论文串讲
      </a>
      （上） |
      <img src="imgs/video-survey-p1.jpg" width="200px" />
      | 51:15 |
      <a href="https://www.bilibili.com/video/BV1fL4y157yA/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1fL4y157yA" />
      </a>
      <br />
      <a href="https://youtu.be/gK7AGO6okhc">
        <img alt="" src="https://img.shields.io/youtube/views/gK7AGO6okhc?style=social" />
      </a>
      |
      | 3/31/22 |
      <a href="https://arxiv.org/pdf/1705.07750.pdf">
        I3D
      </a>
      论文精读 |
      <img src="imgs/i3d.jpg" width="200px" />
      | 52:31 |
      <a href="https://www.bilibili.com/video/BV1tY4y1p7hq/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1tY4y1p7hq" />
      </a>
      <br />
      <a href="https://youtu.be/9lIkKiAn6uE">
        <img alt="" src="https://img.shields.io/youtube/views/9lIkKiAn6uE?style=social" />
      </a>
      |
      | 3/24/22 | 斯坦福 2022 年
      <a href="https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf">
        AI 指数报告
      </a>
      精读 |
      <img src="imgs/ai_index_22.jpg" width="200px" />
      | 1:19:56 |
      <a href="https://www.bilibili.com/video/BV1s44y1N7eu/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1s44y1N7eu" />
      </a>
      <br />
      <a href="https://youtu.be/K8h_xjQ6ufY">
        <img alt="" src="https://img.shields.io/youtube/views/K8h_xjQ6ufY?style=social" />
      </a>
      |
      | 3/17/22 |
      <a
        href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">
        AlphaCode
      </a>
      论文精读 |
      <img src="imgs/alphacode.jpg" width="200px" />
      | 44:00 |
      <a href="https://www.bilibili.com/video/BV1ab4y1s7rc/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1ab4y1s7rc" />
      </a>
      <br />
      <a href="https://youtu.be/t8Gzkca9pW4">
        <img alt="" src="https://img.shields.io/youtube/views/t8Gzkca9pW4?style=social" />
      </a>
      |
      | 3/10/22 |
      <a href="https://arxiv.org/pdf/2107.03374.pdf">
        OpenAI Codex
      </a>
      论文精读 |
      <img src="imgs/codex.jpg" width="200px" />
      | 47:58 |
      <a href="https://www.bilibili.com/video/BV1iY41137Zi/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1iY41137Zi" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1490959755963666432">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1490959755963666432" />
      </a>
      <br />
      <a href="https://youtu.be/oZriUGkQSNM">
        <img alt="" src="https://img.shields.io/youtube/views/oZriUGkQSNM?style=social" />
      </a>
      |
      | 3/3/22 |
      <a
        href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">
        GPT
      </a>
      ,
      <a
        href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">
        GPT-2
      </a>
      ,
      <a href="https://arxiv.org/pdf/2005.14165.pdf">
        GPT-3
      </a>
      精读 |
      <img src="imgs/gpt3.jpg" width="200px" />
      | 1:29:58 |
      <a href="https://www.bilibili.com/video/BV1AF411b7xQ/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1AF411b7xQ" />
      </a>
      <br />
      <a href="https://youtu.be/t70Bl3w7bxY">
        <img alt="" src="https://img.shields.io/youtube/views/t70Bl3w7bxY?style=social" />
      </a>
      |
      | 2/24/22 |
      <a href="https://proceedings.neurips.cc/paper/2014/file/00ec53c4682d36f5c4359f4ae7bd7ba1-Paper.pdf">
        Two-Stream
      </a>
      逐段精读 |
      <img src="imgs/twostream.jpg" width="200px" />
      | 52:57 |
      <a href="https://www.bilibili.com/video/BV1mq4y1x7RU/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1mq4y1x7RU" />
      </a>
      <br />
      <a href="https://youtu.be/vuqwKP2iDe0">
        <img alt="" src="https://img.shields.io/youtube/views/vuqwKP2iDe0?style=social" />
      </a>
      |
      | 2/10/22 |
      <a href="https://openai.com/blog/clip/">
        CLIP
      </a>
      逐段精读 |
      <img src="imgs/clip.jpg" width="200px" />
      | 1:38:25 |
      <a href="https://www.bilibili.com/video/BV1SL4y1s7LQ/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1SL4y1s7LQ" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1475706654562299904">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1475706654562299904" />
      </a>
      <br />
      <a href="https://youtu.be/OZF1t_Hieq8">
        <img alt="" src="https://img.shields.io/youtube/views/OZF1t_Hieq8?style=social" />
      </a>
      |
      | 2/6/22 | 你（被）吐槽过
      <a href="https://perceiving-systems.blog/en/post/novelty-in-science">
        论文不够 novel
      </a>
      吗？|
      <img src="imgs/novelty.jpg" width="200px" />
      | 14:11 |
      <a href="https://www.bilibili.com/video/BV1ea41127Bq/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1ea41127Bq" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1475719090198876161">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1475719090198876161" />
      </a>
      |
      | 1/23/22 |
      <a href="https://www.nature.com/articles/s41586-021-03819-2.pdf">
        AlphaFold 2
      </a>
      精读 |
      <img src="imgs/alphafold_2.jpg" width="200px" />
      | 1:15:28 |
      <a href="https://www.bilibili.com/video/BV1oR4y1K7Xr/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1oR4y1K7Xr" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1469132410537717760">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1469132410537717760" />
      </a>
      <br />
      <a href="https://youtu.be/Oy3OCoGUr-w">
        <img alt="" src="https://img.shields.io/youtube/views/Oy3OCoGUr-w?style=social" />
      </a>
      |
      | 1/18/22 | 如何判断（你自己的）研究工作的价值 |
      <img src="imgs/research_value.jpg" width="200px" />
      | 9:59 |
      <a href="https://www.bilibili.com/video/BV1oL411c7Us/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1oL411c7Us" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1475716940051869696">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1475716940051869696" />
      </a>
      |
      | 1/15/22 |
      <a href="https://arxiv.org/pdf/2103.14030.pdf">
        Swin Transformer
      </a>
      精读 |
      <img src="imgs/swin_transformer.jpg" width="200px" />
      | 1:00:21 |
      <a href="https://www.bilibili.com/video/BV13L4y1475U/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV13L4y1475U" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1466282983652691968">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1466282983652691968" />
      </a>
      <br />
      <a href="https://youtu.be/luP3-Fs0QCo">
        <img alt="" src="https://img.shields.io/youtube/views/luP3-Fs0QCo?style=social" />
      </a>
      |
      | 1/7/22 |
      <a href="https://www.nature.com/articles/s41586-021-04086-x.pdf">
        指导数学直觉
      </a>
      |
      <img src="imgs/math_conj.jpg" width="200px" />
      | 52:51 |
      <a href="https://www.bilibili.com/video/BV1YZ4y1S72j/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1YZ4y1S72j" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1464060386375299072">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1464060386375299072" />
      </a>
      <br />
      <a href="https://youtu.be/czFGjvhtss8">
        <img alt="" src="https://img.shields.io/youtube/views/czFGjvhtss8?style=social" />
      </a>
      |
      | 1/5/22 | AlphaFold 2 预告 |
      <img src="imgs/alphafold_2_preview.jpg" width="200px" />
      | 03:28 |
      <a href="https://www.bilibili.com/video/BV1Eu411U7Te/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Eu411U7Te" />
      </a>
      |
      | 12/20/21 |
      <a href="#contrastive_learning">
        对比学习
      </a>
      论文综述 |
      <img src="imgs/contrastive.jpg" width="200px" />
      | 1:32:01 |
      <a href="https://www.bilibili.com/video/BV19S4y1M7hm/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV19S4y1M7hm" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1460828005077164032">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1460828005077164032" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=1pvxufGRuW4">
        <img alt="" src="https://img.shields.io/youtube/views/1pvxufGRuW4?style=social" />
      </a>
      |
      | 12/15/21 |
      <a href="https://arxiv.org/pdf/1911.05722.pdf">
        MoCo
      </a>
      逐段精读 |
      <img src="imgs/mocov1.jpg" width="200px" />
      | 1:24:11 |
      <a href="https://www.bilibili.com/video/BV1C3411s7t9/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1C3411s7t9" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1454723120678936576">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1454723120678936576" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=1pvxufGRuW4">
        <img alt="" src="https://img.shields.io/youtube/views/1pvxufGRuW4?style=social" />
      </a>
      |
      | 12/9/21 | 如何找研究想法 1 |
      <img src="imgs/mae_idea.jpg" width="200px" />
      | 5:34 |
      <a href="https://www.bilibili.com/video/BV1qq4y1z7F2/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1qq4y1z7F2" />
      </a>
      |
      | 12/8/21 |
      <a href="https://arxiv.org/pdf/2111.06377.pdf">
        MAE
      </a>
      逐段精读 |
      <img src="imgs/mae.jpg" width="200px" />
      | 47:04 |
      <a href="https://www.bilibili.com/video/BV1sq4y1q77t/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1sq4y1q77t" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1452458167968251904">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1452458167968251904" />
      </a>
      <br />
      <a href="https://youtu.be/mYlX2dpdHHM">
        <img alt="" src="https://img.shields.io/youtube/views/mYlX2dpdHHM?style=social" />
      </a>
      |
      | 11/29/21 |
      <a href="https://arxiv.org/pdf/2010.11929.pdf">
        ViT
      </a>
      逐段精读 |
      <img src="imgs/vit.jpg" width="200px" />
      | 1:11:30 |
      <a href="https://www.bilibili.com/video/BV15P4y137jb/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV15P4y137jb" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1449195245754380288">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1449195245754380288" />
      </a>
      <br />
      <a href="https://youtu.be/FRFt3x0bO94">
        <img alt="" src="https://img.shields.io/youtube/views/FRFt3x0bO94?style=social" />
      </a>
      |
      | 11/18/21 |
      <a href="https://arxiv.org/pdf/1810.04805.pdf">
        BERT
      </a>
      逐段精读 |
      <img src="imgs/bert.jpg" width="200px" />
      | 45:49 |
      <a href="https://www.bilibili.com/video/BV1PL411M7eQ/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1PL411M7eQ" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1445340200976785408">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1445340200976785408" />
      </a>
      <br />
      <a href="https://youtu.be/ULD3uIb2MHQ">
        <img alt="" src="https://img.shields.io/youtube/views/ULD3uIb2MHQ?style=social" />
      </a>
      |
      | 11/9/21 |
      <a href="https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">
        GAN
      </a>
      逐段精读 |
      <img src="imgs/gan.jpg" width="200px" />
      | 46:16 |
      <a href="https://www.bilibili.com/video/BV1rb4y187vD/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1rb4y187vD" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1442091389241159681">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1442091389241159681" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=g_0HtlrLiDo">
        <img alt="" src="https://img.shields.io/youtube/views/g_0HtlrLiDo?style=social" />
      </a>
      |
      | 11/3/21 | 零基础多图详解
      <a href="https://distill.pub/2021/gnn-intro/">
        图神经网络
      </a>
      （GNN/GCN） |
      <img src="imgs/gnn.jpg" width="200px" />
      | 1:06:19 |
      <a href="https://www.bilibili.com/video/BV1iT4y1d7zP/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1iT4y1d7zP" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1439540657619087360">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1439540657619087360" />
      </a>
      <br />
      <a href="https://youtu.be/sejA2PtCITw">
        <img alt="" src="https://img.shields.io/youtube/views/sejA2PtCITw?style=social" />
      </a>
      |
      | 10/27/21 |
      <a href="https://arxiv.org/pdf/1706.03762.pdf">
        Transformer
      </a>
      逐段精读
      <br />
      （视频中提到的文献 [^transformer]) |
      <img src="imgs/transformer.jpg" width="200px" />
      | 1:27:05 |
      <a href="https://www.bilibili.com/video/BV1pu411o7BE/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1pu411o7BE" />
      </a>
      <br>
      <a href="https://www.zhihu.com/zvideo/1437034536677404672">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1437034536677404672" />
      </a>
      <br />
      <a href="https://youtu.be/nzqlFIcCSWQ">
        <img alt="" src="https://img.shields.io/youtube/views/nzqlFIcCSWQ?style=social" />
      </a>
      |
      | 10/22/21 |
      <a href="https://arxiv.org/pdf/1512.03385.pdf">
        ResNet
      </a>
      论文逐段精读 |
      <img src="imgs/resnet-2.jpg" width="200px" />
      | 53:46 |
      <a href="https://www.bilibili.com/video/BV1P3411y7nn/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1P3411y7nn" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1434795406001180672">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1434795406001180672" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=pWMnzCX4cwQ">
        <img alt="" src="https://img.shields.io/youtube/views/pWMnzCX4cwQ?style=social" />
      </a>
      |
      | 10/21/21 | 撑起计算机视觉半边天的
      <a href="https://arxiv.org/pdf/1512.03385.pdf">
        ResNet
      </a>
      |
      <img src="imgs/resnet-1.jpg" width="200px" />
      | 11:50 |
      <a href="https://www.bilibili.com/video/BV1Fb4y1h73E/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Fb4y1h73E" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1434787226101751808">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1434787226101751808" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=NnSldWhSqvY">
        <img alt="" src="https://img.shields.io/youtube/views/NnSldWhSqvY?style=social" />
      </a>
      |
      | 10/15/21 |
      <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">
        AlexNet
      </a>
      论文逐段精读 |
      <img src="imgs/alexnet-2.jpg" width="200px" />
      | 55:21 |
      <a href="https://www.bilibili.com/video/BV1hq4y157t1/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1hq4y157t1" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1432354207483871232">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1432354207483871232" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=wYmlILPsLlY">
        <img alt="" src="https://img.shields.io/youtube/views/wYmlILPsLlY?style=social" />
      </a>
      |
      | 10/14/21 | 9年后重读深度学习奠基作之一：
      <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">
        AlexNet
      </a>
      |
      <img src="imgs/alexnet-1.jpg" width="200px" />
      | 19:59 |
      <a href="https://www.bilibili.com/video/BV1ih411J7Kz/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1ih411J7Kz" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1432155856322920448">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1432155856322920448" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=vdYH0fE6thY">
        <img alt="" src="https://img.shields.io/youtube/views/vdYH0fE6thY?style=social" />
      </a>
      |
      | 10/06/21 | 如何读论文 |
      <img src="imgs/read-paper.jpg" width="200px" />
      | 06:39 |
      <a href="https://www.bilibili.com/video/BV1H44y1t75x/">
        <img alt="bilibili"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=bilibili&amp;query=data.stat.view&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1H44y1t75x" />
      </a>
      <br />
      <a href="https://www.zhihu.com/zvideo/1428973951632969728">
        <img alt="zhihu"
          src="https://img.shields.io/badge/dynamic/json?label=views&amp;style=social&amp;logo=zhihu&amp;query=video.play_count&amp;url=https://www.zhihu.com/api/v4/zvideos/1428973951632969728" />
      </a>
      <br />
      <a href="https://www.youtube.com/watch?v=txjl_Q4jCyQ&amp;list=PLFXJ6jwg0qW-7UM8iUTj3qKqdhbQULP5I&amp;index=1">
        <img alt="" src="https://img.shields.io/youtube/views/txjl_Q4jCyQ?style=social" />
      </a>
      |
      </br>
    </p>
    <p>
      [^transformer]: 1
      <a href="https://arxiv.org/pdf/2108.07258.pdf">
        斯坦福100+作者的200+页综述
      </a>
      ，2
      <a href="https://arxiv.org/pdf/1911.07013.pdf">
        对LayerNorm的新研究
      </a>
      ，3
      <a href="https://arxiv.org/pdf/2103.03404.pdf">
        对Attention在Transformer里面作用的研究
      </a>
    </p>
    <h2>
      所有论文
    </h2>
    <p>
      包括已经录制完成和之后将要介绍的论文。选取的原则是10年内深度学习里有影响力文章（必读文章），或者近期比较有意思的文章。当然这十年里重要的工作太多了，不可能一一过一遍。在选取的时候我会偏向一些之前
      <a href="https://c.d2l.ai/zh-v2/">
        直播课
      </a>
      中没讲到过的。 欢迎大家在
      <a href="https://github.com/mli/paper-reading/discussions">
        讨论区
      </a>
      里提供建（点）议（歌）。
    </p>
    <p>
      总论文数 67，录制完成数 32
    </p>
    <p>
      （这里引用采用的是 semanticscholar，是因为它提供
      <a href="https://api.semanticscholar.org/api-docs/graph#operation/get_graph_get_paper">
        API
      </a>
      可以自动获取，不用手动更新。）
    </p>
    <h3>
      计算机视觉 - CNN
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2012 |
      <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">
        AlexNet
      </a>
      | 深度学习热潮的奠基作 |
      <a
        href="https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/abd1c342495432171beb7ca8fd9551ef13cbd0ff">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fabd1c342495432171beb7ca8fd9551ef13cbd0ff%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2014 |
      <a href="https://arxiv.org/pdf/1409.1556.pdf">
        VGG
      </a>
      | 使用 3x3 卷积构造更深的网络 |
      <a
        href="https://www.semanticscholar.org/paper/Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman/eb42cf88027de515750f230b23b1a057dc782108">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Feb42cf88027de515750f230b23b1a057dc782108%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2014 |
      <a href="https://arxiv.org/pdf/1409.4842.pdf">
        GoogleNet
      </a>
      | 使用并行架构构造更深的网络 |
      <a
        href="https://www.semanticscholar.org/paper/Going-deeper-with-convolutions-Szegedy-Liu/e15cf50aa89fee8535703b9f9512fca5bfc43327">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe15cf50aa89fee8535703b9f9512fca5bfc43327%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2015 |
      <a href="https://arxiv.org/pdf/1512.03385.pdf">
        ResNet
      </a>
      | 构建深层网络都要有的残差连接。 |
      <a
        href="https://www.semanticscholar.org/paper/Deep-Residual-Learning-for-Image-Recognition-He-Zhang/2c03df8b48bf3fa39054345bafabfeff15bfd11d">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2c03df8b48bf3fa39054345bafabfeff15bfd11d%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="https://arxiv.org/pdf/1704.04861.pdf">
        MobileNet
      </a>
      | 适合终端设备的小CNN |
      <a
        href="https://www.semanticscholar.org/paper/MobileNets%3A-Efficient-Convolutional-Neural-Networks-Howard-Zhu/3647d6d0f151dc05626449ee09cc7bce55be497e">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3647d6d0f151dc05626449ee09cc7bce55be497e%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2019 |
      <a href="https://arxiv.org/pdf/1905.11946.pdf">
        EfficientNet
      </a>
      | 通过架构搜索得到的CNN |
      <a
        href="https://www.semanticscholar.org/paper/EfficientNet%3A-Rethinking-Model-Scaling-for-Neural-Tan-Le/4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2021 |
      <a href="https://arxiv.org/pdf/2110.07641.pdf">
        Non-deep networks
      </a>
      | 让不深的网络也能在ImageNet刷到SOTA |
      <a
        href="https://www.semanticscholar.org/paper/Non-deep-Networks-Goyal-Bochkovskiy/0d7f6086772079bc3e243b7b375a9ca1a517ba8b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0d7f6086772079bc3e243b7b375a9ca1a517ba8b%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      计算机视觉 - Transformer
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2010.11929.pdf">
        ViT
      </a>
      | Transformer杀入CV界 |
      <a
        href="https://www.semanticscholar.org/paper/An-Image-is-Worth-16x16-Words%3A-Transformers-for-at-Dosovitskiy-Beyer/7b15fa1b8d413fbe14ef7a97f651f47f5aff3903">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7b15fa1b8d413fbe14ef7a97f651f47f5aff3903%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2103.14030.pdf">
        Swin Transformer
      </a>
      | 多层次的Vision Transformer |
      <a
        href="https://www.semanticscholar.org/paper/Swin-Transformer%3A-Hierarchical-Vision-Transformer-Liu-Lin/c8b25fab5608c3e033d34b4483ec47e68ba109b7">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc8b25fab5608c3e033d34b4483ec47e68ba109b7%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2021 |
      <a href="https://arxiv.org/pdf/2105.01601.pdf">
        MLP-Mixer
      </a>
      | 使用MLP替换self-attention |
      <a
        href="https://www.semanticscholar.org/paper/MLP-Mixer%3A-An-all-MLP-Architecture-for-Vision-Tolstikhin-Houlsby/2def61f556f9a5576ace08911496b7c7e4f970a4">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2def61f556f9a5576ace08911496b7c7e4f970a4%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2111.06377.pdf">
        MAE
      </a>
      | BERT的CV版 |
      <a
        href="https://www.semanticscholar.org/paper/Masked-Autoencoders-Are-Scalable-Vision-Learners-He-Chen/c1962a8cf364595ed2838a097e9aa7cd159d3118">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc1962a8cf364595ed2838a097e9aa7cd159d3118%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      生成模型
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------- | ------------ |
      ------------------------------------------------------------ |
      | ✅ | 2014 |
      <a href="https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">
        GAN
      </a>
      | 生成模型的开创工作 |
      <a
        href="https://www.semanticscholar.org/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F54e325aee6b2d476bbbb88615ac15e251c6e8214%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2015 |
      <a href="https://arxiv.org/pdf/1511.06434.pdf">
        DCGAN
      </a>
      | 使用CNN的GAN |
      <a
        href="https://www.semanticscholar.org/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8388f1be26329fa45e5807e968a641ce170ea078%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2016 |
      <a href="https://arxiv.org/pdf/1611.07004.pdf">
        pix2pix
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/Image-to-Image-Translation-with-Conditional-Isola-Zhu/8acbe90d5b852dadea7810345451a99608ee54c7">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8acbe90d5b852dadea7810345451a99608ee54c7%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2016 |
      <a href="https://arxiv.org/pdf/1609.04802.pdf">
        SRGAN
      </a>
      | 图片超分辨率 |
      <a
        href="https://www.semanticscholar.org/paper/Photo-Realistic-Single-Image-Super-Resolution-Using-Ledig-Theis/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdf0c54fe61f0ffb9f0e36a17c2038d9a1964cba3%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="https://arxiv.org/pdf/1701.07875.pdf">
        WGAN
      </a>
      | 训练更加容易 |
      <a
        href="https://www.semanticscholar.org/paper/Wasserstein-GAN-Arjovsky-Chintala/2f85b7376769473d2bed56f855f115e23d727094">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2f85b7376769473d2bed56f855f115e23d727094%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="https://arxiv.org/pdf/1703.10593.pdf">
        CycleGAN
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/Unpaired-Image-to-Image-Translation-Using-Networks-Zhu-Park/c43d954cf8133e6254499f3d68e45218067e4941">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc43d954cf8133e6254499f3d68e45218067e4941%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2018 |
      <a href="https://arxiv.org/pdf/1812.04948.pdf">
        StyleGAN
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/A-Style-Based-Generator-Architecture-for-Generative-Karras-Laine/ceb2ebef0b41e31c1a21b28c2734123900c005e2">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fceb2ebef0b41e31c1a21b28c2734123900c005e2%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2019 |
      <a href="https://arxiv.org/pdf/1912.04958.pdf">
        StyleGAN2
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/Analyzing-and-Improving-the-Image-Quality-of-Karras-Laine/f3e3d1f86a534a3654d0ee263142e44f4e2c61e9">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff3e3d1f86a534a3654d0ee263142e44f4e2c61e9%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2020 |
      <a href="https://arxiv.org/pdf/2006.11239.pdf">
        DDPM
      </a>
      | Diffusion Models |
      <a
        href="https://www.semanticscholar.org/paper/Denoising-Diffusion-Probabilistic-Models-Ho-Jain/289db3be7bf77e06e75541ba93269de3d604ac72">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F289db3be7bf77e06e75541ba93269de3d604ac72%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2021 |
      <a href="https://arxiv.org/pdf/2102.09672.pdf">
        Improved DDPM
      </a>
      | 改进的 DDPM |
      <a
        href="https://www.semanticscholar.org/paper/Improved-Denoising-Diffusion-Probabilistic-Models-Nichol-Dhariwal/de18baa4964804cf471d85a5a090498242d2e79f">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fde18baa4964804cf471d85a5a090498242d2e79f%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2021 |
      <a href="https://arxiv.org/pdf/2105.05233.pdf">
        Guided Diffusion Models
      </a>
      | 号称超越 GAN |
      <a
        href="https://www.semanticscholar.org/paper/Diffusion-Models-Beat-GANs-on-Image-Synthesis-Dhariwal-Nichol/64ea8f180d0682e6c18d1eb688afdb2027c02794">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F64ea8f180d0682e6c18d1eb688afdb2027c02794%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2021 |
      <a href="https://arxiv.org/pdf/2106.12423.pdf">
        StyleGAN3
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/Alias-Free-Generative-Adversarial-Networks-Karras-Aittala/c1ff08b59f00c44f34dfdde55cd53370733a2c19">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc1ff08b59f00c44f34dfdde55cd53370733a2c19%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2204.06125.pdf">
        DALL.E 2
      </a>
      | CLIP + Diffusion models，文本生成图像新高度 |
      <a
        href="https://www.semanticscholar.org/paper/Hierarchical-Text-Conditional-Image-Generation-with-Ramesh-Dhariwal/c57293882b2561e1ba03017902df9fc2f289dea2">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc57293882b2561e1ba03017902df9fc2f289dea2%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      计算机视觉 - Object Detection
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------- | ------------ |
      ------------------------------------------------------------ |
      | | 2014 |
      <a href="https://arxiv.org/pdf/1311.2524v5.pdf">
        R-CNN
      </a>
      | Two-stage |
      <a href="https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2f4df08d9072fc2ac181b7fced6a245315ce05c8%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2015 |
      <a href="http://arxiv.org/abs/1504.08083v2">
        Fast R-CNN
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7ffdbc358b63378f07311e883dddacc9faeeaf4b%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2015 |
      <a href="http://arxiv.org/abs/1506.01497v3">
        Faster R-CNN
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F424561d8585ff8ebce7d5d07de8dbf7aae5e7270%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2016 |
      <a href="http://arxiv.org/abs/1512.02325v5">
        SSD
      </a>
      | Single stage |
      <a href="https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2016 |
      <a href="http://arxiv.org/abs/1506.02640v5">
        YOLO
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff8e79ac0ea341056ef20f2616628b3e964764cfd%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="http://arxiv.org/abs/1703.06870v3">
        Mask R-CNN
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fea99a5535388196d0d44be5b4d7dd02029a43bb2%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="http://arxiv.org/abs/1612.08242v1">
        YOLOv2
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/7d39d69b23424446f0400ef603b2e3e22d0309d6">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7d39d69b23424446f0400ef603b2e3e22d0309d6%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2018 |
      <a href="http://arxiv.org/abs/1804.02767v1">
        YOLOv3
      </a>
      | |
      <a href="https://www.semanticscholar.org/paper/e4845fb1e624965d4f036d7fd32e8dcdd2408148">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe4845fb1e624965d4f036d7fd32e8dcdd2408148%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2019 |
      <a href="https://arxiv.org/pdf/1904.07850.pdf">
        CenterNet
      </a>
      | Anchor free |
      <a
        href="https://www.semanticscholar.org/paper/Objects-as-Points-Zhou-Wang/6a2e2fd1b5bb11224daef98b3fb6d029f68a73f2">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6a2e2fd1b5bb11224daef98b3fb6d029f68a73f2%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2005.12872.pdf">
        DETR
      </a>
      | Transformer |
      <a
        href="https://www.semanticscholar.org/paper/End-to-End-Object-Detection-with-Transformers-Carion-Massa/962dc29fdc3fbdc5930a10aba114050b82fe5a3e">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F962dc29fdc3fbdc5930a10aba114050b82fe5a3e%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <p>
      <a name="contrastive_learning">
      </a>
    </p>
    <h3>
      计算机视觉 - 对比学习
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2018 |
      <a href="https://arxiv.org/pdf/1805.01978.pdf">
        InstDisc
      </a>
      | 提出实例判别和memory bank做对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Unsupervised-Feature-Learning-via-Non-parametric-Wu-Xiong/155b7782dbd713982a4133df3aee7adfd0b6b304">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F155b7782dbd713982a4133df3aee7adfd0b6b304%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2018 |
      <a href="https://arxiv.org/pdf/1807.03748.pdf">
        CPC
      </a>
      | 对比预测编码，图像语音文本强化学习全都能做 |
      <a
        href="https://www.semanticscholar.org/paper/Representation-Learning-with-Contrastive-Predictive-Oord-Li/b227f3e4c0dc96e5ac5426b85485a70f2175a205">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb227f3e4c0dc96e5ac5426b85485a70f2175a205%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a href="https://arxiv.org/pdf/1904.03436.pdf">
        InvaSpread
      </a>
      | 一个编码器的端到端对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Unsupervised-Embedding-Learning-via-Invariant-and-Ye-Zhang/e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fe4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a href="https://arxiv.org/pdf/1906.05849.pdf">
        CMC
      </a>
      | 多视角下的对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Contrastive-Multiview-Coding-Tian-Krishnan/97f4d09175705be4677d675fa27e55defac44800">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F97f4d09175705be4677d675fa27e55defac44800%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a href="https://arxiv.org/pdf/1911.05722.pdf">
        MoCov1
      </a>
      | 无监督训练效果也很好 |
      <a
        href="https://www.semanticscholar.org/paper/Momentum-Contrast-for-Unsupervised-Visual-Learning-He-Fan/ec46830a4b275fd01d4de82bffcabe6da086128f">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fec46830a4b275fd01d4de82bffcabe6da086128f%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2002.05709.pdf">
        SimCLRv1
      </a>
      | 简单的对比学习 (数据增强 + MLP head + 大batch训练久) |
      <a
        href="https://www.semanticscholar.org/paper/A-Simple-Framework-for-Contrastive-Learning-of-Chen-Kornblith/34733eaf66007516347a40ad5d9bbe1cc9dacb6b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F34733eaf66007516347a40ad5d9bbe1cc9dacb6b%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2003.04297.pdf">
        MoCov2
      </a>
      | MoCov1 + improvements from SimCLRv1 |
      <a
        href="https://www.semanticscholar.org/paper/Improved-Baselines-with-Momentum-Contrastive-Chen-Fan/a1b8a8df281bbaec148a897927a49ea47ea31515">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa1b8a8df281bbaec148a897927a49ea47ea31515%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2006.10029.pdf">
        SimCLRv2
      </a>
      | 大的自监督预训练模型很适合做半监督学习 |
      <a
        href="https://www.semanticscholar.org/paper/Big-Self-Supervised-Models-are-Strong-Learners-Chen-Kornblith/3e7f5f4382ac6f9c4fef6197dd21abf74456acd1">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3e7f5f4382ac6f9c4fef6197dd21abf74456acd1%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2006.07733.pdf">
        BYOL
      </a>
      | 不需要负样本的对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Bootstrap-Your-Own-Latent%3A-A-New-Approach-to-Grill-Strub/38f93092ece8eee9771e61c1edaf11b1293cae1b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F38f93092ece8eee9771e61c1edaf11b1293cae1b%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2006.09882.pdf">
        SWaV
      </a>
      | 聚类对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Unsupervised-Learning-of-Visual-Features-by-Cluster-Caron-Misra/10161d83d29fc968c4612c9e9e2b61a2fc25842e">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F10161d83d29fc968c4612c9e9e2b61a2fc25842e%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2011.10566.pdf">
        SimSiam
      </a>
      | 化繁为简的孪生表征学习 |
      <a
        href="https://www.semanticscholar.org/paper/Exploring-Simple-Siamese-Representation-Learning-Chen-He/0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2104.02057.pdf">
        MoCov3
      </a>
      | 如何更稳定的自监督训练ViT |
      <a
        href="https://www.semanticscholar.org/paper/An-Empirical-Study-of-Training-Self-Supervised-Chen-Xie/739ceacfafb1c4eaa17509351b647c773270b3ae">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F739ceacfafb1c4eaa17509351b647c773270b3ae%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2104.14294.pdf">
        DINO
      </a>
      | transformer加自监督在视觉也很香 |
      <a
        href="https://www.semanticscholar.org/paper/Emerging-Properties-in-Self-Supervised-Vision-Caron-Touvron/ad4a0938c48e61b7827869e4ac3baffd0aefab35">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fad4a0938c48e61b7827869e4ac3baffd0aefab35%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      计算机视觉 - 视频理解
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2014 |
      <a href="https://cs.stanford.edu/people/karpathy/deepvideo/">
        DeepVideo
      </a>
      | 提出sports1M数据集，用深度学习做视频理解 |
      <a
        href="https://www.semanticscholar.org/paper/Large-Scale-Video-Classification-with-Convolutional-Karpathy-Toderici/6d4c9c923e9f145d1c01a2de2afc38ec23c44253">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6d4c9c923e9f145d1c01a2de2afc38ec23c44253%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2014 |
      <a href="https://arxiv.org/pdf/1406.2199.pdf">
        Two-stream
      </a>
      | 引入光流做时序建模，神经网络首次超越手工特征 |
      <a
        href="https://www.semanticscholar.org/paper/Two-Stream-Convolutional-Networks-for-Action-in-Simonyan-Zisserman/67dccc9a856b60bdc4d058d83657a089b8ad4486">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F67dccc9a856b60bdc4d058d83657a089b8ad4486%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2014 |
      <a href="https://arxiv.org/pdf/1412.0767.pdf">
        C3D
      </a>
      | 比较深的3D-CNN做视频理解 |
      <a
        href="https://www.semanticscholar.org/paper/Learning-Spatiotemporal-Features-with-3D-Networks-Tran-Bourdev/d25c65d261ea0e6a458be4c50c40ffe5bc508f77">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd25c65d261ea0e6a458be4c50c40ffe5bc508f77%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2015 |
      <a href="https://arxiv.org/pdf/1503.08909.pdf">
        Beyond-short-snippets
      </a>
      | 尝试使用LSTM |
      <a
        href="https://www.semanticscholar.org/paper/Beyond-short-snippets%3A-Deep-networks-for-video-Ng-Hausknecht/5418b2a482720e013d487a385c26fae0f017c6a6">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5418b2a482720e013d487a385c26fae0f017c6a6%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2016 |
      <a href="https://arxiv.org/pdf/1604.06573.pdf">
        Convolutional fusion
      </a>
      | 做early fusion来加强时空间建模 |
      <a
        href="https://www.semanticscholar.org/paper/Convolutional-Two-Stream-Network-Fusion-for-Video-Feichtenhofer-Pinz/9d9aced120e530484609164c836da64548693484">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9d9aced120e530484609164c836da64548693484%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2016 |
      <a href="https://arxiv.org/pdf/1608.00859.pdf">
        TSN
      </a>
      | 超级有效的视频分段建模，bag of tricks in video |
      <a
        href="https://www.semanticscholar.org/paper/Temporal-Segment-Networks%3A-Towards-Good-Practices-Wang-Xiong/ea3d7de6c0880e14455b9acb28f1bc1234321456">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fea3d7de6c0880e14455b9acb28f1bc1234321456%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2017 |
      <a href="https://arxiv.org/pdf/1705.07750.pdf">
        I3D
      </a>
      | 提出Kinetics数据集，膨胀2D网络到3D，开启3D-CNN时代 |
      <a
        href="https://www.semanticscholar.org/paper/Quo-Vadis%2C-Action-Recognition-A-New-Model-and-the-Carreira-Zisserman/b61a3f8b80bbd44f24544dc915f52fd30bbdf485">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb61a3f8b80bbd44f24544dc915f52fd30bbdf485%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2017 |
      <a href="https://arxiv.org/pdf/1711.11248.pdf">
        R2+1D
      </a>
      | 拆分3D卷积核，使3D网络容易优化 |
      <a
        href="https://www.semanticscholar.org/paper/A-Closer-Look-at-Spatiotemporal-Convolutions-for-Tran-Wang/89c3050522a0bb9820c32dc7444e003ef0d3e2e4">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F89c3050522a0bb9820c32dc7444e003ef0d3e2e4%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2017 |
      <a href="https://arxiv.org/pdf/1711.07971.pdf">
        Non-local
      </a>
      | 引入自注意力做视觉问题 |
      <a
        href="https://www.semanticscholar.org/paper/Non-local-Neural-Networks-Wang-Girshick/8899094797e82c5c185a0893896320ef77f60e64">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8899094797e82c5c185a0893896320ef77f60e64%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2018 |
      <a href="https://arxiv.org/pdf/1812.03982.pdf">
        SlowFast
      </a>
      | 快慢两支提升效率 |
      <a
        href="https://www.semanticscholar.org/paper/SlowFast-Networks-for-Video-Recognition-Feichtenhofer-Fan/8b47b9c3c35b2b2a78bff7822605b3040f87d699">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8b47b9c3c35b2b2a78bff7822605b3040f87d699%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2102.05095.pdf">
        TimeSformer
      </a>
      | 视频中第一个引入transformer，开启video transformer时代 |
      <a
        href="https://www.semanticscholar.org/paper/Is-Space-Time-Attention-All-You-Need-for-Video-Bertasius-Wang/c143ea9e30b1f2d93a9c060253845423f9e60e1f">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc143ea9e30b1f2d93a9c060253845423f9e60e1f%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      多模态学习
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2021 |
      <a href="https://openai.com/blog/clip/">
        CLIP
      </a>
      | 图片和文本之间的对比学习 |
      <a
        href="https://www.semanticscholar.org/paper/Learning-Transferable-Visual-Models-From-Natural-Radford-Kim/6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2102.03334.pdf">
        ViLT
      </a>
      | 第一个摆脱了目标检测的视觉文本模型 |
      <a
        href="https://www.semanticscholar.org/paper/ViLT%3A-Vision-and-Language-Transformer-Without-or-Kim-Son/0839722fb5369c0abaff8515bfc08299efc790a1">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0839722fb5369c0abaff8515bfc08299efc790a1%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2104.13921.pdf">
        ViLD
      </a>
      | CLIP蒸馏帮助开集目标检测 |
      <a
        href="https://www.semanticscholar.org/paper/Open-vocabulary-Object-Detection-via-Vision-and-Gu-Lin/cf9b8da26d9b92e75ba49616ed2a1033f59fce14">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcf9b8da26d9b92e75ba49616ed2a1033f59fce14%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2112.03857.pdf">
        GLIP
      </a>
      | 联合目标检测和文本定位 |
      <a
        href="https://www.semanticscholar.org/paper/Grounded-Language-Image-Pre-training-Li-Zhang/5341b412383c43f4a693ad63ec4489e3ec7688c8">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5341b412383c43f4a693ad63ec4489e3ec7688c8%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2104.08860.pdf">
        CLIP4Clip
      </a>
      | 拿CLIP直接做视频文本retrieval |
      <a
        href="https://www.semanticscholar.org/paper/CLIP4Clip%3A-An-Empirical-Study-of-CLIP-for-End-to-Luo-Ji/281ad83e06d731d5d686acf07cd701576f1188c4">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F281ad83e06d731d5d686acf07cd701576f1188c4%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2109.08472.pdf">
        ActionCLIP
      </a>
      | 用多模态对比学习有监督的做视频动作分类 |
      <a
        href="https://www.semanticscholar.org/paper/ActionCLIP%3A-A-New-Paradigm-for-Video-Action-Wang-Xing/dc05240a06326b5b1664f7e8c95c330b08cd0349">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdc05240a06326b5b1664f7e8c95c330b08cd0349%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2112.02413.pdf">
        PointCLIP
      </a>
      | 3D变2D，巧妙利用CLIP做点云 |
      <a
        href="https://www.semanticscholar.org/paper/PointCLIP%3A-Point-Cloud-Understanding-by-CLIP-Zhang-Guo/f3ce9ba3fcec362b70263a7ed63d9404975496a0">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff3ce9ba3fcec362b70263a7ed63d9404975496a0%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2201.03546.pdf">
        LSeg
      </a>
      | 有监督的开集分割 |
      <a
        href="https://www.semanticscholar.org/paper/Language-driven-Semantic-Segmentation-Li-Weinberger/cc9826c222ac1e81b4b374dd9e0df130f298b1e8">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcc9826c222ac1e81b4b374dd9e0df130f298b1e8%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2202.11094.pdf">
        GroupViT
      </a>
      | 只用图像文本对也能无监督做分割 |
      <a
        href="https://www.semanticscholar.org/paper/GroupViT%3A-Semantic-Segmentation-Emerges-from-Text-Xu-Mello/0b5f27a5766c5d1394a6282ad94fec21d620bd6b">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0b5f27a5766c5d1394a6282ad94fec21d620bd6b%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2202.05822.pdf">
        CLIPasso
      </a>
      | CLIP跨界生成简笔画 |
      <a
        href="https://www.semanticscholar.org/paper/CLIPasso%3A-Semantically-Aware-Object-Sketching-Vinker-Pajouheshgar/9dec819778bebae4a468c7813f7638534c826f52">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9dec819778bebae4a468c7813f7638534c826f52%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2207.01077.pdf">
        DepthCLIP
      </a>
      | 用文本跨界估计深度 |
      <a
        href="https://www.semanticscholar.org/paper/Can-Language-Understand-Depth-Zhang-Zeng/9d0afe58801fe9e5537902e853d6e9e385340a92">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9d0afe58801fe9e5537902e853d6e9e385340a92%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      自然语言处理 - Transformer
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2017 |
      <a href="https://arxiv.org/pdf/1706.03762.pdf">
        Transformer
      </a>
      | 继MLP、CNN、RNN后的第四大类架构 |
      <a
        href="https://www.semanticscholar.org/paper/Attention-is-All-you-Need-Vaswani-Shazeer/204e3073870fae3d05bcbc2f6a8e263d9b72e776">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F204e3073870fae3d05bcbc2f6a8e263d9b72e776%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2018 |
      <a
        href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">
        GPT
      </a>
      | 使用 Transformer 解码器来做预训练 |
      <a
        href="https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fcd18800a0fe0b668a1cc19f2ec95b5003d0a5035%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2018 |
      <a href="https://arxiv.org/pdf/1810.04805.pdf">
        BERT
      </a>
      | Transformer一统NLP的开始 |
      <a
        href="https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdf2b0e26d0599ce3e70df8a9da02e51594e0e992%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a
        href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">
        GPT-2
      </a>
      | 更大的 GPT 模型，朝着zero-shot learning迈了一大步 |
      <a
        href="https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9405cc0d6169988371b2755e573cc28650d14dfe%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2020 |
      <a href="https://arxiv.org/pdf/2005.14165.pdf">
        GPT-3
      </a>
      | 100倍更大的 GPT-2，few-shot learning效果显著 |
      <a
        href="https://www.semanticscholar.org/paper/Language-Models-are-Few-Shot-Learners-Brown-Mann/6b85b63579a916f705a8e10a49bd8d849d91b1fc">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F6b85b63579a916f705a8e10a49bd8d849d91b1fc%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      系统
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2014 |
      <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">
        参数服务器
      </a>
      | 支持千亿参数的传统机器学习模型 |
      <a
        href="https://www.semanticscholar.org/paper/Scaling-Distributed-Machine-Learning-with-the-Li-Andersen/0de0c3240bda7972bd0a3c8369ebc4b4f2e4f9c2">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0de0c3240bda7972bd0a3c8369ebc4b4f2e4f9c2%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2018 |
      <a href="https://proceedings.neurips.cc/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf">
        GPipe
      </a>
      | 流水线（Pipeline）并行 |
      <a
        href="https://www.semanticscholar.org/paper/GPipe%3A-Efficient-Training-of-Giant-Neural-Networks-Huang-Cheng/c18663fea10c8a303d045fd2c1f33cacf9b73ca3">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc18663fea10c8a303d045fd2c1f33cacf9b73ca3%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a href="https://arxiv.org/pdf/1909.08053.pdf">
        Megatron-LM
      </a>
      | 张量（Tensor）并行 |
      <a
        href="https://www.semanticscholar.org/paper/Megatron-LM%3A-Training-Multi-Billion-Parameter-Using-Shoeybi-Patwary/8323c591e119eb09b28b29fd6c7bc76bd889df7a">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F8323c591e119eb09b28b29fd6c7bc76bd889df7a%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2019 |
      <a href="https://arxiv.org/pdf/1910.02054.pdf">
        Zero
      </a>
      | 参数分片 |
      <a
        href="https://www.semanticscholar.org/paper/ZeRO%3A-Memory-optimizations-Toward-Training-Trillion-Rajbhandari-Rasley/00c957711b12468cb38424caccdf5291bb354033">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F00c957711b12468cb38424caccdf5291bb354033%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a href="https://arxiv.org/pdf/2203.12533.pdf">
        Pathways
      </a>
      | 将Jax拓展到上千TPU核上 |
      <a
        href="https://www.semanticscholar.org/paper/Pathways%3A-Asynchronous-Distributed-Dataflow-for-ML-Barham-Chowdhery/512e9aa873a1cd7eb61ce1f25ca7df6acb7e2352">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F512e9aa873a1cd7eb61ce1f25ca7df6acb7e2352%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      图神经网络
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | ✅ | 2021 |
      <a href="https://distill.pub/2021/gnn-intro/">
        图神经网络介绍
      </a>
      | GNN的可视化介绍 |
      <a
        href="https://www.semanticscholar.org/paper/A-Gentle-Introduction-to-Graph-Neural-Networks-S%C3%A1nchez-Lengeling-Reif/2c0e0440882a42be752268d0b64243243d752a74">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F2c0e0440882a42be752268d0b64243243d752a74%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      优化算法
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | | 2014 |
      <a href="https://arxiv.org/pdf/1412.6980.pdf">
        Adam
      </a>
      | 深度学习里最常用的优化算法之一 |
      <a
        href="https://www.semanticscholar.org/paper/Adam%3A-A-Method-for-Stochastic-Optimization-Kingma-Ba/a6cb366736791bcccc5c8639de5a8f9636bf87e8">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa6cb366736791bcccc5c8639de5a8f9636bf87e8%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2016 |
      <a href="https://arxiv.org/pdf/1611.03530.pdf">
        为什么超大的模型泛化性不错
      </a>
      | |
      <a
        href="https://www.semanticscholar.org/paper/Understanding-deep-learning-requires-rethinking-Zhang-Bengio/54ddb00fa691728944fd8becea90a373d21597cf">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F54ddb00fa691728944fd8becea90a373d21597cf%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2017 |
      <a href="https://distill.pub/2017/momentum/">
        为什么Momentum有效
      </a>
      | Distill的可视化介绍 |
      <a
        href="https://www.semanticscholar.org/paper/Why-Momentum-Really-Works-Goh/3e8ccf9d3d843c9855c5d76ab66d3e775384da72">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3e8ccf9d3d843c9855c5d76ab66d3e775384da72%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
    <h3>
      新领域应用
    </h3>
    <p>
      | 已录制 | 年份 | 名字 | 简介 | 引用 |
      | ------ | ---- | ------------------------------------------------------------ | -------------------- |
      ------------------------------------------------------------ |
      | | 2016 |
      <a href="https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf">
        AlphaGo
      </a>
      | 强化学习出圈 |
      <a
        href="https://www.semanticscholar.org/paper/Mastering-the-game-of-Go-with-deep-neural-networks-Silver-Huang/846aedd869a00c09b40f1f1f35673cb22bc87490">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F846aedd869a00c09b40f1f1f35673cb22bc87490%3Ffields%3DcitationCount" />
      </a>
      |
      | | 2020 |
      <a href="https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf">
        AlphaFold
      </a>
      | 赢得比赛的的蛋白质3D结构预测 |
      <a
        href="https://www.semanticscholar.org/paper/Improved-protein-structure-prediction-using-from-Senior-Evans/3a083d843f891b3574494c385699c21766ce8b7a">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3a083d843f891b3574494c385699c21766ce8b7a%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://www.nature.com/articles/s41586-021-03819-2.pdf">
        AlphaFold 2
      </a>
      | 原子级别精度的蛋白质3D结构预测 |
      <a
        href="https://www.semanticscholar.org/paper/Highly-accurate-protein-structure-prediction-with-Jumper-Evans/dc32a984b651256a8ec282be52310e6bd33d9815">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdc32a984b651256a8ec282be52310e6bd33d9815%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://arxiv.org/pdf/2107.03374.pdf">
        Codex
      </a>
      | 使用注释生成代码 |
      <a
        href="https://www.semanticscholar.org/paper/Evaluating-Large-Language-Models-Trained-on-Code-Chen-Tworek/acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Facbdbf49f9bc3f151b93d9ca9a06009f4f6eb269%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2021 |
      <a href="https://www.nature.com/articles/s41586-021-04086-x.pdf">
        指导数学直觉
      </a>
      | 分析不同数学物体之前的联系来帮助发现新定理 |
      <a
        href="https://www.semanticscholar.org/paper/Advancing-mathematics-by-guiding-human-intuition-AI-Davies-Velickovic/f672b8fb430606fee0bb368f16603531ce1e90c4">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ff672b8fb430606fee0bb368f16603531ce1e90c4%3Ffields%3DcitationCount" />
      </a>
      |
      | ✅ | 2022 |
      <a
        href="https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf">
        AlphaCode
      </a>
      | 媲美一般程序员的编程解题水平 |
      <a
        href="https://www.semanticscholar.org/paper/Competition-Level-Code-Generation-with-AlphaCode-Li-Choi/5cbe278b65a81602a864184bbca37de91448a5f5">
        <img alt="citation"
          src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F5cbe278b65a81602a864184bbca37de91448a5f5%3Ffields%3DcitationCount" />
      </a>
      |
    </p>
  </section>
</body>

</html>